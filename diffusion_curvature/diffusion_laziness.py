# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/0c1a-Diffusion-Laziness.ipynb.

# %% auto 0
__all__ = ['wasserstein_spread_of_diffusion', 'entropy_of_diffusion', 'get_matrix_power_recursive', 'powers_of_diffusion',
           'kl_div', 'js_dist', 'diffusion_distances_along_trajectory', 'trapezoidal_rule', 'DiffusionLaziness']

# %% ../nbs/0c1a-Diffusion-Laziness.ipynb 3
import jax.numpy as jnp
from jax import jit

@jit
def wasserstein_spread_of_diffusion(
                D:jax.Array, # manifold geodesic distances
                Pt:jax.Array, # powered diffusion matrix/t-step ehat diffusions
                ):
        """
        Returns how "spread out" each diffusion is, with wasserstein distance
        Presumes that the manifold distances have been separately calculated
        """
        return jnp.sum(D * Pt, axis=-1)

# %% ../nbs/0c1a-Diffusion-Laziness.ipynb 11
import jax.scipy
import jax.numpy as jnp

def entropy_of_diffusion(
    Pt:jax.Array, # powered diffusion matrix
    epsilon=1e-5, # threshold for small values, for speed
): 
        """
        Returns the pointwise entropy of diffusion from the powered diffusion matrix in the input
        Assumes that Pt sums to 1
        """
        # Use only the elements of Pt that are greater than epsilon
        Pt = Pt * (Pt>epsilon)
        # Normalize Pt so that it sums to 1
        Pt = Pt / (jnp.sum(Pt, axis=-1) + 1e-12)
        # Pt = (Pt + 1e-10) /(1 + 1e-10*Pt.shape[0]) # ensure, for differentiability, that there are no zeros in Pt, but that it still sums to 1.
        entropy_elementwise = jax.scipy.special.entr(Pt)
        entropy_of_rows = jnp.sum(entropy_elementwise, axis=-1)
        # normalize so max value is 1
        # entropy_of_rows = entropy_of_rows / (-jnp.log(1/jnp.sum(Pt>epsilon, axis=-1)))
        return entropy_of_rows

# %% ../nbs/0c1a-Diffusion-Laziness.ipynb 18
from typing import List
import math

def get_matrix_power_recursive(
    desired_power:int, 
    Pt_dict:dict, # should be, by default, {1 : P}
):
    if desired_power in Pt_dict.keys():
        return Pt_dict[desired_power], Pt_dict
    # Given no existing keys, we factor things into the closest powers of two. But if there is a large existing key (larger than the poewr of two), we'll use that.
    best_power = desired_power // 2
    max_power = max(Pt_dict.keys())
    if max_power >= best_power and max_power < desired_power: u = max_power
    else:
        u = best_power
        _, Pt_dict = get_matrix_power_recursive(best_power, Pt_dict)
    P_minusmax, Pt_dict = get_matrix_power_recursive(abs(desired_power - u), Pt_dict)
    Pt = Pt_dict[u] @ P_minusmax
    Pt_dict[desired_power] = Pt
    return Pt, Pt_dict


def powers_of_diffusion(
    P:jax.Array, # diffusion matrix
    ts:List[Int], # list of times 
)->List[jax.Array]: 
    """
    Returns list[P^t for t in ts], but done efficiently.
    """
    Pt_dict = { 1: P }
    Pts = []
    for t in ts:
        Pt, Pt_dict = get_matrix_power_recursive(t, Pt_dict)
        Pts.append(Pt)
    return Pts

# %% ../nbs/0c1a-Diffusion-Laziness.ipynb 34
@jax.jit
def kl_div(A, B, eps = 1e-12):
    # Calculate Kullback-Leibler divergence
    # get rid of zero values
    A = jnp.where(A == 0, eps, A)
    B = jnp.where(B == 0, eps, B)
    v = A*(jnp.log(A) - jnp.log(B)) 
    return jnp.sum(v)

# %% ../nbs/0c1a-Diffusion-Laziness.ipynb 36
@jax.jit
def js_dist(
    P:jax.Array, 
    Q:jax.Array,
):
    """Compute the Jensen-Shannon distance between two probability distributions.

    Input
    -----
    P, Q : array-like
        Probability distributions of equal length that sum to 1
    """

    M = 0.5 * (P + Q)

    # Get the JS DIVERGENCE
    result = 0.5 * (kl_div(P, M) + kl_div(Q, M))
    # Take sqrt to get the JS DISTANCE
    return jnp.sqrt(jnp.abs(result))

# %% ../nbs/0c1a-Diffusion-Laziness.ipynb 44
from scipy.spatial.distance import jensenshannon
def diffusion_distances_along_trajectory(diffusions):
    # given a sequence of diffusions, returns the distances between each 
    js_dist_vectorized = jax.vmap(js_dist, (0, 0), 0)
    distances = [jnp.zeros(diffusions[0].shape[0])]
    for idx in range(len(diffusions)-1):
        step_distance = js_dist_vectorized(diffusions[idx+1], diffusions[idx])
        distances.append(
            distances[-1] + step_distance
        )
    return jnp.stack(distances)

# %% ../nbs/0c1a-Diffusion-Laziness.ipynb 48
import jax
import jax.numpy as jnp

def trapezoidal_rule(x, y):
    # Ensure x and y are JAX arrays
    x = jnp.asarray(x)
    y = jnp.asarray(y)
    
    # Calculate the differences between consecutive x values along the second axis (axis=1)
    dx = x[:, 1:] - x[:, :-1]
    
    # Calculate the trapezoidal areas along the second axis
    trapezoidal_areas = dx * (y[:, :-1] + y[:, 1:]) / 2
    
    # Sum up the areas along the second axis to get the integral for each row
    integral = jnp.sum(trapezoidal_areas, axis=1)
    
    return integral

# %% ../nbs/0c1a-Diffusion-Laziness.ipynb 51
from typing import Literal
from .kernels import diffusion_matrix_from_affinities
from .heat_diffusion import heat_diffusion_from_dirac

class DiffusionLaziness():
    DIFFUSION_TYPES = Literal['diffusion matrix','heat kernel']
    LAZINESS_METHODS = Literal['Entropic', 'Wasserstein']
    def __init__(
        self,
        diffusion_type:DIFFUSION_TYPES = "diffusion matrix",
        laziness_method:LAZINESS_METHODS = "Entropic",
    ):
        store_attr()


    def fit_transform(
        self,
        G, # graph
        ts, # time or list of times.
        D = None,
        t_dist:int = 25, # diffusion time for distance calculation
    ):
        # get jax affinity matrix, and compute diffusion matrix from graph
        W = G.W
        if scipy.sparse.issparse(W):
            W = W.todense()
        if D is None: ts += [t_dist]
        W = jnp.array(W)
        # get powers of diffusion
        match self.diffusion_type:
            case 'diffusion matrix':
                P = diffusion_matrix_from_affinities(W)
                Pts = powers_of_diffusion(P, ts)
            case 'heat kernel':
                raise NotImplementedError # TODO: Implement and test
                Pts = heat_diffusion_from_dirac(G, ts)
        match self.laziness_method:
            case "Wasserstein":
                if D is None: D = phate_distances(Pts[-1])
                laziness_with_distance = partial(wasserstein_spread_of_diffusion, D = D)
                laziness_fn = jax.vmap(wasserstein_spread_of_diffusion)
            case "Entropic":
                laziness_fn = jax.vmap(entropy_of_diffusion, (0), 0)
        if D is None: diffusions = Pts[:-1] # the last Pt is for heat 
        print(len(diffusions))
        self.ls = laziness_fn(jnp.stack(diffusions)).T 
        self.ds = diffusion_distances_along_trajectory(diffusions).T
        laziness_under_curve = trapezoidal_rule(self.ds, self.ls)
        return laziness_under_curve
