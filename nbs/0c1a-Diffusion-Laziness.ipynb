{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| default_exp diffusion_laziness\n",
    "# Diffusion Curvature utils\n",
    "from diffusion_curvature.utils import *\n",
    "from diffusion_curvature.datasets import *\n",
    "# Python necessities\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from fastcore.all import *\n",
    "import matplotlib.pyplot as plt\n",
    "# Notebook Helpers\n",
    "from nbdev.showdoc import *\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from fastcore.all import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Laziness Estimators\n",
    "> What's the shape of this diffusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Spread of Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "\n",
    "@jit\n",
    "def wasserstein_spread_of_diffusion(\n",
    "                D:jax.Array, # manifold geodesic distances\n",
    "                Pt:jax.Array, # powered diffusion matrix/t-step ehat diffusions\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Returns how \"spread out\" each diffusion is, with wasserstein distance\n",
    "        Presumes that the manifold distances have been separately calculated\n",
    "        \"\"\"\n",
    "        return jnp.sum(D * Pt, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.random.rand(1000,1000)\n",
    "Pt = np.random.rand(1000,1000)\n",
    "Pt = Pt / np.sum(Pt, axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08 ms ± 57.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "wasserstein_spread_of_diffusion(D,Pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "Djax = jax.random.normal(key, (1000, 1000))\n",
    "key = jax.random.PRNGKey(10)\n",
    "Ptjax = jax.random.normal(key, (1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706 µs ± 11.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "wasserstein_spread_of_diffusion(Djax,Ptjax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, it's nearly two orders of magnitude faster when using jax arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy of Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import jax.scipy\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def entropy_of_diffusion(\n",
    "    Pt:jax.Array, # powered diffusion matrix\n",
    "    epsilon=1e-5, # threshold for small values, for speed\n",
    "): \n",
    "        \"\"\"\n",
    "        Returns the pointwise entropy of diffusion from the powered diffusion matrix in the input\n",
    "        Assumes that Pt sums to 1\n",
    "        \"\"\"\n",
    "        # Use only the elements of Pt that are greater than epsilon\n",
    "        Pt = Pt * (Pt>epsilon)\n",
    "        # Normalize Pt so that it sums to 1\n",
    "        Pt = Pt / (jnp.sum(Pt, axis=-1) + 1e-12)\n",
    "        # Pt = (Pt + 1e-10) /(1 + 1e-10*Pt.shape[0]) # ensure, for differentiability, that there are no zeros in Pt, but that it still sums to 1.\n",
    "        entropy_elementwise = jax.scipy.special.entr(Pt)\n",
    "        entropy_of_rows = jnp.sum(entropy_elementwise, axis=-1)\n",
    "        # normalize so max value is 1\n",
    "        # entropy_of_rows = entropy_of_rows / (-jnp.log(1/jnp.sum(Pt>epsilon, axis=-1)))\n",
    "        return entropy_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jnp.allclose(entropy_of_diffusion(Pt),entropy(Pt,axis=1), atol = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Laziness Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions estimate the laziness of a powered diffusion matrix, at a single time. Here, we extend the computation over multiple times, as well as making it more convenient to call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Multiple Powers of Diffusion at Once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is taking a diffusion matrix, and a list of times, and producing powerings of the matrix for each time.\n",
    "We do this by beginning with the lowest number, then for each subsequent number, taking its additive factors (i.e. partitions), seeing if any of them are already in the list, and using them if so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from typing import List\n",
    "\n",
    "def get_matrix_power_recursive(\n",
    "    desired_power:int, \n",
    "    Pt_dict:dict, # should be, by default, {1 : P}\n",
    "):\n",
    "    if desired_power in Pt_dict.keys():\n",
    "        return Pt_dict[desired_power], Pt_dict\n",
    "    # Given no existing keys, we factor things into the closest powers of two. But if there is a large existing key (larger than the poewr of two), we'll use that.\n",
    "    best_power = desired_power // 2\n",
    "    max_power = max(Pt_dict.keys())\n",
    "    if max_power >= best_power: u = max_power\n",
    "    else:\n",
    "        u = best_power\n",
    "        _, Pt_dict = get_matrix_power_recursive(best_power, Pt_dict)\n",
    "    P_minusmax, Pt_dict = get_matrix_power_recursive(desired_power - u, Pt_dict)\n",
    "    Pt = Pt_dict[u] @ P_minusmax\n",
    "    Pt_dict[desired_power] = Pt\n",
    "    return Pt, Pt_dict\n",
    "\n",
    "\n",
    "def powers_of_diffusion(\n",
    "    P:jax.Array, # diffusion matrix\n",
    "    ts:List[Int], # list of times \n",
    ")->List[jax.Array]: \n",
    "    \"\"\"\n",
    "    Returns list[P^t for t in ts], but done efficiently.\n",
    "    \"\"\"\n",
    "    Pt_dict = { 1: P }\n",
    "    Pts = []\n",
    "    for t in ts:\n",
    "        Pt, Pt_dict = get_matrix_power_recursive(t, Pt_dict)\n",
    "        Pts.append(Pt)\n",
    "    return Pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = random_jnparray(10,10)\n",
    "A_19, A_power_dict = get_matrix_power_recursive(\n",
    "    19, {1:A}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.allclose(jnp.linalg.matrix_power(A, 19), A_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 4, 5, 9, 10, 19])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_power_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed test: jnp's implementation of matmul is, as expected faster. But only by a factor of 5. That's pretty good. Quite likely python is the cause of slowness, not the algorithm we've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.6 µs ± 70.1 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t = np.random.randint(40,60)\n",
    "At, Adict = get_matrix_power_recursive(t, { 1 : A })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.88 µs ± 44.8 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t = np.random.randint(40,60)\n",
    "At = jnp.linalg.matrix_power(A, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the real use case: getting powered matrices from a list of powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = [1,2,3,4,5,6,7,8,10,13,15,17,21,25]\n",
    "Pts = powers_of_diffusion(A, ts)\n",
    "for i,t in enumerate(ts):\n",
    "    jnp.allclose(Pts[i], jnp.linalg.matrix_power(A, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing it, we've now become faster than the bare metal -- though surprisingly not by that much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581 µs ± 3.09 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ts = np.arange(1,100)\n",
    "Pts = powers_of_diffusion(A, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710 µs ± 106 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ts = np.arange(1,100)\n",
    "Pts = [jnp.linalg.matrix_power(A, t) for t in ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that computing a hundred sequential powers instead of one only scales by a factor of ten, versus, for the basic jax, a factor of 100. That's the important constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion Laziness Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class DiffusionLaziness():\n",
    "    DIFFUSION_TYPES = Literal['diffusion matrix','heat kernel']\n",
    "    LAZINESS_METHODS = Literal['Entropic', 'Wasserstein']\n",
    "    def __init__(\n",
    "        diffusion_type:DIFFUSION_TYPES = \"diffusion matrix\",\n",
    "        laziness_method:LAZINESS_METHODS = \"Entropic\",\n",
    "    ):\n",
    "        store_attr()\n",
    "\n",
    "\n",
    "    def fit_transform(\n",
    "        G, # graph\n",
    "        t, # time or list of times.\n",
    "    ):\n",
    "        # compute diffusion matrix from graph\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_curvature-pixi",
   "language": "python",
   "name": "diffusion_curvature-pixi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
