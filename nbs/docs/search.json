[
  {
    "objectID": "library/MIOFlow Standard - Quicktrain.html",
    "href": "library/MIOFlow Standard - Quicktrain.html",
    "title": "Quicktrain for MIOFlow Standard",
    "section": "",
    "text": "::: {#cell-1 .cell 0=‘d’ 1=‘e’ 2=‘f’ 3=‘a’ 4=‘u’ 5=‘l’ 6=‘t’ 7=‘’ 8=’e’ 9=’x’ 10=’p’ 11=’ ’ 12=’m’ 13=’i’ 14=’o’ 15=’f’ 16=’l’ 17=’o’ 18=’w’ 19=’’ 20=‘q’ 21=‘u’ 22=‘i’ 23=‘c’ 24=‘k’ 25=‘t’ 26=‘r’ 27=‘a’ 28=‘i’ 29=‘n’ execution_count=1}\n## Standard libraries\nimport os\nimport math\nimport numpy as np\nimport time\nfrom fastcore.all import *\nfrom nbdev.showdoc import *\n# Configure environment\nos.environ['XLA_PYTHON_CLIENT_PREALLOCATE']='false' # Tells Jax not to hog all of the memory to this process.\n\n## Imports for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom IPython.display import set_matplotlib_formats\n# set_matplotlib_formats('svg', 'pdf') # For export\nfrom matplotlib.colors import to_rgba\nimport seaborn as sns\nsns.set()\n\n## Progress bar\nfrom tqdm.auto import tqdm\n\n## project specifics\nimport diffusion_curvature\nimport pygsp\nimport jax\nimport jax.numpy as jnp\njax.devices()\n\nfrom diffusion_curvature.graphs import *\nfrom diffusion_curvature.datasets import *\nfrom diffusion_curvature.core import *\nfrom diffusion_curvature.utils import *\nfrom diffusion_curvature.comparison_space import *\n\n%load_ext autoreload\n%autoreload 2\n:::\nRegular MIOFlow hides its training behind a mess of functions and variables. Here, we adapt them into an easy-to-call class with an sklearn style fit-transform function.\n\nImplementation\n::: {#cell-5 .cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’ execution_count=6}\nfrom fastcore.all import *\nfrom diffusion_curvature.mioflow import *\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom imageio import imread, mimwrite\nfrom IPython.display import Image\nimport os\nimport torch\n\nclass MIOFlowStandard():\n    def __init__(\n        self,\n        embedding_dimension = 2, # dimension in which to embed the data. Should be the manifold's intrinsic dimension.\n        use_cuda = torch.cuda.is_available(),\n        autoencoder = None,\n    ):\n        store_attr()\n        # These determine the logic flow for training: \n        #   use_emb=True use_gae=False is only the encoder to match the approximation of the geodesic.\n        #   use_emb=False use_gae=True the full Geodesic Autoencoder (GAE), i.e. matching the geodesic and a reconstruction loss.\n        #   use_emb=False use_gae=False Is not using the GAE.\n        #   use_emb=True use_gae=True, is redundant and should raise an error. \n        self.use_emb = False\n        self.use_gae = True\n        self.need_to_train_gae = (self.use_emb or self.use_gae) and self.use_emb != self.use_gae\n        # If the reconstruction loss needs to be computed.\n        self.recon = self.use_gae and not self.use_emb \n\n    def setup_data(\n        self,\n        X, # np.array of shape (n_samples, n_features)\n    ):\n        data = {'samples': [0] * len(X)} # all at time 0\n        for i in range(X.shape[1]):\n            data[f'd{i+1}'] = X[:, i]\n\n        if D is None:\n            emb_op = HeatGeo(knn=5)\n            emb = emb_op.fit_transform(X)\n            D = emb_op.dist\n        \n        # Create the dataframe\n        df = pd.DataFrame(data)\n        df['radial_dists'] = D[central_idx]\n        self.model_features = len(df.columns) - 2\n        self.groups = sorted(df.samples.unique())\n        self.df = df\n        return df\n\n    def train_autoencoder(self,df):\n        self.model_features = len(df.columns) - 2\n        self.groups = sorted(df.samples.unique())\n        use_cuda = self.use_cuda\n        # This is True if we want to holdout (or skip) one timepoint during training. It is used to test the accuracy of the trajectories on unseen data.\n        hold_one_out = False\n        # It can be a group number or 'random', works in tandem with hold_one_out\n        hold_out = 3\n        # The dimensions in the input space, it is columns - 2 because we assume one column is equal to \"samples\", and one to \n       \n        # These are training GAE hyperparameters needed for training\n        # Distance_type in ['gaussian', 'alpha_decay'], and Gaussian scale\n        distance_type = 'gaussian'\n        rbf_length_scale=0.1\n        dist = setup_distance(distance_type, rbf_length_scale=rbf_length_scale)\n        #Can be changed depending on the dataset\n        n_epochs_emb = 10000\n        samples_size_emb = (30, )\n        # Layers for the Geodesic Autoencoder\n        gae_embedded_dim = self.embedding_dimension\n        encoder_layers = [self.model_features, 8, gae_embedded_dim]\n        if self.autoencoder is None:\n            gae = Autoencoder(\n                encoder_layers = encoder_layers,\n                decoder_layers = encoder_layers[::-1],\n                activation='ReLU', use_cuda = use_cuda\n            )\n        else:\n            gae = self.autoencoder\n        optimizer = torch.optim.AdamW(gae.parameters()) # Added in extra cell just for iterative programming / running of code\n        #   but could be added to code block above\n        if need_to_train_gae:\n            start_time_geo = time.time()\n\n            losses = train_ae(\n                gae, df, self.groups, optimizer, \n                n_epochs=n_epochs_emb, sample_size=samples_size_emb,\n                noise_min_scale=0.09, noise_max_scale=0.15, \n                dist=dist, recon=self.recon, use_cuda=self.use_cuda,\n                hold_one_out=hold_one_out, hold_out=hold_out\n            )\n            run_time_geo = time.time() - start_time_geo\n\n            print('run time:',run_time_geo)\n            autoencoder = gae\n        else:\n            autoencoder = None \n        # store results\n        self.autoencoder = autoencoder\n        return auteoncoder\n\n    def visualize_autoencoder(self, X=None, n_samples=1000):\n        if X is not None: df = self.setup_data(X)\n        else: df = self.df\n        sample_X = sample(df,0,size=(n_samples,),replace=False,to_torch=True,use_cuda=self.use_cuda)[0]\n        encoded_X = self.autoencoder.encode(sample_X).cpu().detach().numpy()\n        plt.scatter(encoded_X[:,0],encoded_X[:,1],c=sample_X[:,2].cpu())\n\n    def train_ode(self, df):\n        self.model_features = len(df.columns) - 2\n        self.groups = sorted(df.samples.unique())\n        #Directory where results are saved\n        exp_name = 'test'\n        # density loss knn\n        use_density_loss = False\n        # Weight of density (not percentage of total loss)\n        lambda_density = 35\n        # For petal=LeakyReLU / dyngen=CELU\n        activation = 'LeakyReLU'\n\n        criterion = MMD_loss_to_uniform(use_cuda=use_cuda)\n\n        # Can change but we never really do, mostly depends on the dataset.\n        layers = [16,32,16]\n        # Scale of the noise in the trajectories. Either len(groups)*[float] or None. Should be None if using an adaptative ODE solver.\n        sde_scales = len(self.groups)*[0.1] \n        if recon:    \n            model_features = self.embedding_dimension\n        model = make_model(\n            model_features, layers, \n            activation=activation, scales=sde_scales, use_cuda=self.use_cuda\n        ) \n        # Basically \"batch size\"\n        sample_size=(60, )\n        # Training specification\n        n_local_epochs = 40\n        n_epochs = 10\n        n_post_local_epochs = 0\n        # Using the reverse trajectories to train\n        reverse_schema = False\n        # each reverse_n epoch\n        reverse_n = 2\n        # criterion_name = 'ot'\n        # criterion = config_criterion(criterion_name)\n        optimizer = torch.optim.AdamW(model.parameters())\n\n        # Bookkeeping variables\n        batch_losses = []\n        globe_losses = []\n        if hold_one_out and hold_out in self.groups:\n            local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups) if hold_out not in [t0, t1]}\n        else:\n            local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups)}\n\n        # For creating output.\n        n_points = 100\n        n_trajectories = 100\n        n_bins = 100\n        start_time = time.time()\n        local_losses, batch_losses, globe_losses = training_regimen_neural_flattener(\n            # local, global, local train structure\n            n_local_epochs=n_local_epochs,\n            n_epochs=n_epochs, \n            n_post_local_epochs=n_post_local_epochs,\n            criterion=criterion,\n            # where results are stored\n            exp_dir=\"../../results/\", \n\n            # BEGIN: train params\n            model=model, df=df, groups=self.groups, optimizer=optimizer, \n            use_cuda=use_cuda,\n            \n            hold_one_out=hold_one_out, hold_out=hold_out,\n            \n            use_density_loss=use_density_loss, \n            lambda_density=lambda_density,\n            \n            autoencoder=self.autoencoder, use_emb=self.use_emb, use_gae=self.use_gae, \n\n            sample_size=sample_size, logger=None,\n            reverse_schema=reverse_schema, reverse_n=reverse_n,\n            use_penalty=True, lambda_energy=0.001,\n            # END: train params\n\n            plot_every=None,\n            n_points=n_points, n_trajectories=n_trajectories, n_bins=n_bins, \n            #local_losses=local_losses, batch_losses=batch_losses, globe_losses=globe_losses\n        )\n        run_time = time.time() - start_time + run_time_geo if use_emb or use_gae else time.time() - start_time\n        self.ode = model\n        return model\n\n    def transform(self, X, return_trajectories=False):\n        df = self.setup_data(X)\n        self.generated, self.trajectories = generate_plot_data_flat(\n            self.ode, df, 1000, n_trajectories, 100, use_cuda=use_cuda, samples_key='samples', logger=None,\n            autoencoder=self.autoencoder, recon=False\n        )\n        if return_trajectories:\n            return generated, trajectories\n        else:\n            return generated[-1] # just return the last timepoint, which is maximally flattened\n\n    def training_gif(self):\n        # create a placeholder array (T, N, D) with random values\n        data = self.generated\n        # create a tmp directory if not exists\n        if not os.path.exists('tmp'):\n            os.makedirs('tmp')\n        # empty list to store images\n        images = []\n\n        for i in range(data.shape[0]): # for each sub-array\n            fig, ax = plt.subplots() # create a new figure and plot\n            im = ax.imshow(data[i])  # show the image data on the plot\n            \n            filename = f'tmp/frame_{i}.png' # save to tmp folder\n            plt.savefig(filename)    # save the figure to a temporary file\n            images.append(imread(filename)) # add the image to the list\n            plt.close()  # close the figure\n\n        # create gif with each image lasting for 0.2 seconds\n        mimwrite('result.gif', images, duration=0.2)\n\n        # display inline\n        Image(url='result.gif')\n\n        # deletes tmp directory and all files inside it\n        shutil.rmtree('tmp')\n\n\n    def fit_transform(self, X):\n        df = self.setup_data(X)\n        self.train_autoencoder(df)\n        self.train_ode(df)\n        return self.transform(X)\n:::\n\n\nTests\n\nfrom diffusion_curvature.datasets import sphere\nfrom diffusion_curvature.utils import plot_3d\nimport matplotlib.pyplot as plt\nX_sphere, ks_sphere = sphere(4000) # keep it relatively sparse\nX_cap_of_sphere = X_sphere[X_sphere[:,2] &gt; 0] # Just the itty bitty polar top\nprint('num points',len(X_cap_of_sphere))\nplot_3d(X_cap_of_sphere,X_cap_of_sphere[:,2],use_plotly=True)\n# plt.scatter(X_cap_of_sphere[:,0],X_cap_of_sphere[:,1])\n\nnum points 2008\n\n\n                                                \n\n\n\nMIOFlattener = MIOFlowStandard()\n\n\n# fit transform data\nX_cap_of_sphere_flattened = MIOFlattener.fit_transform(X_cap_of_sphere)\n\nUnboundLocalError: cannot access local variable 'D' where it is not associated with a value\n\n\n\n# sync changes to the library\nfrom IPython.display import display, Javascript\nimport time\ndisplay(Javascript('IPython.notebook.save_checkpoint();'))\ntime.sleep(2)\n!pixi run nbsync\n\n\n\n\n WARN pixi::project::manifest: BETA feature `[pypi-dependencies]` enabled!\n\nPlease report any and all issues here:\n\n    https://github.com/prefix-dev/pixi.\n\nTurn this warning off by setting the environment variable `PIXI_BETA_WARNING_OFF` to `true`.\n\n⠁ activating environment                                                        ✨ Pixi task: nbdev_export\n/home/piriac/Pumberton/Workshop/21-SUMRY-Curvature/diffusion-curvature/.pixi/env/lib/python3.11/site-packages/nbdev/export.py:54: UserWarning: Notebook '/home/piriac/Pumberton/Workshop/21-SUMRY-Curvature/diffusion-curvature/nbs/experiments/Curvature from Flattening.ipynb' uses `#|export` without `#|default_exp` cell.\nNote nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\nSee https://nbdev.fast.ai/getting_started.html for more information.\n  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\""
  }
]