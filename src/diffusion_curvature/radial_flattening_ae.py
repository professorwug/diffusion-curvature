# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/library/Radial Flattening Autoencoder.ipynb.

# %% auto 0
__all__ = ['RadialDistancesDataset', 'dataloader_for_local_neighborhood_flattening', 'RadialFlatteningAutoencoder',
           'radially_flatten_with_ae']

# %% ../../nbs/library/Radial Flattening Autoencoder.ipynb 5
import torch

class RadialDistancesDataset(torch.utils.data.Dataset):
    """
    Given a pointcloud, a distance matrix, and a central idx
    returns a dataloader with keys
    x - points per batch, beginning with central idx (which appears in every batch)
    d - distances to central idx in batch
    a - local adjacency matrix of batch, exp(-d)
    """
    def __init__(self, pointcloud, distances, central_idx, batch_size = 64):
        self.pointcloud = torch.tensor(pointcloud, dtype=torch.float32)
        self.distances = torch.tensor(distances, dtype=torch.float32)
        self.distances = self.distances / torch.max(self.distances)
        self.central_idx = central_idx
        self.batch_size = batch_size

    def __len__(self):
        return len(self.pointcloud)
    
    def __getitem__(self, idx):
        batch_idxs = torch.concatenate([torch.tensor([self.central_idx]),torch.randperm(len(self.pointcloud))[:self.batch_size-1]])
        batch = {}
        batch['x'] = self.pointcloud[batch_idxs]
        batch['d'] = self.distances[self.central_idx][batch_idxs]
        a = torch.exp(-self.distances[batch_idxs][:,batch_idxs])
        batch['p'] = a / torch.sum(a, axis=-1)[:,None]
        return batch
        
def dataloader_for_local_neighborhood_flattening(pointcloud, distances, central_idx, batch_size = 64):
    dataset = RadialDistancesDataset(pointcloud, distances, central_idx, batch_size)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=None, shuffle=True)
    return dataloader

# We don't expect to have enough points for this to be useful.
# def train_and_testloader_from_pointcloud_with_distances(
#     pointcloud, distances, batch_size = 64, train_test_split = 0.8
# ):
#     X = pointcloud
#     D = distances
#     split_idx = int(len(X)*train_test_split)
#     X_train = X[:split_idx]
#     X_test = X[split_idx:]
#     D_train = D[:split_idx,:split_idx]
#     D_test = D[split_idx:,split_idx:]
#     trainloader = dataloader_from_pointcloud_with_distances(X_train, D_train, batch_size)
#     testloader = dataloader_from_pointcloud_with_distances(X_test, D_test, batch_size)
#     return trainloader, testloader

# %% ../../nbs/library/Radial Flattening Autoencoder.ipynb 10
import torch
import torch.nn as nn
import pytorch_lightning as pl

class RadialFlatteningAutoencoder(pl.LightningModule):
    """
    What if you already know what your latent space should look like, but want to learn a differentiable mapping into it?
    Enter the DistanceMatchingAutoencoder, or DISMA for short. In addition to a mean squared error loss, it also penalizes the difference between the pairwise distances of the embedding and the supplied ground truth.

    Each minibatch from the dataloader is assumed to have the following keys:
    - `x`: the input data
    - `d`: the ground truth manifold distances from each batch point to the central point
    - 'p': a local diffusion matrix
    """
    def __init__(self, input_dim, intrinsic_dim, learning_rate=1e-3, reconstruction_weight=1, distance_weight=1, affinity_weight = 1):
        super().__init__()
        self.input_dim = input_dim
        self.intrinsic_dimension = intrinsic_dim
        self.lr = learning_rate
        self.reconstruction_weight = reconstruction_weight
        self.distance_weight = distance_weight
        self.affinity_weight = affinity_weight
        self.KLD = nn.KLDivLoss(reduction="mean")
        self.encoder = nn.Sequential(
            nn.Linear(in_features=input_dim, out_features=256),
            nn.ReLU(),
            nn.Linear(in_features=256, out_features=128),
            nn.ReLU(),
            nn.Linear(in_features=128, out_features=64),
            nn.ReLU(),
            nn.Linear(in_features=64, out_features=intrinsic_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(in_features=intrinsic_dim, out_features=64),
            nn.ReLU(),
            nn.Linear(in_features=64, out_features=128),
            nn.ReLU(),
            nn.Linear(in_features=128, out_features=256),
            nn.ReLU(),
            nn.Linear(in_features=256, out_features=input_dim)
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x
    
    def immersion(self, x):
        """The immersion defined by the autoencoder (or more precisely, the decoder)."""
        return self.decoder(x)

    def distance_loss(self, x_embedded, ground_truth_distances):
        # print("x_embedded is ", x_embedded)
        embedding_distances = torch.cdist(x_embedded, x_embedded[None,]) # torch.sqrt(torch.sum((x_embedded - x_embedded[0])**2, axis=-1)) # TODO: How will this play with batching?
        # print(embedding_distances)
        loss = nn.MSELoss()(embedding_distances, ground_truth_distances)
        # print(loss)
        return loss

    def affinity_loss(self, x_embedded, ground_truth_affinities):
        D = torch.cdist(x_embedded, x_embedded)
        A = torch.exp(-D) + torch.ones_like(D)*1e-10 #+ torch.eye(x_embedded.shape[0], device=x_embedded.device) + 1e-10
        P = A / torch.sum(A, axis=-1)[:,None]
        # KLD expects the input to be log'd
        Plog = torch.log(P)
        # test if there's a nan in Plog
        # print(torch.isnan(Plog).any().item())
        return self.KLD(Plog,ground_truth_affinities+torch.ones_like(D)*1e-10) #+  torch.eye(x_embedded.shape[0], device=x_embedded.device) + 1e-10)       )

    def step(self, batch, batch_idx):
        x = batch['x']
        d = batch['d']
        p = batch['p']
        x_embedded = self.encoder(x)
        x_hat = self.decoder(x_embedded)
        recon_loss = nn.MSELoss()(x_hat, x) if self.reconstruction_weight else 0
        dist_loss = self.distance_loss(x_embedded, d) if self.distance_weight else 0
        affinity_loss = self.affinity_loss(x_embedded, p) if self.affinity_weight else 0
        # print(f"{recon_loss=}, {dist_loss=}, {affinity_loss=}")
        loss = self.reconstruction_weight * recon_loss + self.distance_weight * dist_loss + self.affinity_weight * affinity_loss
        return loss

    def training_step(self, batch, batch_idx):
        loss = self.step(batch, batch_idx)
        self.log('train_loss', loss, prog_bar=True, on_epoch=True)
        return loss

    def validation_step(self, batch, batch_idx):
        loss = self.step(batch, batch_idx)
        self.log('val_loss', loss, prog_bar=True, on_epoch=True)
        return loss

    def test_step(self, batch, batch_idx):
        loss = self.step(batch, batch_idx)
        self.log('test_loss', loss, prog_bar=True, on_epoch=True)
        return loss

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
        return optimizer


# %% ../../nbs/library/Radial Flattening Autoencoder.ipynb 12
from heatgeo.embedding import HeatGeo
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import EarlyStopping

def radially_flatten_with_ae(
    X,
    D = None, # if not supplied, computes with heatgeo
    learning_rate = 1e-5,
    intrinsic_dim = 2,
    return_model = False,
):
    if not D:
        emb_op = HeatGeo(knn=5)
        emb = emb_op.fit_transform(X)
        D = emb_op.dist
        
    trainloader = dataloader_for_local_neighborhood_flattening(X, D, central_idx=0, batch_size=64)
    train_sample = next(iter(trainloader))
    
    # Initialize model and trainer
    model = RadialFlatteningAutoencoder(
        input_dim = train_sample['x'].shape[1],
        intrinsic_dim = intrinsic_dim,
        reconstruction_weight = 1,
        distance_weight = 1,
        affinity_weight = 1,
        learning_rate = learning_rate,
        )

    trainer = Trainer(
        max_epochs=100, 
        accelerator='cuda',
        use_distributed_sampler=False,
        enable_progress_bar=False, enable_model_summary=False,
        )
    trainer.fit(
        model=model,
        train_dataloaders=trainloader,        
    )
    embeddings = model.encoder(trainloader.dataset.pointcloud).cpu().detach().numpy()
    if return_model: return embeddings, model
    else: return embeddings
    
