{
  "hash": "4f5e6228b73ac1beb48c4d448a77fee2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Diffusion Curvature\nauthor:\n  - name: Kincaid MacDonald\n    orcid: 0000-0002-0760-5497\n    corresponding: true\n    email: kincaid@aya.yale.edu\n    roles: []\n    affiliations:\n    - Yale\n  - name: Dhananjay Bhaskar\n    orcid: 0000-0002-7859-8394\n    corresponding: false\n    roles: []\n    affiliations: \n    - MILA\n  - name: Kaly Zhang\n    orcid: 0000-0002-7859-8394\n    corresponding: false\n    roles: []\n    affiliations: \n    - MILA\n  - name: Ian Adelstein\n    orcid: 0000-0002-7859-8394\n    corresponding: false\n    roles: []\n    affiliations:\n    - Yale Department of Math\n  - name: Smita Krishnaswamy\n    orcid: 0000-0002-7859-8394\n    corresponding: false\n    roles: []\n    affiliations:\n    - Yale Department of Applied Math\n    - Yale School of Medicine\nkeywords:\n    - Manifold Learning\n    - Geometric Deep Learning\n    - Graph Curvature\n    - Point Clouds\nabstract: \n    For a number of years now work has been proceeding in order to bring to perfection the crudely conceived idea of a machine that would not only supply inverse reactive current for use in unilateral phase detractors, but would also be capable of automatically synchronizing cardinal grammeters. Such a machine is the \"Turbo-Encabulator.\"\nplain-language-summary: |\n    We introduce Diffusion Curvature, a fast, differentiable, noise-robust pointwise curvature for graphs and point clouds.\nkey-points: []\ndate: last-modified\nbibliography: references.bib\ncitation:\n    container-title: IEEE TPAMI\nnumber-sections: true\n---\n\n:::{#cd6df5f0 .cell .markdown}\n## Introduction\n\nRecent years have seen a growing appreciation that black-box machine learning methods can understand data better if equipped with geometric priors, both globally [cite TDA methods] and locally [cite heat & wave, energy]. This is especially true for graph-structured data. The usefulness of graphs as a general data representation comes at a cost: that data is “ripped from its context”. To take an example, when point cloud data becomes a graph, the *extrinsic* geometric perspective afforded by a bird’s eye view of the points is reduced to an *intrinsic* perspective – the ‘ant’s eye’ view. \n\n\n\nOutline:\n- \n\n\n# Diffusion Ricci Curvature\n\n\n\n\n\n\n\n\n{{< embed ../nbs/experiments/2c3-are-kernels-zeitgeibers.ipynb#fig-spread-of-diffusion-2d >}}\n\n\n\n\n\n\n\n\n\n## Data & Methods {#sec-data-methods}\n:::\n\n::: {#cell-torus .cell execution_count=1}\n``` {.python .cell-code .hidden}\nfrom diffusion_curvature.utils import plot_3d\nfrom diffusion_curvature.datasets import torus\nfrom diffusion_curvature.core import DiffusionCurvature, get_adaptive_graph\nX_torus, ks_torus = torus(2000)\nDC = DiffusionCurvature()\nG_torus = get_adaptive_graph(X_torus, k = 5, alpha = 1)\nks_computed = DC.curvature(G_torus, dim=2, t = 25)\nplot_3d(X_torus, ks_computed, colorbar=True)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n```\n2024-03-24 17:42:03,075:[WARNING](pygsp.graphs.graph.check_weights): The main diagonal of the weight matrix is not 0!\n2024-03-24 17:42:05,185:[WARNING](pygsp.graphs.graph.check_weights): The main diagonal of the weight matrix is not 0!\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Diffusion Curvature vs Gaussian Curvature of the Torus](index_files/figure-html/torus-output-2.png){#torus width=715 height=758 fig-alt='The diffusion curvature corresponds closely to the gaussian curvature of the torus'}\n:::\n:::\n\n\n:::{#57285e5f .cell .markdown}\n## Conclusion\n\n## References {.unnumbered}\n\n::: {#refs}\n:::\n:::\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}