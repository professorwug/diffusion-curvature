[
  {
    "objectID": "library/Mean Flat Entropies.html",
    "href": "library/Mean Flat Entropies.html",
    "title": "1c1 Mean Entropy of Uniform Flat Spaces",
    "section": "",
    "text": "average_flat_entropies\n\n average_flat_entropies (dim, t, num_trials,\n                         num_points_in_comparison=10000,\n                         graph_former=&lt;function get_adaptive_graph&gt;)\n\n\n\n\ncreate_mean_entropy_database\n\n create_mean_entropy_database (outfile='../data/entropies_averaged.h5',\n                               dimensions:int&lt;(Intrinsic)DimensionstoTakeM\n                               eanEntropiesover&gt;=[1, 2, 3, 4, 5, 6], knns:\n                               int&lt;k-nearestneighborvaluestocompute&gt;=[5,\n                               10, 15], ts:int&lt;timevaluestocompute&gt;=[25,\n                               30, 35])\n\n\n\n\nload_average_entropies\n\n load_average_entropies (filename)\n\n\nd = load_average_entropies('../data/entropies_averaged.h5')\n\n\nd\n\n{'1': {'10': {'25': 4.1617084},\n  '15': {'25': 4.5504103},\n  '5': {'25': 3.4661007}},\n '2': {'10': {'25': 5.775014}, '15': {'25': 6.2073145}, '5': {'25': 4.912664}},\n '3': {'10': {'25': 7.301388},\n  '15': {'25': 7.7671103},\n  '5': {'25': 6.2948627}},\n '4': {'10': {'25': 8.641593}, '15': {'25': 8.925011}, '5': {'25': 7.6750712}},\n '5': {'10': {'25': 9.111419}, '15': {'25': 9.178771}, '5': {'25': 8.638502}},\n '6': {'10': {'25': 9.189743}, '15': {'25': 9.203704}, '5': {'25': 9.015003}}}\n\n\n\n!nbdev_export"
  },
  {
    "objectID": "library/continuous_normalizing_flows.html",
    "href": "library/continuous_normalizing_flows.html",
    "title": "Mapping the Data to a Flat Space with Continuous Normalizing Flows",
    "section": "",
    "text": "Previously, our diffusion curvature comparison was done using a uniform sampling of a flat space. There’s some variance here, due to random sampling, which is not ideal – it mirrors the variance in sampling of the dataset itself, but compounds upon the problem by using a different random sampling. We observed that, with low-dimensional abundantly sampled data (like our torus), this variance was over 10x smaller than the variance within the torus, making comparisons possible. But for more sparsely sampled data (including, by necessity, all high dimensional data), the variance due to sampling will be much greater. This raises the question: can we learn a flat space with a sampling equivalent to the manifold’s sampling?\nIt’s not obvious that this question makes sense. What does it mean for a plane to be sampled the same as a sphere? Both can be uniformly sampled with respect to volume, but volume is modulated by curvature. Considering any sufficiently large neighborhood of the sphere versus an equivalent neighborhood of the plane, the neighborhood in positive curvature will have fewer points, because it has less volume. It’s impossible to place a sticker on a tennis ball; the flat sticker has “too many points” to biject onto the ball.\nHowever, at a sufficiently small neighborhood size, the question starts to make sense. It mirrors the aspiration to learn a logarithmic (or reverse-exponential) map, from the manifold to its tangent space. Equipped with this map, or a good approximation, we might be able to obtain a flat space with a (locally accurate) one-to-one mapping between points in the flat space and on the manifold.\nThis could be useful in a couple of ways: 1. Performing diffusion entropy in the equivalently sampled flat space. If a neighborhood of the manifold is sparsely sampled, it will bias the diffusion entropy towards being more negative than reality. If we create a flat space with a similarly sparse sampling, and a similarly biased entropy, the biases will cancel each other out in comparison. 2. If the map is a really good approximation of the logarithmic map, we could discern curvature just by locally measuring the changes in distances between points. This would put our bijection between points in the flat and manifold spaces to much better use, but it requires much more from the continuous normalizing flows.\nThe key challenges we anticipate include: 1. Mapping a sufficient number of points to perform 4-8 scales of diffusion may involve a neighborhood so large that the global geometry interferes with the sampling. For example, if mapping a 500 point neighborhood from the sphere into a flat space, these 500 points might include enough of the sphere’s curvature that the flat space appears more sparsely sampled than the sphere, thus biasing the comparison space. (Interestingly, though, this bias could be used to measure the curvature…)\nHere’s the strategy: for every point \\(x_i\\), we’ll take the nearest \\(n\\) points on the manifold, and treat this neighborhood of curvature like a self-contained dataset. We’ll then learn a continuous normalizing flow from this neighborhood of curvature to a uniformly sampled flat space of a supplied dimension. We’ll perform diffusion entropy in both spaces, bearing in mind these caveats: - \\(k\\) must be sufficiently large to minimize edge effects, where the diffusion, instead of continuing across the manifold, rebounds on itself. - \\(k\\) must be sufficiently small to avoid the mixing of geometry and sampling."
  },
  {
    "objectID": "library/continuous_normalizing_flows.html#datasets-for-testing",
    "href": "library/continuous_normalizing_flows.html#datasets-for-testing",
    "title": "Mapping the Data to a Flat Space with Continuous Normalizing Flows",
    "section": "Datasets for testing",
    "text": "Datasets for testing\nThis dataset returns the whole torus.\n\nwhole_torus_dataset = data.TensorDataset(torch.tensor(X_torus).float())\nwhole_torus_dataloader = data.DataLoader(whole_torus_dataset, batch_size=len(X_torus), shuffle=True)\n\nThis is a toy dataset from the torch dyn library:\n\nfrom torchdyn.datasets import *\nimport torch.utils.data as data\n\n\nd = ToyDataset()\nX_moons, yn_moons = d.generate(n_samples=512, noise=1e-1, dataset_type='moons')\nscaler = MinMaxScaler(feature_range=(-1,1))\nX_moons = scaler.fit_transform(X_moons)\n\ncolors = ['orange', 'blue']\nfig = plt.figure(figsize=(3,3))\nax = fig.add_subplot(111)\nfor i in range(len(X_moons)):\n    ax.scatter(X_moons[i,0], X_moons[i,1], s=1, color=colors[yn_moons[i].int()])\n\nX_train = torch.Tensor(X_moons)\nmoons_trainset = data.TensorDataset(X_train)\nmoons_trainloader = data.DataLoader(moons_trainset, batch_size=len(X_moons), shuffle=True)"
  },
  {
    "objectID": "library/Diffusion Entropy for Optimal t.html",
    "href": "library/Diffusion Entropy for Optimal t.html",
    "title": "diffusion_curvature",
    "section": "",
    "text": "/Users/boreas/Pumberton/Workshop/21-SUMRY-Curvature/diffusion-curvature/.pixi/env/lib/python3.11/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\nfind_knee_point\n\n find_knee_point (y, x=None)\n\nReturns the x-location of a (single) knee of curve y=f(x)\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny\narray, shape=[n]\n\ndata for which to find the knee point\n\n\nx\nNoneType\nNone\nindices of the data points of y,if these are not in order and evenly spaced\n\n\nReturns\nint\n\n\n\n\n\n\n\n\ncompute_von_neumann_entropy\n\n compute_von_neumann_entropy (data, t_max=100)\n\nDetermines the Von Neumann entropy of data at varying matrix powers. The user should select a value of t around the “knee” of the entropy curve.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\n\n\n\n\n\nt_max\nint\n100\nMaximum value of t to test\n\n\nReturns\narray, shape=[t_max]\n\nThe entropy of the diffusion affinities for each value of t\n\n\n\n\n\n\noptimal_t_via_vne\n\n optimal_t_via_vne (P, tmax=100)\n\n\nfrom diffusion_curvature.datasets import torus\nimport graphtools\n\n\nG = graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\n\n\nfrom diffusion_curvature.graphs import diff_aff, diff_op, diffusion_matrix_from_affinities\n\n\nX, ks = torus(5000)\nP = diff_op(G).todense()\n\n\nP\n\nmatrix([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]])\n\n\n\noptimal_t_via_vne(P, tmax=100)\n\n26"
  },
  {
    "objectID": "library/Random Surfaces.html",
    "href": "library/Random Surfaces.html",
    "title": "Random Surfaces",
    "section": "",
    "text": "There’s a general paucity of high-dimensional test data. To test diffusion curvature, we developed a battery of benchmark datasets: randomly generated quadric surfaces in arbitrary dimensions, sampled uniformly from the manifold space using rejection sampling. This provides a more challenging benchmark than our toy datasets."
  },
  {
    "objectID": "library/Random Surfaces.html#the-determinant-problem",
    "href": "library/Random Surfaces.html#the-determinant-problem",
    "title": "Random Surfaces",
    "section": "The Determinant Problem",
    "text": "The Determinant Problem\nRejection sampling requires taking the determinant of the Hessian, which (if using the standard algorithm) increases in terms factorially with the size of the matrix. The default sympy method (Bareiss) is painfully slow here, but the LU or Berkowitz methods do much better.\n\nf, variables = random_surface(4, 5)\nG = sp.Matrix.zeros(len(variables), len(variables))\nfor i, x1 in tqdm(enumerate(variables)):\n    for j, x2 in tqdm(enumerate(variables)):\n        G[i,j] = (sp.diff(f, x1).T  * sp.diff(f, x2))[0]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG.det(method='lu')\n\nCPU times: user 49.1 ms, sys: 8 µs, total: 49.1 ms\nWall time: 48.7 ms\n\n\n\\(\\displaystyle \\left(1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1\\right) \\left(2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1 - \\frac{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right) \\left(- \\frac{\\left(\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) - \\frac{\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right)^{2}}{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1 - \\frac{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}} + 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} + 1 - \\frac{7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right) \\left(- \\frac{\\left(\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) - \\frac{\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} \\cdot \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right)^{2}}{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1 - \\frac{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}} - \\frac{\\left(- \\frac{\\left(\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) - \\frac{\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right) \\left(\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) - \\frac{\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} \\cdot \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right)}{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1 - \\frac{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}} + \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) - \\frac{\\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} \\cdot \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right)^{2}}{- \\frac{\\left(\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) - \\frac{\\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right)^{2}}{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1 - \\frac{2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}} + 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} + 1 - \\frac{7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}} + 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} + 1 - \\frac{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} \\cdot 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}}{1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} + 1}\\right)\\)\n\n\n\n# %%time\n# G.det(method='bareiss')\n\n\nG.det(method='berkowitz')\n\nCPU times: user 46.6 ms, sys: 21 µs, total: 46.7 ms\nWall time: 46.1 ms\n\n\n\\(\\displaystyle \\left(- 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} - 1\\right) \\left(\\left(\\left(- 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} - 1\\right) \\left(- 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} - 1\\right) - 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(- 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} - 1\\right) + \\left(- 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} - 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(- 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} - 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} - 2\\right) - \\left(\\left(7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} + 1\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) - \\left(\\left(7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} + 1\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) - \\left(\\left(2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1\\right) \\left(\\left(2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) + \\left(\\left(7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} + 1\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) + \\left(\\left(7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} + 1\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) - \\left(\\left(7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} + 1\\right) \\left(\\left(7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} + 1\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) + \\left(\\left(2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) + \\left(\\left(7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} + 1\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) - \\left(\\left(7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} + 1\\right) \\left(\\left(7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} + 1\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) + \\left(\\left(2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + \\left(\\left(7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} + 1\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + \\left(- 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} - 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} - 1.64829031015765 \\left(0.220643585572026 x_{0} - x_{1} + 0.106949298560283 x_{2} + 0.699452823395452 x_{3} + 0.0952121791339656\\right)^{2} \\cdot 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(\\left(- 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} - 1\\right) \\left(- 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} - 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} - 2\\right) + \\left(- 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} - 1\\right) \\left(- 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} - 1\\right) - 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} - 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} - 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) + \\left(- \\left(\\left(2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} + 1\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(- 1.28385758951593 x_{0} + 1.59104631286197 x_{1} + 0.997318021037841 x_{2} - 0.352713739100065 x_{3} - 0.881673650061698\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) - \\left(\\left(7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} + 1\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) + \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2}\\right) \\left(0.137307668650024 x_{0} + 0.997318021037841 x_{1} + 0.398416880657731 x_{2} - 2.73426624171553 x_{3} - 1.67633928947153\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) - \\left(\\left(7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} + 1\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right) + 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} \\cdot \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) \\left(0.283274941914653 x_{0} - 1.28385758951593 x_{1} + 0.137307668650024 x_{2} + 0.897997815824595 x_{3} + 0.122238878795492\\right) \\left(0.897997815824595 x_{0} - 0.352713739100065 x_{1} - 2.73426624171553 x_{2} - 1.13257563120039 x_{3} - 0.191222223510257\\right)\\right) \\left(- 2.53142836967166 \\left(- 0.806926598639691 x_{0} + x_{1} + 0.626831546621588 x_{2} - 0.221686657546508 x_{3} - 0.554147068463235\\right)^{2} - 7.47621188058517 \\left(0.0502173733322597 x_{0} + 0.364747955346186 x_{1} + 0.145712540563627 x_{2} - x_{3} - 0.613085611011957\\right)^{2} - 7.47621188058517 \\left(0.328423692661756 x_{0} - 0.128997583965622 x_{1} - x_{2} - 0.414215563181511 x_{3} - 0.0699354805296065\\right)^{2} - 3\\right)\\)\n\n\n\n\nmanifold_density\n\n manifold_density (f, variables)\n\n\nf, vars = random_surface(3,5)\ng = manifold_density(f,vars)\ng\n\n\\(\\displaystyle 13.5614352769329 \\sqrt{- 1.02623740481724 \\cdot 10^{-17} x_{0}^{6} + 1.93174099730304 \\cdot 10^{-17} x_{0}^{5} x_{1} - 1.488044236985 \\cdot 10^{-16} x_{0}^{5} x_{2} + 5.91595680424056 \\cdot 10^{-17} x_{0}^{5} - 9.6587049865152 \\cdot 10^{-17} x_{0}^{4} x_{1}^{2} + 1.29788848256298 \\cdot 10^{-17} x_{0}^{4} x_{1} x_{2} - 2.70443739622426 \\cdot 10^{-16} x_{0}^{4} x_{1} + 3.59183091686034 \\cdot 10^{-17} x_{0}^{4} x_{2}^{2} + 1.63594315709101 \\cdot 10^{-16} x_{0}^{4} x_{2} + 0.0428981842836413 x_{0}^{4} - 5.02252659298791 \\cdot 10^{-16} x_{0}^{3} x_{1}^{3} - 2.4146762466288 \\cdot 10^{-16} x_{0}^{3} x_{1}^{2} x_{2} - 1.54539279784243 \\cdot 10^{-16} x_{0}^{3} x_{1}^{2} + 1.55746617907558 \\cdot 10^{-16} x_{0}^{3} x_{1} x_{2}^{2} + 4.8293524932576 \\cdot 10^{-18} x_{0}^{3} x_{1} x_{2} + 0.158101724304246 x_{0}^{3} x_{1} + 7.90806470770932 \\cdot 10^{-17} x_{0}^{3} x_{2}^{3} + 1.05038416728353 \\cdot 10^{-16} x_{0}^{3} x_{2}^{2} + 0.0886474424859319 x_{0}^{3} x_{2} - 0.0944889101075168 x_{0}^{3} - 2.55955682142653 \\cdot 10^{-16} x_{0}^{2} x_{1}^{4} + 1.54539279784243 \\cdot 10^{-16} x_{0}^{2} x_{1}^{3} x_{2} + 1.54539279784243 \\cdot 10^{-16} x_{0}^{2} x_{1}^{3} + 1.93174099730304 \\cdot 10^{-15} x_{0}^{2} x_{1}^{2} x_{2} + 0.348121417877565 x_{0}^{2} x_{1}^{2} + 1.03589610980376 \\cdot 10^{-15} x_{0}^{2} x_{1} x_{2}^{3} - 1.90276488234349 \\cdot 10^{-15} x_{0}^{2} x_{1} x_{2}^{2} - 0.0715208880245337 x_{0}^{2} x_{1} x_{2} + 0.470963907716864 x_{0}^{2} x_{1} - 9.6587049865152 \\cdot 10^{-17} x_{0}^{2} x_{2}^{4} + 2.70443739622426 \\cdot 10^{-16} x_{0}^{2} x_{2}^{3} + 0.19782156165004 x_{0}^{2} x_{2}^{2} - 0.443309605155563 x_{0}^{2} x_{2} + 0.350971090329827 x_{0}^{2} - 2.23357552813164 \\cdot 10^{-17} x_{0} x_{1}^{5} + 5.79522299190912 \\cdot 10^{-17} x_{0} x_{1}^{4} x_{2} + 7.48549636454928 \\cdot 10^{-17} x_{0} x_{1}^{4} - 1.15904459838182 \\cdot 10^{-16} x_{0} x_{1}^{3} x_{2}^{2} - 8.49966038813338 \\cdot 10^{-16} x_{0} x_{1}^{3} x_{2} - 0.501405484463605 x_{0} x_{1}^{3} + 2.99419854581971 \\cdot 10^{-16} x_{0} x_{1}^{2} x_{2}^{3} + 8.49966038813338 \\cdot 10^{-16} x_{0} x_{1}^{2} x_{2}^{2} + 0.652830619403015 x_{0} x_{1}^{2} x_{2} - 0.651188652398792 x_{0} x_{1}^{2} - 1.14697121714868 \\cdot 10^{-17} x_{0} x_{1} x_{2}^{4} - 2.45814041906812 \\cdot 10^{-15} x_{0} x_{1} x_{2}^{3} - 0.236963314995756 x_{0} x_{1} x_{2}^{2} + x_{0} x_{1} x_{2} - 0.495218153250122 x_{0} x_{1} + 9.30027648115624 \\cdot 10^{-18} x_{0} x_{2}^{5} + 1.40202139569885 \\cdot 10^{-16} x_{0} x_{2}^{4} + 0.196816648150011 x_{0} x_{2}^{3} - 0.520113025199358 x_{0} x_{2}^{2} + 0.266472942657378 x_{0} x_{2} + 0.17421012991701 x_{0} + 9.6587049865152 \\cdot 10^{-18} x_{1}^{6} - 4.10494961926896 \\cdot 10^{-17} x_{1}^{5} x_{2} + 7.72696398921216 \\cdot 10^{-17} x_{1}^{5} + 4.8293524932576 \\cdot 10^{-17} x_{1}^{4} x_{2}^{2} - 7.72696398921216 \\cdot 10^{-17} x_{1}^{4} x_{2} + 0.141799855637808 x_{1}^{4} - 1.93174099730304 \\cdot 10^{-17} x_{1}^{3} x_{2}^{3} - 1.93174099730304 \\cdot 10^{-16} x_{1}^{3} x_{2}^{2} - 0.311168249960423 x_{1}^{3} x_{2} + 0.249939163482498 x_{1}^{3} + 4.50337119996271 \\cdot 10^{-16} x_{1}^{2} x_{2}^{4} + 1.60817438025478 \\cdot 10^{-15} x_{1}^{2} x_{2}^{3} + 0.34011554110888 x_{1}^{2} x_{2}^{2} - 0.102939136514011 x_{1}^{2} x_{2} + 0.671511677094302 x_{1}^{2} - 7.74205571575359 \\cdot 10^{-17} x_{1} x_{2}^{5} - 3.48920717637862 \\cdot 10^{-16} x_{1} x_{2}^{4} - 0.126802862844654 x_{1} x_{2}^{3} + 0.375850587154057 x_{1} x_{2}^{2} - 0.243797669999287 x_{1} x_{2} + 0.0665729373707557 x_{1} - 7.2440287398864 \\cdot 10^{-18} x_{2}^{6} + 3.25415353549584 \\cdot 10^{-17} x_{2}^{5} + 0.0753922499719916 x_{2}^{4} - 0.144561150709131 x_{2}^{3} + 0.0319114359028648 x_{2}^{2} + 0.00798012960396319 x_{2} + 0.11710543118272}\\)\n\n\nTo get M, we need the max value of \\(f\\).\n\n\n\nmax_value\n\n max_value (expr, bounds)\n\n\nmax_value(g, bounds = (-1,1))\n\n19.570601051506028\n\n\n\n\n\nrejection_sample_from_surface\n\n rejection_sample_from_surface (F, n_points, bounds=[-1, 1],\n                                batch_size=1024, verbose=False)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nF\n\n\na sympy matrix of size \\(N \\times 1\\) representing a surface\n\n\nn_points\n\n\nnumber of points to sample\n\n\nbounds\nlist\n[-1, 1]\nbounds for each variable\n\n\nbatch_size\nint\n1024\nnumber of points to test sampling at a time\n\n\nverbose\nbool\nFalse\n\n\n\n\n\nX = rejection_sample_from_surface(f, 1000)\nplot_3d(X,X[:,-1], use_plotly=True)"
  },
  {
    "objectID": "library/Random Surfaces.html#sanity-check-on-torus",
    "href": "library/Random Surfaces.html#sanity-check-on-torus",
    "title": "Random Surfaces",
    "section": "Sanity Check on Torus",
    "text": "Sanity Check on Torus\n\ntheta = sp.Symbol('theta')\nphi = sp.Symbol('phi')\nR = 2\nr = 1\nF_torus = sp.Matrix([(R + r*sp.cos(theta))*sp.cos(phi), (R + r*sp.cos(theta))*sp.sin(phi), r*sp.sin(theta)])\n\n\nG_torus = manifold_density(F_torus, [theta, phi])\nG_torus\n\n\\(\\displaystyle \\sqrt{\\sin^{4}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} \\cos^{2}{\\left(\\theta \\right)} + 4 \\sin^{4}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} \\cos{\\left(\\theta \\right)} + 4 \\sin^{4}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} + 2 \\sin^{2}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} \\cos^{2}{\\left(\\phi \\right)} \\cos^{2}{\\left(\\theta \\right)} + 8 \\sin^{2}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} \\cos^{2}{\\left(\\phi \\right)} \\cos{\\left(\\theta \\right)} + 8 \\sin^{2}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} \\cos^{2}{\\left(\\phi \\right)} + \\sin^{2}{\\left(\\phi \\right)} \\cos^{4}{\\left(\\theta \\right)} + 4 \\sin^{2}{\\left(\\phi \\right)} \\cos^{3}{\\left(\\theta \\right)} + 4 \\sin^{2}{\\left(\\phi \\right)} \\cos^{2}{\\left(\\theta \\right)} + \\sin^{2}{\\left(\\theta \\right)} \\cos^{4}{\\left(\\phi \\right)} \\cos^{2}{\\left(\\theta \\right)} + 4 \\sin^{2}{\\left(\\theta \\right)} \\cos^{4}{\\left(\\phi \\right)} \\cos{\\left(\\theta \\right)} + 4 \\sin^{2}{\\left(\\theta \\right)} \\cos^{4}{\\left(\\phi \\right)} + \\cos^{2}{\\left(\\phi \\right)} \\cos^{4}{\\left(\\theta \\right)} + 4 \\cos^{2}{\\left(\\phi \\right)} \\cos^{3}{\\left(\\theta \\right)} + 4 \\cos^{2}{\\left(\\phi \\right)} \\cos^{2}{\\left(\\theta \\right)}}\\)\n\n\n\nX_torus = rejection_sample_from_surface(F_torus, 2000, bounds=[0, 2*np.pi], verbose=True)\n\nHey, just woke up\nComputed f, M, g\nComputed bouncer np\ncomputed sample candidates\ncomputed bouncer results\nPoints added 666 for a total of 667\ncomputed sample candidates\ncomputed bouncer results\nPoints added 692 for a total of 1359\ncomputed sample candidates\ncomputed bouncer results\nPoints added 677 for a total of 2036\n\n\n\nfrom diffusion_curvature.hickok import KDE\n\n\nkde_density = KDE(2, X=X_torus)\ndensity = kde_density.density()\n\n\nplot_3d(X_torus, density, colorbar=True)\n\n\n\n\nAs hoped, the density differences between the outside and inside are negligible."
  },
  {
    "objectID": "library/Random Surfaces.html#sanity-check-on-sphere",
    "href": "library/Random Surfaces.html#sanity-check-on-sphere",
    "title": "Random Surfaces",
    "section": "Sanity Check on Sphere",
    "text": "Sanity Check on Sphere\nTo ensure that our curvature computation is working as expected, here’s the computation on the upper half of a sphere.\n\n# a sympy function giving the parametrization of the upper half of a sphere in terms of x and y\n# creata sympy variables x and y\nx = sp.Symbol('x')\ny = sp.Symbol('y')\nrs = np.array([1,2,3,4,5,6])\nks = []\nfor r in rs:\n    F_sphere = sp.Matrix([x, y, sp.sqrt(r**2 - (x)**2 - (y)**2)])\n    X_sphere = rejection_sample_from_surface(F_sphere, 1000, bounds=[-0.6,0.6])\n    k_sphere = scalar_curvature_at_origin(F_sphere)\n    ks.append(k_sphere)\n\n\nplot_3d(X_sphere)\n\n\n\n\n\nassert np.allclose(np.array(ks), 2/rs**2)"
  },
  {
    "objectID": "library/Graphs.html",
    "href": "library/Graphs.html",
    "title": "Graph Creation Utils",
    "section": "",
    "text": "get_umap_graph\n\n get_umap_graph (X, knn=5, **kwargs)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\n\n\n\n\n\nknn\nint\n5\nknn default to 15 in UMAP\n\n\nkwargs\n\n\n\n\n\n\n\n\n\nget_scanpy_graph\n\n get_scanpy_graph (X, knn=5, **kwargs)\n\n\n\n\nget_alpha_decay_graph\n\n get_alpha_decay_graph (X, knn:int=5, decay:float=40.0,\n                        anisotropy:float=0, n_pca:int=None, **kwargs)\n\n\n\n\nget_knn_graph\n\n get_knn_graph (X, knn=5, **kwargs)\n\n\n\n\ndiff_aff\n\n diff_aff (graph)\n\nCompute the diffusion affinity for a pygsp graph.\n\n\n\nkernel_degree\n\n kernel_degree (graph)\n\nCompute the kernel degree for a pygsp graph.\n\n\n\ndiff_op\n\n diff_op (graph)\n\nCompute the diffusion operator for a pygsp graph.\n\n\nThe Differentiable Kernel\n\n\ngeneric_kernel\n\n generic_kernel (D, sigma, anisotropic_density_normalization)\n\n\n\n\n\nDetails\n\n\n\n\nD\ndistance matrix\n\n\nsigma\nkernel bandwidth\n\n\nanisotropic_density_normalization\n\n\n\n\n\n\n\ndiffusion_matrix_from_affinities\n\n diffusion_matrix_from_affinities (W)\n\n\nfrom diffusion_curvature.utils import random_jnparray\nfrom diffusion_curvature.distances import pairwise_euclidean\n\n\nX = random_jnparray(100,9)\nD = pairwise_euclidean(X,X)\nW = generic_kernel(D,0.7,0.5)\nP = diffusion_matrix_from_affinities(W)\n\n\nimport jax.numpy as jnp\n\n\njnp.max(jnp.array([1, 0.4, 1, 3])/jnp.array([1e-8,1,1,1]))\n\nArray(1.e+08, dtype=float32)\n\n\n\njnp.array([1, 0.4, 1, 3])/jnp.array([0,1,1,1])\n\nArray([inf, 0.4, 1. , 3. ], dtype=float32)\n\n\n\n\n\nGraph Testing\n\nfrom diffusion_curvature.datasets import *\nfrom diffusion_curvature.utils import *\nfrom diffusion_curvature.heat_diffusion import *\n\n\nX_torus,ks = torus(5000,use_guide_points=True)\n\n\nG_torus = get_alpha_decay_graph(X_torus, decay=None, knn=30, anisotropy=1, )\nP = diff_op(G_torus).todense() # is sparse, by default\nP = jnp.array(P)\nPt = jax_power_matrix(P,30)\nplot_3d(X_torus, P[0])\n\n\n\n\n\nplot_3d(X_torus, G_torus.P[0].toarray())\n\n\n\n\n\nnp.allclose(diff_op(G_torus).toarray(), G_torus.P.toarray())\n\nFalse\n\n\n\nA = G_torus.K.toarray()\nP_homemade = diffusion_matrix_from_affinities(A)\n\n\nnp.allclose(P_homemade, G_torus.P.toarray(), atol=1e-4)\n\nTrue\n\n\n\nP_homemade\n\nArray([[0.0334698 , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.03510092, 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.03167431, ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.03027344, 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.03521152,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.03522947]], dtype=float32)\n\n\n\nG_torus.P.toarray()\n\narray([[0.03346897, 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.03508904, 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.03166429, ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.03027342, 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.03520697,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.03523469]])\n\n\n\nP\n\nArray([[0.96891046, 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.9683374 , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.9701013 , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.9696673 , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.9694721 ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.96949625]], dtype=float32)\n\n\n\nG_torus.K.toarray()\n\narray([[0.00111111, 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.00118906, 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.00100781, ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.00097656, 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.0011491 ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.0011491 ]])\n\n\n\n!nbdev_export\n\n/usr/bin/bash: line 1: nbdev_export: command not found"
  },
  {
    "objectID": "library/Curvature Enhanced Spectral Clustering.html",
    "href": "library/Curvature Enhanced Spectral Clustering.html",
    "title": "1d Curvature Clustering",
    "section": "",
    "text": "Our comparison space fitting is, unfortunately, too expensive to perform on every node of the graph. It presently take 10-20s to fit a comparison space; even if this were reduced 10 fold, a 5000 node graph would take over an hour. Much of this computation would be redundant, as the spreads of diffusion of neighboring points change little, and they could easily reuse the same comparison space. Indeed, whole neighborhoods of the graph should be able to reuse the same comparison space. But what constitutes a neighborhood? And how do you ensure that the district lines don’t divide up regions of homogenous curvature? Imagine, for example, two spheres joined by a sinuous bridge. Normal clustering algorithms would divide the bridge in half. We want the bridge to be in its own cluster.\nTo achieve this, we augment the well-known method of spectral clustering by supplementing its eigencoordinates with a new dimension: the unsigned curvature.\n\n\nenhanced_spectral_clustering\n\n enhanced_spectral_clustering (G, ks, dim, num_clusters,\n                               curvature_weighting=1)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nG\n\n\nPyGSP graph, or another with laplacian matrix L\n\n\nks\n\n\nunsigned magnitude of curvature\n\n\ndim\n\n\nintrinsic dimension of manifold (averaged across graph)\n\n\nnum_clusters\n\n\n\n\n\ncurvature_weighting\nint\n1\n\n\n\n\n\nfrom diffusion_curvature.core import get_adaptive_graph\n\n\nX_torus, ks_torus = torus(5000)\nG_torus = get_adaptive_graph(X_torus) #get_alpha_decay_graph(X_torus, knn=10, decay=20, anisotropy=0.5)\n\n\nn=3\nclusters = enhanced_spectral_clustering(G_torus, ks_torus, dim=2, num_clusters=n)\nclusters_plain= enhanced_spectral_clustering(G_torus, ks_torus, dim=2, num_clusters=n, curvature_weighting=0)\nfig = plt.figure(figsize=(16,8))\n\n# plot the torus in 3D colored by its clustering\nax1 = fig.add_subplot(121, projection='3d')\nax1.scatter(X_torus[:,0], X_torus[:,1], X_torus[:,2], c=clusters_plain, cmap='plasma')\nax1.set_title(f'Clustered Torus with n={n}')\nax1.set_box_aspect([np.ptp(X_torus[:,0]), np.ptp(X_torus[:,1]), np.ptp(X_torus[:,2])])\nax1.set_xticklabels([])\nax1.set_yticklabels([])\nax1.set_zticklabels([])\n\n# plot the torus in 3D colored by the curvature\nax2 = fig.add_subplot(122, projection='3d')\nax2.scatter(X_torus[:,0], X_torus[:,1], X_torus[:,2], c=clusters, cmap='plasma')\nax2.set_title(f'Curvature Clustered Torus with n={n}')\nax2.set_box_aspect([np.ptp(X_torus[:,0]), np.ptp(X_torus[:,1]), np.ptp(X_torus[:,2])])\nax2.set_xticklabels([])\nax2.set_yticklabels([])\nax2.set_zticklabels([])\n\nplt.show()\n\n\n\n\n\nn=6\nclusters= enhanced_spectral_clustering(G_torus, ks_torus, dim=2, num_clusters=n)\nclusters_plain = enhanced_spectral_clustering(G_torus, ks_torus, dim=2, num_clusters=n, curvature_weighting=0)\nfig = plt.figure(figsize=(16,8))\n\n# plot the torus in 3D colored by its clustering\nax1 = fig.add_subplot(121, projection='3d')\nax1.scatter(X_torus[:,0], X_torus[:,1], X_torus[:,2], c=clusters_plain, cmap='plasma')\nax1.set_title(f'Clustered Torus with n={n}')\nax1.set_box_aspect([np.ptp(X_torus[:,0]), np.ptp(X_torus[:,1]), np.ptp(X_torus[:,2])])\nax1.set_xticklabels([])\nax1.set_yticklabels([])\nax1.set_zticklabels([])\n\n# plot the torus in 3D colored by the curvature\nax2 = fig.add_subplot(122, projection='3d')\nax2.scatter(X_torus[:,0], X_torus[:,1], X_torus[:,2], c=clusters, cmap='plasma')\nax2.set_title(f'Curvature Clustered Torus with n={n}')\nax2.set_box_aspect([np.ptp(X_torus[:,0]), np.ptp(X_torus[:,1]), np.ptp(X_torus[:,2])])\nax2.set_xticklabels([])\nax2.set_yticklabels([])\nax2.set_zticklabels([])\n\nplt.show()\n\n\n\n\n\n# array of all idxs in cluster i\ncluster_idxs = [jnp.where(clusters==i)[0] for i in range(n)]\n\n\njnp.where(clusters==0)[0]\n\nArray([   0,   11,   15,   27,   34,   38,   41,   47,   71,   73,   75,\n         78,   81,   88,   90,   93,   99,  113,  115,  116,  122,  132,\n        141,  146,  150,  151,  152,  156,  161,  173,  183,  184,  190,\n        195,  196,  203,  223,  224,  238,  243,  244,  247,  264,  282,\n        283,  292,  293,  308,  309,  312,  317,  328,  338,  339,  344,\n        345,  352,  354,  357,  364,  367,  368,  371,  376,  377,  386,\n        392,  394,  397,  405,  408,  409,  413,  418,  428,  434,  435,\n        442,  443,  445,  455,  460,  466,  479,  481,  487,  488,  499,\n        510,  514,  516,  533,  534,  537,  541,  555,  561,  574,  579,\n        580,  587,  593,  595,  596,  598,  599,  603,  605,  607,  622,\n        623,  631,  639,  654,  662,  665,  667,  672,  681,  687,  707,\n        715,  725,  727,  730,  731,  732,  738,  745,  747,  750,  752,\n        758,  763,  768,  777,  782,  786,  792,  795,  804,  811,  813,\n        820,  822,  824,  838,  848,  851,  855,  856,  860,  863,  868,\n        883,  888,  897,  898,  899,  903,  905,  907,  920,  921,  928,\n        936,  939,  942,  944,  945,  956,  971,  982,  997, 1003, 1012,\n       1017, 1019, 1036, 1038, 1055, 1061, 1069, 1076, 1079, 1090, 1092,\n       1096, 1100, 1121, 1122, 1129, 1155, 1160, 1165, 1166, 1169, 1171,\n       1179, 1187, 1193, 1199, 1207, 1208, 1212, 1213, 1217, 1221, 1223,\n       1231, 1233, 1237, 1243, 1253, 1254, 1259, 1260, 1263, 1272, 1274,\n       1276, 1282, 1285, 1289, 1297, 1303, 1307, 1330, 1332, 1338, 1340,\n       1344, 1353, 1354, 1356, 1358, 1360, 1375, 1384, 1389, 1392, 1393,\n       1400, 1403, 1410, 1411, 1420, 1424, 1426, 1428, 1429, 1433, 1437,\n       1438, 1443, 1449, 1470, 1471, 1472, 1475, 1476, 1483, 1488, 1492,\n       1495, 1496, 1501, 1502, 1514, 1520, 1522, 1527, 1533, 1535, 1536,\n       1550, 1558, 1559, 1560, 1566, 1571, 1595, 1600, 1604, 1606, 1611,\n       1613, 1615, 1618, 1623, 1625, 1626, 1632, 1641, 1644, 1654, 1668,\n       1681, 1684, 1685, 1691, 1692, 1694, 1701, 1705, 1709, 1712, 1725,\n       1731, 1733, 1734, 1747, 1753, 1754, 1755, 1757, 1768, 1772, 1785,\n       1787, 1788, 1790, 1791, 1796, 1797, 1801, 1805, 1807, 1808, 1814,\n       1815, 1825, 1834, 1843, 1856, 1862, 1864, 1867, 1872, 1878, 1906,\n       1914, 1919, 1922, 1924, 1927, 1928, 1945, 1946, 1953, 1956, 1965,\n       1970, 1973, 1985, 1987, 1993, 1997, 2006, 2010, 2020, 2023, 2032,\n       2036, 2037, 2039, 2043, 2047, 2057, 2062, 2065, 2068, 2076, 2085,\n       2087, 2093, 2095, 2099, 2103, 2106, 2112, 2121, 2133, 2135, 2154,\n       2155, 2160, 2166, 2168, 2169, 2174, 2177, 2182, 2218, 2224, 2232,\n       2241, 2242, 2247, 2255, 2257, 2270, 2277, 2278, 2290, 2305, 2318,\n       2320, 2328, 2329, 2334, 2346, 2350, 2357, 2364, 2371, 2375, 2379,\n       2382, 2397, 2399, 2403, 2419, 2424, 2428, 2436, 2437, 2439, 2443,\n       2445, 2446, 2448, 2456, 2458, 2462, 2466, 2467, 2469, 2477, 2479,\n       2480, 2483, 2487, 2498, 2501, 2505, 2507, 2512, 2513, 2517, 2518,\n       2523, 2537, 2539, 2541, 2545, 2546, 2548, 2558, 2561, 2565, 2571,\n       2572, 2579, 2581, 2588, 2590, 2596, 2605, 2608, 2633, 2635, 2641,\n       2642, 2648, 2652, 2658, 2659, 2680, 2685, 2687, 2688, 2691, 2695,\n       2702, 2708, 2709, 2711, 2721, 2724, 2734, 2738, 2745, 2749, 2751,\n       2753, 2760, 2764, 2765, 2776, 2777, 2784, 2785, 2787, 2790, 2791,\n       2796, 2802, 2804, 2805, 2808, 2813, 2815, 2816, 2820, 2824, 2841,\n       2843, 2851, 2855, 2877, 2878, 2879, 2890, 2894, 2900, 2902, 2921,\n       2925, 2935, 2936, 2938, 2939, 2948, 2955, 2957, 2959, 2962, 2968,\n       2970, 2975, 2976, 2982, 2987, 2999, 3006, 3009, 3014, 3019, 3022,\n       3025, 3034, 3056, 3058, 3063, 3070, 3078, 3090, 3099, 3104, 3113,\n       3117, 3126, 3127, 3137, 3139, 3154, 3157, 3171, 3172, 3177, 3188,\n       3190, 3192, 3198, 3202, 3203, 3205, 3208, 3236, 3241, 3244, 3247,\n       3253, 3256, 3262, 3264, 3272, 3279, 3285, 3287, 3288, 3289, 3290,\n       3293, 3297, 3299, 3314, 3326, 3334, 3337, 3343, 3347, 3363, 3382,\n       3383, 3386, 3388, 3394, 3398, 3409, 3413, 3420, 3424, 3427, 3438,\n       3440, 3443, 3451, 3457, 3462, 3469, 3482, 3483, 3485, 3486, 3487,\n       3489, 3491, 3492, 3510, 3513, 3515, 3517, 3518, 3548, 3551, 3553,\n       3559, 3562, 3567, 3568, 3574, 3582, 3583, 3586, 3591, 3597, 3601,\n       3603, 3614, 3617, 3629, 3647, 3650, 3661, 3663, 3674, 3675, 3681,\n       3691, 3697, 3699, 3700, 3711, 3715, 3722, 3723, 3726, 3737, 3741,\n       3744, 3756, 3758, 3766, 3776, 3780, 3783, 3792, 3800, 3802, 3806,\n       3819, 3827, 3829, 3830, 3831, 3832, 3842, 3848, 3851, 3865, 3871,\n       3885, 3887, 3890, 3898, 3903, 3907, 3920, 3927, 3936, 3939, 3941,\n       3942, 3946, 3948, 3949, 3952, 3956, 3958, 3959, 3961, 3964, 3965,\n       3968, 3971, 3975, 3976, 3978, 3980, 3987, 3988, 3990, 4002, 4003,\n       4009, 4010, 4012, 4017, 4019, 4028, 4030, 4033, 4039, 4043, 4046,\n       4049, 4058, 4061, 4063, 4068, 4069, 4074, 4079, 4086, 4091, 4092,\n       4095, 4099, 4100, 4103, 4104, 4113, 4114, 4122, 4128, 4131, 4136,\n       4143, 4148, 4151, 4156, 4157, 4158, 4168, 4169, 4173, 4178, 4188,\n       4194, 4197, 4198, 4210, 4218, 4221, 4239, 4247, 4253, 4256, 4272,\n       4288, 4294, 4301, 4307, 4309, 4316, 4325, 4326, 4332, 4334, 4337,\n       4339, 4340, 4348, 4349, 4351, 4360, 4361, 4368, 4379, 4380, 4385,\n       4387, 4390, 4391, 4400, 4402, 4408, 4411, 4413, 4422, 4424, 4428,\n       4443, 4444, 4447, 4451, 4458, 4470, 4475, 4479, 4480, 4490, 4493,\n       4494, 4502, 4503, 4513, 4514, 4517, 4521, 4523, 4524, 4527, 4535,\n       4538, 4539, 4546, 4548, 4552, 4555, 4557, 4569, 4573, 4574, 4576,\n       4584, 4602, 4605, 4609, 4620, 4631, 4633, 4634, 4641, 4643, 4655,\n       4658, 4663, 4670, 4673, 4675, 4688, 4699, 4715, 4718, 4724, 4728,\n       4740, 4746, 4757, 4758, 4759, 4765, 4770, 4772, 4776, 4780, 4781,\n       4784, 4793, 4802, 4806, 4808, 4809, 4814, 4816, 4830, 4834, 4837,\n       4841, 4851, 4860, 4864, 4891, 4893, 4897, 4911, 4912, 4917, 4928,\n       4930, 4931, 4937, 4948, 4950, 4955, 4958, 4964, 4969, 4971, 4972,\n       4973, 4981, 4984, 4985, 4991, 4996], dtype=int32)\n\n\n\n!nbdev_export"
  },
  {
    "objectID": "library/Manifold Distances.html",
    "href": "library/Manifold Distances.html",
    "title": "Manifold Distances",
    "section": "",
    "text": "Wasserstein Diffusion Curvature – despite the name – requires only manifold distances. This saves quite a bit of computation, but doesn’t alleviate the need for a good approximation of the manifold’s geodesic distance. Here, we implement one straightforward and accurate manifold distance: that proposed by Moon et al. in PHATE (2019). The PHATE distance is an extension of the diffusion distance, except instead of calculating the L2 distances between diffusion coordinates (which corresponds roughly to the rows of the diffusion matrix), it takes the L2 distances between the log-transformed diffusions. This flips the weighting from local to global, as a diffusion that assigns a small mass where another assigns a miniscule mass becomes much further than those that differ only at their centers. This log transform has the additional advantage of, through the WAWA formulation of the heat equation, recovering the distance term.\nIt is defined as: \\[d_p(x,y) = \\| \\log(p_y^t)-\\log(p_x^t) \\|_2 \\]\n\n\n\n\n phate_distances (G:&lt;function Graph&gt;)\n\n\n\n\n\n\n phate_distances_differentiable (Pt)\n\n\n\n\n\n\n pairwise_euclidean (x, y)\n\n\nA = random_jnparray(8,3)\nD = pairwise_euclidean(A,A)\n\nAssertionError: \n\n\n\nD.shape\n\n(8, 8)\n\n\n\nfrom diffusion_curvature.datasets import torus\nimport graphtools\n\n\nX_torus, torus_gaussian_curvature = torus(n=3000)\nG_torus = graphtools.Graph(X_torus)\nG_torus.Pt = G_torus.P ** 4\n\n\nG_torus = phate_distances(G_torus)\n\n\nG_torus.D\n\narray([[ 0.        , 93.7875039 , 94.59402414, ..., 92.54080119,\n        90.6213935 , 92.93120075],\n       [93.7875039 ,  0.        , 89.16673659, ..., 86.98550107,\n        84.94065264, 87.40071844],\n       [94.59402414, 89.16673659,  0.        , ..., 87.64808383,\n        85.61906139, 82.96883047],\n       ...,\n       [92.54080119, 86.98550107, 87.64808383, ...,  0.        ,\n        83.30204347, 85.8508315 ],\n       [90.6213935 , 84.94065264, 85.61906139, ..., 83.30204347,\n         0.        , 83.77829279],\n       [92.93120075, 87.40071844, 82.96883047, ..., 85.8508315 ,\n        83.77829279,  0.        ]])"
  },
  {
    "objectID": "library/Manifold Distances.html#phate-distances",
    "href": "library/Manifold Distances.html#phate-distances",
    "title": "Manifold Distances",
    "section": "",
    "text": "Wasserstein Diffusion Curvature – despite the name – requires only manifold distances. This saves quite a bit of computation, but doesn’t alleviate the need for a good approximation of the manifold’s geodesic distance. Here, we implement one straightforward and accurate manifold distance: that proposed by Moon et al. in PHATE (2019). The PHATE distance is an extension of the diffusion distance, except instead of calculating the L2 distances between diffusion coordinates (which corresponds roughly to the rows of the diffusion matrix), it takes the L2 distances between the log-transformed diffusions. This flips the weighting from local to global, as a diffusion that assigns a small mass where another assigns a miniscule mass becomes much further than those that differ only at their centers. This log transform has the additional advantage of, through the WAWA formulation of the heat equation, recovering the distance term.\nIt is defined as: \\[d_p(x,y) = \\| \\log(p_y^t)-\\log(p_x^t) \\|_2 \\]\n\n\n\n\n phate_distances (G:&lt;function Graph&gt;)\n\n\n\n\n\n\n phate_distances_differentiable (Pt)\n\n\n\n\n\n\n pairwise_euclidean (x, y)\n\n\nA = random_jnparray(8,3)\nD = pairwise_euclidean(A,A)\n\nAssertionError: \n\n\n\nD.shape\n\n(8, 8)\n\n\n\nfrom diffusion_curvature.datasets import torus\nimport graphtools\n\n\nX_torus, torus_gaussian_curvature = torus(n=3000)\nG_torus = graphtools.Graph(X_torus)\nG_torus.Pt = G_torus.P ** 4\n\n\nG_torus = phate_distances(G_torus)\n\n\nG_torus.D\n\narray([[ 0.        , 93.7875039 , 94.59402414, ..., 92.54080119,\n        90.6213935 , 92.93120075],\n       [93.7875039 ,  0.        , 89.16673659, ..., 86.98550107,\n        84.94065264, 87.40071844],\n       [94.59402414, 89.16673659,  0.        , ..., 87.64808383,\n        85.61906139, 82.96883047],\n       ...,\n       [92.54080119, 86.98550107, 87.64808383, ...,  0.        ,\n        83.30204347, 85.8508315 ],\n       [90.6213935 , 84.94065264, 85.61906139, ..., 83.30204347,\n         0.        , 83.77829279],\n       [92.93120075, 87.40071844, 82.96883047, ..., 85.8508315 ,\n        83.77829279,  0.        ]])"
  },
  {
    "objectID": "library/Diffusion Laziness.html",
    "href": "library/Diffusion Laziness.html",
    "title": "Diffusion Laziness Estimators",
    "section": "",
    "text": "Wasserstein Spread of Diffusion\n\n\nwasserstein_spread_of_diffusion\n\n wasserstein_spread_of_diffusion (D, Pt)\n\nReturns how “spread out” each diffusion is, with wasserstein distance Presumes that the manifold distances have been separately calculated\n\n\n\n\nDetails\n\n\n\n\nD\nmanifold geodesic distances\n\n\nPt\npowered diffusion matrix/t-step ehat diffusions\n\n\n\n\n\nBenchmarking\n\nD = np.random.rand(1000,1000)\nPt = np.random.rand(1000,1000)\nPt = Pt / np.sum(Pt, axis=1)[:,None]\n\n\nwasserstein_spread_of_diffusion(D,Pt)\n\n1.82 ms ± 131 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nkey = jax.random.PRNGKey(0)\nDjax = jax.random.normal(key, (1000, 1000))\nkey = jax.random.PRNGKey(10)\nPtjax = jax.random.normal(key, (1000, 1000))\n\n\njnp.allclose(Djax,Ptjax)\n\nArray(False, dtype=bool)\n\n\n\nwasserstein_spread_of_diffusion(Djax,Ptjax)\n\n20.4 µs ± 126 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n\n\nWow, it’s nearly two orders of magnitude faster when using jax arrays.\n\n\n\nEntropy of Diffusion\n\n\nentropy_of_diffusion\n\n entropy_of_diffusion (Pt, epsilon=1e-05)\n\nReturns the pointwise entropy of diffusion from the powered diffusion matrix in the input Assumes that Pt sums to 1\n\nfrom scipy.stats import entropy\n\n\nassert jnp.allclose(entropy_of_diffusion(Pt),entropy(Pt,axis=1))\n\nAssertionError: \n\n\n\njnp.sum(Pt, axis=-1)[:,None]\n\nArray([[1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [0.9999999 ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.0000001 ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.0000001 ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.0000001 ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.9999999 ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.9999999 ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [0.99999994],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ],\n       [1.        ]], dtype=float32)"
  },
  {
    "objectID": "library/Utils.html",
    "href": "library/Utils.html",
    "title": "Utils",
    "section": "",
    "text": "Most are self explanatory. A small description is appended to those that aren’t.\n\n\nkronecker_delta\n\n kronecker_delta (length, idx=None)\n\nreturns np array of len with all zeroes except idx.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlength\n\n\nlength of array. If you pass an array or list, length is set to size of the first dimension.\n\n\nidx\nNoneType\nNone\nidx to make nonzero. If none, fills a random idx.\n\n\n\n\n\n\nplot_3d\n\n plot_3d (X, distribution=None, title='', lim=None, use_plotly=False,\n          zlim=None, colorbar=False, cmap='plasma')\n\n\n\n\nperform_trials\n\n perform_trials (f, n_trials=10, n_workers=12, pause=0, method=None,\n                 threadpool=False, **kwargs)\n\nAn adaptation of fastcore’s parallel for running the same function multiple times.\n\ndef afn(a=9,b=3):\n    return a*b\nperform_trials(afn,n_trials=10,n_workers=2,a=4,b=10)\n\nfinished future submissions\ngot a result 40\ngot a result 40\ngot a result 40\ngot a result 40\ngot a result 40\ngot a result 40\ngot a result 40\ngot a result 40\ngot a result 40\ngot a result 40\n\n\n\n\n\n[40, 40, 40, 40, 40, 40, 40, 40, 40, 40]\n\n\n\n\n\nplot_array\n\n plot_array (ratios, xs=None, title='')\n\n\n\n\nrandom_jnparray\n\n random_jnparray (*shape)"
  },
  {
    "objectID": "experiments/Neumann Heat Kernel via Chebyshev Approximation.html",
    "href": "experiments/Neumann Heat Kernel via Chebyshev Approximation.html",
    "title": "Analytic estimation of the heat kernel",
    "section": "",
    "text": "&lt;style&gt;body {font-family:Baskerville}&lt;/style&gt;"
  },
  {
    "objectID": "experiments/Neumann Heat Kernel via Chebyshev Approximation.html#philosophy",
    "href": "experiments/Neumann Heat Kernel via Chebyshev Approximation.html#philosophy",
    "title": "Analytic estimation of the heat kernel",
    "section": "Philosophy",
    "text": "Philosophy\nThe graph diffusion matrix \\(P\\) is one means of approximating the heat kernel, which has seen repeated empirical success in methods like Diffusion Maps, PHATE, Diffusion Condensation, etc. Yet, \\(P\\)’s approximation of heat diffusion is fairly crude. All it does is normalize the adjacency matrix, which leaves it awfully dependent on how we parameterize that matrix. A wonky kernel bandwidth or unsatisfactory density normalization leaves \\(P\\) stranded.\nCoifman et al. have proven that \\(P^t\\) converges to the Neumann heat kernel on the manifold as \\(t \\to 0\\), which is to say: locally, it’s perfectly fine. But in practice, \\(P\\) isn’t used with really small powers of \\(t\\), and the kernel bandwidth is usually large enough that a single step of diffusion extends haphazardly across the manifold, with decay determined by unreliable euclidean distances. This can be avoided by restricting a single step of diffusion to a single neighborhood - but in this case, powering \\(P\\) to the needed global reach becomes prohibitive.\nIn this notebook, we implement and experiment with an alternate estimation of the heat kernel. This was used by Huguet et al’s A Heat Diffusion Perspective on Geodesic Preserving Dimensionality Reduction. The implementation is adapted from the authors’ source code KrishnaswamyLab/HeatGeo: Embedding with the Heat-geodesic dissimilarity. But, following Knuth’s guidance on code reuse, we strip it out of the framework and reimplement the pieces ourselves, to escape ‘dependency heck’."
  },
  {
    "objectID": "experiments/Neumann Heat Kernel via Chebyshev Approximation.html#implementation-outline",
    "href": "experiments/Neumann Heat Kernel via Chebyshev Approximation.html#implementation-outline",
    "title": "Analytic estimation of the heat kernel",
    "section": "Implementation Outline",
    "text": "Implementation Outline\n\n\nexpm_multiply\n\n expm_multiply (L:numpy.ndarray, X:numpy.ndarray, phi:float, tau,\n                K:int=None, err:float=1e-32)\n\nComputes the exp(tL)X for each t in tau. If L is the graph laplacian, this is heat diffusion applied to X.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nL\nndarray\n\nThe graph laplacian. or another PSD matrix with max eval &lt;= 2\n\n\nX\nndarray\n\nThe signal to diffuse\n\n\nphi\nfloat\n\nl_max/2, where l_max is the largest eigenvalue of L. PyGSP has a method to compute this easily.\n\n\ntau\n\n\nDiffusion times, either as a single float/int, or a list/ndarray of floats/ints\n\n\nK\nint\nNone\nThe number of polynomial terms to use in the approximation. If None, calculates the least number that guarantees precision of err.\n\n\nerr\nfloat\n1e-32\nPrecision\n\n\n\n\n\n\ncompute_chebychev_coeff_all\n\n compute_chebychev_coeff_all (phi, tau, K)\n\nCompute the K+1 Chebychev coefficients for our functions.\n\n\n\nreverse_bound\n\n reverse_bound (f, phi, x, tau, err)\n\nReturns the minimal K such that f(phi, x, tau, K) &lt;= err.\n\n\n\nget_bound_bergamaschi_specific\n\n get_bound_bergamaschi_specific (phi, x, tau, K)\n\n\n\n\nget_bound_bergamaschi_generic\n\n get_bound_bergamaschi_generic (phi, x, tau, K)\n\n\n\n\nE\n\n E (K, C)\n\n\n\n\nget_bound_eta_specific\n\n get_bound_eta_specific (phi, x, tau, K)\n\n\n\n\nget_bound_eta_generic\n\n get_bound_eta_generic (phi, x, tau, K)\n\n\n\n\nget_bound_eps_generic\n\n get_bound_eps_generic (phi, x, tau, K)\n\n\n\n\ng\n\n g (K, C)\n\nHere’s an example of how to use this.\n\nfrom diffusion_curvature.datasets import torus\nfrom diffusion_curvature.graphs import *\n\n\nX, ks = torus(2000)\nG_torus = get_alpha_decay_graph(X)\n\nTo use expm_multiply, we need: 1. The graph laplacian 2. An estimate of the largest eigenvalue (e.g. from PyGSP) 3. The diffusion times\nFor convenience, here’s a wrapper that does all of this for a PyGSP graph and signal.\n\n\n\nheat_diffusion_on_signal\n\n heat_diffusion_on_signal (G:pygsp.graphs.graph.Graph, x:numpy.ndarray, t)\n\nReturns the heat-diffused signal. Uses chebyshev approximation of exp(-tL).\n\n\n\n\nType\nDetails\n\n\n\n\nG\nGraph\nThe graph on which to diffuse heat\n\n\nx\nndarray\nThe signal to diffuse\n\n\nt\n\ntime of diffusion, or list of times\n\n\n\n\n\n\nkronecker_delta\n\n kronecker_delta (length, idx=None)\n\nreturns np array of len with all zeroes except idx.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlength\n\n\nlength of array. If you pass an array or list, length is set to size of the first dimension.\n\n\nidx\nNoneType\nNone\nidx to make nonzero. If none, fills a random idx.\n\n\n\n\ndiffused_diracs = heat_diffusion_on_signal(G_torus,kronecker_delta(X),[4,8,12])\n\n\nplot_3d(X,diffused_diracs[2])"
  },
  {
    "objectID": "experiments/Neumann Heat Kernel via Chebyshev Approximation.html#estimation-of-euclidean-heat",
    "href": "experiments/Neumann Heat Kernel via Chebyshev Approximation.html#estimation-of-euclidean-heat",
    "title": "Analytic estimation of the heat kernel",
    "section": "Estimation of Euclidean heat",
    "text": "Estimation of Euclidean heat"
  },
  {
    "objectID": "experiments/Curvature by Quadratic Fitting.html",
    "href": "experiments/Curvature by Quadratic Fitting.html",
    "title": "Scalar Curvature by Volume Comparison",
    "section": "",
    "text": "In our ‘Volume Estimation’ notebook, we saw that self-diffusion can provide a reasonable estimate of the volume of geodesic balls – at least on euclidean manifolds, and with a few caveats. Here, we take advantage of this by using a classical formula that relates the ratio of manifold volumes to euclidean volumes to the scalar curvature:\n\\[\n\\frac{\\operatorname{vol}\\left(B^M(x, r)\\right)}{\\operatorname{vol}\\left(B^E(r)\\right)}=1-\\frac{S(x)}{6(n+2)} r^2+\\mathcal{O}\\left(r^4\\right)\n\\]\nWe’re inspired here by Hickock’s 2023 method, which uses uses density estimation and shortest-path distances to estimate the manifold volume at several scales, and then fits a quadratic to the resulting ratios and extracts from it the scalar curvature. Diffusion has the potential to strengthen this process further, principally by reducing the reliance on shortest-path distances and density estimation. As a nice side effect, this enables Hickock’s method to be generalized to graphs that don’t come with attached point clouds.\ndef volume_ratio(A,B):\n    \"\"\"Removes constant offset from both A and B before taking ratio,\"\"\"\n    A = A + 1e-12 #- np.min(A) \n    B = B + 1e-12 #- np.min(B) \n    return A/B"
  },
  {
    "objectID": "experiments/Curvature by Quadratic Fitting.html#an-experiment-the-torus-in-detail",
    "href": "experiments/Curvature by Quadratic Fitting.html#an-experiment-the-torus-in-detail",
    "title": "Scalar Curvature by Volume Comparison",
    "section": "An experiment: the torus in detail",
    "text": "An experiment: the torus in detail\nThe torus contains regions of both negative and positive curvature, allowing us to examine how the method responds to each of these.\n\ndef ratios_of_torus(idx):\n    X, ks = torus(2000, use_guide_points=True)\n    knn = 10\n    anisotropy = 1\n    decay = 20\n    denoising = 5\n    G_torus = get_alpha_decay_graph(X,knn=knn, anisotropy=anisotropy,decay=decay)  \n    ts = globalts\n    torus_ratios = volume_comparisons_of_graph_at_idx(G_torus,idx,dim=2,ts=ts, knn=knn, anisotropy=anisotropy, decay=decay, denoising_scale=denoising)\n    return torus_ratios\n\nLet’s first see what diffusion on the torus looks like at the scale of our chosen ts.\n\nX, ks = torus(2000, use_guide_points=True)\nG_torus = get_alpha_decay_graph(X,knn=10, anisotropy=0.5,decay=20)\n\n\nfrom diffusion_curvature.heatkernel import heat_diffusion_on_signal\n\n\ndiffused_diracs = heat_diffusion_on_signal(G_torus,kronecker_delta(X,0),globalts)\nplot_3d(X,diffused_diracs[-1],title=\"Diffusion with Largest t\")\n\n\n\n\nThe diffusion is well contained within the region of curvature, hence this t value seems reasonable.\n\nfrom diffusion_curvature.utils import perform_trials\n\n\ntorus_ratios_in_bulk = np.array(\n    perform_trials(ratios_of_torus,n_trials=50, idx=0))\n\n\n\n\n\nplot_array(torus_ratios_in_bulk,np.sqrt(globalts), title=\"Positive Curvature on the torus (outer rim)\")\n\n\n\n\n\ntorus_ratios_in_bulk = np.array(\n    perform_trials(ratios_of_torus,n_trials=50, idx=1))\n\n\n\n\n\nplot_array(torus_ratios_in_bulk,np.sqrt(globalts), title=\"Negative Curvature on the torus (inner rim)\")"
  },
  {
    "objectID": "experiments/Curvature by Quadratic Fitting.html#experiment-with-different-manifolds",
    "href": "experiments/Curvature by Quadratic Fitting.html#experiment-with-different-manifolds",
    "title": "Scalar Curvature by Volume Comparison",
    "section": "Experiment with different manifolds",
    "text": "Experiment with different manifolds\n\nThe Saddle\n\nX, ks = paraboloid(5000, use_guide_points=True)\nplot_3d(X,ks,\"Saddle\")\n\n\n\n\n\ndef ratios_of_saddle(idx):\n    X, ks = paraboloid(5000, use_guide_points=True)\n    G = get_alpha_decay_graph(X,knn=10, anisotropy=0.5, decay=20)  \n    ts = globalts\n    h_ratios = volume_comparisons_of_graph_at_idx(G,idx,dim=2,ts=ts, knn=10, anisotropy=0.5, decay=20)\n    return h_ratios\n\n\nsaddle_ratios_in_bulk = np.array(\n    perform_trials(ratios_of_saddle,n_trials=50, idx=0))\n\n\n\n\n\nplot_array(saddle_ratios_in_bulk,np.sqrt(globalts),\"Volume Comparisons in middle of Saddle\")\n\n\n\n\n\n\nThe Sphere\n\ndef ratios_of_sphere(idx):\n    X, ks = sphere(2000, use_guide_points=True)\n    G = get_alpha_decay_graph(X,knn=10, decay=20, anisotropy=0.5)  \n    ts = globalts\n    h_ratios = volume_comparisons_of_graph_at_idx(G,idx,dim=2,ts=ts, decay=20, knn=10, anisotropy=0.5)\n    return h_ratios\n\n\nsphere_ratios_in_bulk = np.array(\n    perform_trials(ratios_of_sphere,n_trials=50, idx=0))\n\n\n\n\n\nplot_array(sphere_ratios_in_bulk,np.sqrt(globalts),\"Volume Comparisons on Sphere\")"
  },
  {
    "objectID": "experiments/3e1 Flattening with Diffusion Models.html",
    "href": "experiments/3e1 Flattening with Diffusion Models.html",
    "title": "3e1 Flattening with Diffusion Models",
    "section": "",
    "text": "X_sphere, ks_sphere = sphere(1000,use_guide_points=True) # keep it relatively sparse\nX_cap_of_sphere = X_sphere[X_sphere[:,2] &gt; 0] # Just the itty bitty polar top\nX_pca = X_cap_of_sphere[:,:2]\nplot_3d(X_cap_of_sphere)\n\n\n\n\n\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\n\nLambda = 2  # @param {type:\"slider\", min:1, max:50, step:1}\ntimesteps = 50\nts = np.linspace(0, 1, timesteps)\n# Generate random normal samples for the Wiener process\n# dw = np.concatenate([np.zeros((len(ts),2,1)), np.random.normal(0, np.sqrt(ts[1] - ts[0]), size=(len(ts), 2, len(X_pca)-1))],axis=-1)  # Three-dimensional array for multiple trajectories\ndw = np.concatenate([np.ones((len(ts),2,1)), 2*np.random.rand(len(ts), 2, len(X_pca)-1)],axis=-1)-1 # Three-dimensional array for multiple trajectories\n\n\n# Compute the diffusion process for multiple trajectories\nx = np.cumsum((Lambda**ts - 1)[:, None, None] * dw, axis=0) + X_pca.T[None, :, :]  # Broadcasting x0 to match the shape of dw\n\n\ni = 4\nprint(x[i][0][0],x[i][1][0])\n\n0.0 0.0\n\n\nWe’ll now run diffusion at each point along the way, capturing the (unsigned) diffusion curvatures.\n\nPs_at_ts = []\nuks_at_ts = []\nfor t in range(timesteps):\n    G_t = get_adaptive_graph(x[t].T)\n    DC = DiffusionCurvature(\n        laziness_method=\"Wasserstein\",\n        graph_former = get_adaptive_graph,\n    )\n    uks = DC.unsigned_curvature(G_t, t=10)\n    Ps_at_ts.append(DC.Pt)\n    uks_at_ts.append(uks[0])\n\n\nplt.scatter(X_pca[:,0],X_pca[:,1],c=Ps_at_ts[0][0])\nplt.title(\"PCA Projection of Sphere Neighborhood\")\n\nText(0.5, 1.0, 'PCA Projection of Sphere Neighborhood')\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport numpy as np\n\n\n# Assuming x is a numpy array of shape (50, 2, 164)\n# Set up the figure and axis for the animation\nfig, ax = plt.subplots()\n\ndef animate(i):\n    ax.clear()\n    ax.scatter(x[i, 0, :], x[i, 1, :], c = Ps_at_ts[i][0])\n    max = np.max(np.abs(x[i]))\n    ax.set_xlim(-max, max)\n    ax.set_ylim(-max, max)\n    ax.set_title(f\"t = {i}\")\n\n# Create the animation\nani = animation.FuncAnimation(fig, animate, frames=50, interval=400)\nfrom IPython.display import HTML\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\nWe’ll compare the diffusion entropies of this diffusion process with the entropy of diffusion on the sphere, and on plane.\n\nG_sphere = get_adaptive_graph(X_cap_of_sphere)\nDC = DiffusionCurvature(\n    laziness_method=\"Wasserstein\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    graph_former = get_adaptive_graph,\n)\nsphere_entropy = DC.unsigned_curvature(G_sphere, t=10)[0]\nsphere_entropy\n\nArray(30.332912, dtype=float32)\n\n\n\nplot_3d(X_cap_of_sphere,DC.Pt[0])\n\n\n\n\n\nDC.curvature(G_sphere,t=25,dim=2)[0]\n\nArray(-11.218405, dtype=float32)\n\n\n\nX_plane = plane(len(X_cap_of_sphere))\nG_plane = get_adaptive_graph(X_plane)\nplane_entropy = DC.unsigned_curvature(G_plane, t=10)[0]\nplane_entropy\n\nArray(33.120407, dtype=float32)\n\n\n\nplt.scatter(X_plane[:,0], X_plane[:,1], c=DC.Pt[0])\n\n&lt;matplotlib.collections.PathCollection at 0x7f70f80b7210&gt;\n\n\n\n\n\n\n# from diffusion_curvature.compute_mean_flat_entropies import average_flat_entropies\n# plane_entropy = average_flat_entropies(dim=2,t=10,num_trials=100, num_points_in_comparison=len(X_pca))\n\n\nplane_entropy\n\nArray(33.120407, dtype=float32)\n\n\n\nplt.plot(ts, np.ones_like(uks_at_ts)*plane_entropy, label = \"Base Euclidean\")\nplt.plot(ts, np.ones_like(uks_at_ts)*sphere_entropy, label = \"2-Sphere\")\nplt.plot(ts, uks_at_ts, label = \"Noising of PCA'd Sphere\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"W1 Spread of Diffusion\")\nplt.title(\"Diffusion Wasserstein of Noising Diffusion across Time\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nX_sphere, ks_sphere = paraboloid(1000,use_guide_points=True) # keep it relatively sparse\nX_cap_of_sphere = X_sphere[X_sphere[:,2] &gt; -1] # Just the itty bitty polar top\nX_pca = X_cap_of_sphere[:,:2]\nplot_3d(X_cap_of_sphere)\n\n\n\n\n\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\n\nLambda = 2  # @param {type:\"slider\", min:1, max:50, step:1}\ntimesteps = 50\nts = np.linspace(0, 1, timesteps)\n# Generate random normal samples for the Wiener process\n# dw = np.concatenate([np.zeros((len(ts),2,1)), np.random.normal(0, np.sqrt(ts[1] - ts[0]), size=(len(ts), 2, len(X_pca)-1))],axis=-1)  # Three-dimensional array for multiple trajectories\ndw = np.concatenate([np.ones((len(ts),2,1)), 2*np.random.rand(len(ts), 2, len(X_pca)-1)],axis=-1)-1 # Three-dimensional array for multiple trajectories\n\n\n# Compute the diffusion process for multiple trajectories\nx = np.cumsum((Lambda**ts - 1)[:, None, None] * dw, axis=0) + X_pca.T[None, :, :]  # Broadcasting x0 to match the shape of dw\n\n\ni = 4\nprint(x[i][0][0],x[i][1][0])\n\n0.0 0.0\n\n\nWe’ll now run diffusion at each point along the way, capturing the (unsigned) diffusion curvatures.\n\nPs_at_ts = []\nuks_at_ts = []\nfor t in range(timesteps):\n    G_t = get_adaptive_graph(x[t].T)\n    DC = DiffusionCurvature(\n        laziness_method=\"Wasserstein\",\n        graph_former = get_adaptive_graph,\n    )\n    uks = DC.unsigned_curvature(G_t, t=10)\n    Ps_at_ts.append(DC.Pt)\n    uks_at_ts.append(uks[0])\n\n\nplt.scatter(X_pca[:,0],X_pca[:,1],c=Ps_at_ts[0][0])\nplt.title(\"PCA Projection of Sphere Neighborhood\")\n\nText(0.5, 1.0, 'PCA Projection of Sphere Neighborhood')\n\n\n\n\n\n\n# Assuming x is a numpy array of shape (50, 2, 164)\n# Set up the figure and axis for the animation\nfig, ax = plt.subplots()\n\ndef animate(i):\n    ax.clear()\n    ax.scatter(x[i, 0, :], x[i, 1, :], c = Ps_at_ts[i][0])\n    max = np.max(np.abs(x[i]))\n    ax.set_xlim(-max, max)\n    ax.set_ylim(-max, max)\n    ax.set_title(f\"t = {i}\")\n\n# Create the animation\nani = animation.FuncAnimation(fig, animate, frames=50, interval=400)\nfrom IPython.display import HTML\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\nWe’ll compare the diffusion entropies of this diffusion process with the entropy of diffusion on the sphere, and on plane.\n\nG_sphere = get_adaptive_graph(X_cap_of_sphere, k=15)\nDC = DiffusionCurvature(\n    laziness_method=\"Wasserstein\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    graph_former = get_adaptive_graph,\n)\nsphere_entropy = DC.unsigned_curvature(G_sphere, t=25)[0]\nsphere_entropy\n\nArray(25.005825, dtype=float32)\n\n\n\nplot_3d(X_cap_of_sphere,DC.Pt[0])\n\n\n\n\n\nDC.curvature(G_sphere,t=25,dim=2)[0]\n\nArray(-35.839073, dtype=float32)\n\n\n\nX_plane = plane(len(X_cap_of_sphere), dim=2)\nG_plane = get_adaptive_graph(X_plane,k=15)\nDC = DiffusionCurvature(\n    laziness_method=\"Wasserstein\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    graph_former = get_adaptive_graph,\n)\nplane_entropy = DC.unsigned_curvature(G_plane, t=25)[0]\nplane_entropy\n\nArray(28.964823, dtype=float32)\n\n\n\nplt.scatter(X_plane[:,0], X_plane[:,1], c=DC.Pt[0])\n\n&lt;matplotlib.collections.PathCollection at 0x7f6fd0220990&gt;\n\n\n\n\n\n\n# from diffusion_curvature.compute_mean_flat_entropies import average_flat_entropies\n# plane_entropy = average_flat_entropies(dim=2,t=10,num_trials=100, num_points_in_comparison=len(X_pca))\n\n\nplane_entropy\n\nArray(40.152046, dtype=float32)\n\n\n\nplt.plot(ts, np.ones_like(uks_at_ts)*plane_entropy, label = \"Base Euclidean\")\nplt.plot(ts, np.ones_like(uks_at_ts)*sphere_entropy, label = \"2-Saddle\")\nplt.plot(ts, uks_at_ts, label = \"Noising of PCA'd Saddle\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"W1 Spread of Diffusion\")\nplt.title(\"Diffusion Wasserstein of Noising Diffusion across Time\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "experiments/3e1 Flattening with Diffusion Models.html#with-a-saddle",
    "href": "experiments/3e1 Flattening with Diffusion Models.html#with-a-saddle",
    "title": "3e1 Flattening with Diffusion Models",
    "section": "",
    "text": "X_sphere, ks_sphere = paraboloid(1000,use_guide_points=True) # keep it relatively sparse\nX_cap_of_sphere = X_sphere[X_sphere[:,2] &gt; -1] # Just the itty bitty polar top\nX_pca = X_cap_of_sphere[:,:2]\nplot_3d(X_cap_of_sphere)\n\n\n\n\n\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\n\nLambda = 2  # @param {type:\"slider\", min:1, max:50, step:1}\ntimesteps = 50\nts = np.linspace(0, 1, timesteps)\n# Generate random normal samples for the Wiener process\n# dw = np.concatenate([np.zeros((len(ts),2,1)), np.random.normal(0, np.sqrt(ts[1] - ts[0]), size=(len(ts), 2, len(X_pca)-1))],axis=-1)  # Three-dimensional array for multiple trajectories\ndw = np.concatenate([np.ones((len(ts),2,1)), 2*np.random.rand(len(ts), 2, len(X_pca)-1)],axis=-1)-1 # Three-dimensional array for multiple trajectories\n\n\n# Compute the diffusion process for multiple trajectories\nx = np.cumsum((Lambda**ts - 1)[:, None, None] * dw, axis=0) + X_pca.T[None, :, :]  # Broadcasting x0 to match the shape of dw\n\n\ni = 4\nprint(x[i][0][0],x[i][1][0])\n\n0.0 0.0\n\n\nWe’ll now run diffusion at each point along the way, capturing the (unsigned) diffusion curvatures.\n\nPs_at_ts = []\nuks_at_ts = []\nfor t in range(timesteps):\n    G_t = get_adaptive_graph(x[t].T)\n    DC = DiffusionCurvature(\n        laziness_method=\"Wasserstein\",\n        graph_former = get_adaptive_graph,\n    )\n    uks = DC.unsigned_curvature(G_t, t=10)\n    Ps_at_ts.append(DC.Pt)\n    uks_at_ts.append(uks[0])\n\n\nplt.scatter(X_pca[:,0],X_pca[:,1],c=Ps_at_ts[0][0])\nplt.title(\"PCA Projection of Sphere Neighborhood\")\n\nText(0.5, 1.0, 'PCA Projection of Sphere Neighborhood')\n\n\n\n\n\n\n# Assuming x is a numpy array of shape (50, 2, 164)\n# Set up the figure and axis for the animation\nfig, ax = plt.subplots()\n\ndef animate(i):\n    ax.clear()\n    ax.scatter(x[i, 0, :], x[i, 1, :], c = Ps_at_ts[i][0])\n    max = np.max(np.abs(x[i]))\n    ax.set_xlim(-max, max)\n    ax.set_ylim(-max, max)\n    ax.set_title(f\"t = {i}\")\n\n# Create the animation\nani = animation.FuncAnimation(fig, animate, frames=50, interval=400)\nfrom IPython.display import HTML\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\nWe’ll compare the diffusion entropies of this diffusion process with the entropy of diffusion on the sphere, and on plane.\n\nG_sphere = get_adaptive_graph(X_cap_of_sphere, k=15)\nDC = DiffusionCurvature(\n    laziness_method=\"Wasserstein\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    graph_former = get_adaptive_graph,\n)\nsphere_entropy = DC.unsigned_curvature(G_sphere, t=25)[0]\nsphere_entropy\n\nArray(25.005825, dtype=float32)\n\n\n\nplot_3d(X_cap_of_sphere,DC.Pt[0])\n\n\n\n\n\nDC.curvature(G_sphere,t=25,dim=2)[0]\n\nArray(-35.839073, dtype=float32)\n\n\n\nX_plane = plane(len(X_cap_of_sphere), dim=2)\nG_plane = get_adaptive_graph(X_plane,k=15)\nDC = DiffusionCurvature(\n    laziness_method=\"Wasserstein\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    graph_former = get_adaptive_graph,\n)\nplane_entropy = DC.unsigned_curvature(G_plane, t=25)[0]\nplane_entropy\n\nArray(28.964823, dtype=float32)\n\n\n\nplt.scatter(X_plane[:,0], X_plane[:,1], c=DC.Pt[0])\n\n&lt;matplotlib.collections.PathCollection at 0x7f6fd0220990&gt;\n\n\n\n\n\n\n# from diffusion_curvature.compute_mean_flat_entropies import average_flat_entropies\n# plane_entropy = average_flat_entropies(dim=2,t=10,num_trials=100, num_points_in_comparison=len(X_pca))\n\n\nplane_entropy\n\nArray(40.152046, dtype=float32)\n\n\n\nplt.plot(ts, np.ones_like(uks_at_ts)*plane_entropy, label = \"Base Euclidean\")\nplt.plot(ts, np.ones_like(uks_at_ts)*sphere_entropy, label = \"2-Saddle\")\nplt.plot(ts, uks_at_ts, label = \"Noising of PCA'd Saddle\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"W1 Spread of Diffusion\")\nplt.title(\"Diffusion Wasserstein of Noising Diffusion across Time\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "experiments/3e Curvature with (Neural) Flattening.html",
    "href": "experiments/3e Curvature with (Neural) Flattening.html",
    "title": "3e Curvature Via (Neural) Flattening",
    "section": "",
    "text": "[gpu(id=0)]\n\n\n\nThe Normal Way\nFirst, we create a dataset of saddles and take the diffusion curvature on them in the normal way, with the mean precomputed comparison space.\n\nimport graphtools\nfrom diffusion_curvature.core import DiffusionCurvature\nfrom diffusion_curvature.datasets import rejection_sample_from_saddle\n\n\nks_dc = []\ndim = 2\nsamplings = [200]*100\nXs_sampled = []\nfor n_points in tqdm(samplings):\n    X, k = rejection_sample_from_saddle(n_points, dim)\n    Xs_sampled.append(X)\n    # Compute Diffusion Curvature\n    G = graphtools.Graph(X, anisotropy=1, knn=5, decay=None).to_pygsp()\n    DC = DiffusionCurvature(\n        laziness_method=\"Entropic\",\n        flattening_method=\"Mean Fixed\",\n        comparison_method=\"Subtraction\",\n        points_per_cluster=None, # construct separate comparison spaces around each point\n        comparison_space_size_factor=1\n    )\n    ks = DC.curvature(G, t=25, dim=dim, knn=5, idx=0)\n    ks_dc.append(ks)\n# plot a histogram of the diffusion curvatures\nplt.hist(ks_dc, bins=20)\n\n\n\n\n2023-12-08 15:24:09.030037: W external/xla/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n2023-12-08 15:24:09.030055: W external/xla/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n2023-12-08 15:24:09.030122: W external/xla/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\nRelying on driver to perform ptx compilation. \nModify $PATH to customize ptxas location.\nThis message will be only logged once.\n2023-12-08 15:24:09.032957: W external/xla/xla/service/gpu/buffer_comparator.cc:641] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\nRelying on driver to perform ptx compilation. \nSetting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas\nThis message will only be logged once.\n2023-12-08 15:24:09.063303: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:548] failed to load PTX text as a module: CUDA_ERROR_INVALID_IMAGE: device kernel image is invalid\n2023-12-08 15:24:09.063327: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:553] error log buffer (63 bytes): error   : Binary format for key='0', ident='' is not recognize\n2023-12-08 15:24:09.063350: W external/xla/xla/service/gpu/runtime/support.cc:58] Intercepted XLA runtime error:\nINTERNAL: Failed to load PTX text as a module: CUDA_ERROR_INVALID_IMAGE: device kernel image is invalid\n2023-12-08 15:24:09.063374: E external/xla/xla/pjrt/pjrt_stream_executor_client.cc:2593] Execution of replica 0 failed: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.func.launch' failed: Failed to load PTX text as a module: CUDA_ERROR_INVALID_IMAGE: device kernel image is invalid; current tracing scope: concatenate.1; current profiling annotation: XlaModule:#hlo_module=jit_matrix_power,program_id=2#.\n\n\nXlaRuntimeError: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.func.launch' failed: Failed to load PTX text as a module: CUDA_ERROR_INVALID_IMAGE: device kernel image is invalid; current tracing scope: concatenate.1; current profiling annotation: XlaModule:#hlo_module=jit_matrix_power,program_id=2#."
  },
  {
    "objectID": "experiments/3d1 Effects of Graph Construction on Negative Curvature Detection.html",
    "href": "experiments/3d1 Effects of Graph Construction on Negative Curvature Detection.html",
    "title": "3d1 Effects of Graph Construction on Negative Curvature",
    "section": "",
    "text": "In 3d, we noticed that the knn value has a suspiciously large effect on the signs of curvature measured. With \\(k=5\\), DC has trouble picking up any negative curvature; with \\(k=15\\), it struggles to identify anything as positive.\nHere we’ll test the method by probing its ability to separate saddles and spheres in various dimensions."
  },
  {
    "objectID": "experiments/3d1 Effects of Graph Construction on Negative Curvature Detection.html#executive-summary",
    "href": "experiments/3d1 Effects of Graph Construction on Negative Curvature Detection.html#executive-summary",
    "title": "3d1 Effects of Graph Construction on Negative Curvature",
    "section": "Executive Summary:",
    "text": "Executive Summary:\n\nBoth the fixed and adaptive kernel significantly outperform Graphtools’ graph construction on this toy data.\nThe median heuristic is not very good at choosing the right sigma.\nThe adaptive gaussian kernel with \\(k=10\\) chooses the right sigma well, producing tightly clustered distinctions between the saddles and spheres.\nDisabling the anisotropic density normalization helps performance in high dimensions, enabling the adaptive kernel + DC to detect negative curvature in higher-dimensional saddles."
  },
  {
    "objectID": "experiments/3a2 Hickok Curvature of Battery.html",
    "href": "experiments/3a2 Hickok Curvature of Battery.html",
    "title": "diffusion_curvature",
    "section": "",
    "text": "name = \"core_r05\"\n\n\nfrom diffusion_curvature.hickok import scalar_curvature_est\n\n\ndef hickock_curvature_of_pt(X, dim):\n    SC = scalar_curvature_est(\n        n = dim, #manifold dim\n        X = X, #data\n        verbose=False,\n    )\n    ks_est = SC.estimate(rmax=2, indices=[0])\n    return ks_est[0]\n\n\nfrom diffusion_curvature.hickok import scalar_curvature_est\n\n\nX, ks = torus(3000)\nSC = scalar_curvature_est(\n    n = 2, #manifold dim\n    X = X, #data\n    verbose=False,\n)\nks_est = SC.estimate(9)\nks_est_idx = SC.estimate(3, indices=[0])\n\ncomputed Rdist\ncomputed density\ncomputed nearest neighbor matrices\n\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.scatter(ks, ks_est)\n\n&lt;matplotlib.collections.PathCollection&gt;\n\n\n\n\n\n\nimport deepdish\n\n\n# load curvature battery\nbattery_file = \"/home/piriac/data/diffusion_curvature/Curvature_Colosseum_dikey.h5\"\nCC = deepdish.io.load(battery_file)\n\n\nsaved_calcs = f\"/home/piriac/data/diffusion_curvature/computed_hickok_curvatures_{name}.h5\"\nif os.path.exists(saved_calcs):\n    print(f\"Loading saved calculations from {saved_calcs}\")\n    computed_hickok_curvatures = deepdish.io.load(saved_calcs)\nelse:\n    computed_hickok_curvatures = compute_curvature_on_battery(hickok_curvature_of_pt, CC)\n    deepdish.io.save(\"/home/piriac/data/diffusion_curvature/computed_hickok_curvatures_{name}.h5\", computed_hickok_curvatures    )\n\nLoading saved calculations from /home/piriac/data/diffusion_curvature/computed_hickok_curvatures_core_r05.h5\n\n\n\nXsample = CC[2][3][0.5]['Xs'][8]\nhickock_curvature_of_pt(Xsample, 2)\n\n14.954056948843835\n\n\n\nhc_curvature_correlations = compute_correlations(computed_hickok_curvatures, CC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntable = result_table(hc_curvature_correlations, c=1)\n\nCodimension =  1\n╒═══════╤═══════════════╤════════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╕\n│   dim │ Noise = 0.0   │ Noise = 0.05   │ Noise = 0.1   │ Noise = 0.2   │ Noise = 0.3   │ Noise = 0.5   │\n╞═══════╪═══════════════╪════════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╡\n│     2 │ 0.885/1.61    │ 0.815/5.90     │ 0.720/3.67    │ 0.553/3.15    │ 0.502/0.00    │ 0.250/0.08    │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     3 │ 0.785/1.55    │ 0.689/3.13     │ 0.534/6.60    │ 0.304/0.03    │ 0.218/0.12    │ 0.036/0.80    │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     4 │ 0.397/0.00    │ 0.184/0.19     │ 0.331/0.01    │ 0.228/0.11    │ 0.179/0.21    │ -0.035/0.81   │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     5 │ 0.089/0.53    │ -0.073/0.61    │ -0.374/0.00   │ 0.098/0.49    │ 0.208/0.14    │ 0.197/0.17    │\n╘═══════╧═══════════════╧════════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╛\n\n\n\ntable = result_table(hc_curvature_correlations, c=2)\n\nCodimension =  2\n╒═══════╤═══════════════╤════════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╕\n│   dim │ Noise = 0.0   │ Noise = 0.05   │ Noise = 0.1   │ Noise = 0.2   │ Noise = 0.3   │ Noise = 0.5   │\n╞═══════╪═══════════════╪════════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╡\n│     2 │ 0.795/5.62    │ 0.782/1.96     │ 0.344/0.01    │ 0.191/0.18    │ 0.072/0.61    │ 0.143/0.32    │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     3 │ 0.378/0.00    │ 0.103/0.47     │ 0.058/0.69    │ 0.186/0.19    │ -0.111/0.44   │ 0.302/0.03    │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     4 │ 0.138/0.33    │ 0.195/0.17     │ -0.332/0.01   │ 0.110/0.44    │ -0.049/0.73   │ 0.055/0.70    │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     5 │ 0.250/0.08    │ -0.182/0.20    │ 0.030/0.83    │ -0.125/0.38   │ 0.201/0.16    │ 0.066/0.65    │\n╘═══════╧═══════════════╧════════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╛\n\n\n\ntable = result_table(hc_curvature_correlations, c=3)\n\nCodimension =  3\n╒═══════╤═══════════════╤════════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╕\n│   dim │ Noise = 0.0   │ Noise = 0.05   │ Noise = 0.1   │ Noise = 0.2   │ Noise = 0.3   │ Noise = 0.5   │\n╞═══════╪═══════════════╪════════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╡\n│     2 │ 0.570/1.53    │ 0.350/0.01     │ -0.016/0.91   │ -0.090/0.53   │ -0.018/0.90   │ -0.134/0.35   │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     3 │ 0.197/0.16    │ -0.113/0.43    │ 0.181/0.20    │ -0.090/0.53   │ 0.109/0.45    │ 0.194/0.17    │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     4 │ 0.006/0.96    │ 0.151/0.29     │ -0.012/0.93   │ -0.052/0.72   │ -0.024/0.86   │ 0.113/0.43    │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     5 │ -0.235/0.10   │ 0.157/0.27     │ 0.039/0.78    │ 0.157/0.27    │ 0.246/0.08    │ 0.386/0.00    │\n╘═══════╧═══════════════╧════════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╛\n\n\n\ntable_latex = result_table(hc_curvature_correlations, c=1, style='latex_raw')\ntable_latex += result_table(hc_curvature_correlations, c=2, style='latex_raw')\ntable_latex += result_table(hc_curvature_correlations, c=3, style='latex_raw')\n\nCodimension =  1\n\\begin{tabular}{rllllll}\n\\hline\n   dim & Noise = 0.0   & Noise = 0.05   & Noise = 0.1   & Noise = 0.2   & Noise = 0.3   & Noise = 0.5   \\\\\n\\hline\n     2 & 0.885/1.61    & 0.815/5.90     & 0.720/3.67    & 0.553/3.15    & 0.502/0.00    & 0.250/0.08    \\\\\n     3 & 0.785/1.55    & 0.689/3.13     & 0.534/6.60    & 0.304/0.03    & 0.218/0.12    & 0.036/0.80    \\\\\n     4 & 0.397/0.00    & 0.184/0.19     & 0.331/0.01    & 0.228/0.11    & 0.179/0.21    & -0.035/0.81   \\\\\n     5 & 0.089/0.53    & -0.073/0.61    & -0.374/0.00   & 0.098/0.49    & 0.208/0.14    & 0.197/0.17    \\\\\n\\hline\n\\end{tabular}\nCodimension =  2\n\\begin{tabular}{rllllll}\n\\hline\n   dim & Noise = 0.0   & Noise = 0.05   & Noise = 0.1   & Noise = 0.2   & Noise = 0.3   & Noise = 0.5   \\\\\n\\hline\n     2 & 0.795/5.62    & 0.782/1.96     & 0.344/0.01    & 0.191/0.18    & 0.072/0.61    & 0.143/0.32    \\\\\n     3 & 0.378/0.00    & 0.103/0.47     & 0.058/0.69    & 0.186/0.19    & -0.111/0.44   & 0.302/0.03    \\\\\n     4 & 0.138/0.33    & 0.195/0.17     & -0.332/0.01   & 0.110/0.44    & -0.049/0.73   & 0.055/0.70    \\\\\n     5 & 0.250/0.08    & -0.182/0.20    & 0.030/0.83    & -0.125/0.38   & 0.201/0.16    & 0.066/0.65    \\\\\n\\hline\n\\end{tabular}\nCodimension =  3\n\\begin{tabular}{rllllll}\n\\hline\n   dim & Noise = 0.0   & Noise = 0.05   & Noise = 0.1   & Noise = 0.2   & Noise = 0.3   & Noise = 0.5   \\\\\n\\hline\n     2 & 0.570/1.53    & 0.350/0.01     & -0.016/0.91   & -0.090/0.53   & -0.018/0.90   & -0.134/0.35   \\\\\n     3 & 0.197/0.16    & -0.113/0.43    & 0.181/0.20    & -0.090/0.53   & 0.109/0.45    & 0.194/0.17    \\\\\n     4 & 0.006/0.96    & 0.151/0.29     & -0.012/0.93   & -0.052/0.72   & -0.024/0.86   & 0.113/0.43    \\\\\n     5 & -0.235/0.10   & 0.157/0.27     & 0.039/0.78    & 0.157/0.27    & 0.246/0.08    & 0.386/0.00    \\\\\n\\hline\n\\end{tabular}\n\n\n\nsign_accs = compute_sign_score(computed_hickok_curvatures, CC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntable = result_table(sign_accs, c=2, keys=['accuracy'])\n\nCodimension =  2\n╒═══════╤═══════════════╤════════════════╤═══════════════╤═══════════════╤═══════════════╤═══════════════╕\n│   dim │   Noise = 0.0 │   Noise = 0.05 │   Noise = 0.1 │   Noise = 0.2 │   Noise = 0.3 │   Noise = 0.5 │\n╞═══════╪═══════════════╪════════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╡\n│     2 │          0.34 │           0.78 │          0.64 │          0.72 │          0.68 │          0.60 │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     3 │          0.22 │           0.26 │          0.16 │          0.24 │          0.22 │          0.34 │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     4 │          0.18 │           0.12 │          0.10 │          0.18 │          0.08 │          0.20 │\n├───────┼───────────────┼────────────────┼───────────────┼───────────────┼───────────────┼───────────────┤\n│     5 │          0.16 │           0.16 │          0.12 │          0.16 │          0.14 │          0.12 │\n╘═══════╧═══════════════╧════════════════╧═══════════════╧═══════════════╧═══════════════╧═══════════════╛"
  },
  {
    "objectID": "experiments/Diffusion Laziness.html",
    "href": "experiments/Diffusion Laziness.html",
    "title": "Measurements of Diffusion Laziness",
    "section": "",
    "text": "Entropic Diffusion Laziness\n\n\nentropy_of_diffusion\n\n entropy_of_diffusion (G:graphtools.base.DataGraph, idx=None)\n\nReturns the pointwise entropy of diffusion from the powered diffusion matrix in the inpiut"
  },
  {
    "objectID": "experiments/3c Sampling Experiments.html",
    "href": "experiments/3c Sampling Experiments.html",
    "title": "3c Sampling Experiments on Diffusion Curvature",
    "section": "",
    "text": "How does it perform with planes of varying dimensions?\nUsing clustering within the manifold:\n\nds = [3,4,5,6]\nplanes = [plane(1000*2**(d-2), d) for d in ds]\nfor i, d in enumerate(ds):\n    G = get_alpha_decay_graph(planes[i], decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=500,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\")\n    ks = DC.curvature(G, t=8, dim=d, knn=15)\n    print(\"dimension\",d,\": Curvature of Plane is \",ks[0])\n\n\n\n\ndimension 3 : Curvature of Plane is  0.22488499\ndimension 4 : Curvature of Plane is  -0.0021333694\ndimension 5 : Curvature of Plane is  -0.1174202\ndimension 6 : Curvature of Plane is  -0.098750114\n\n\n\n\n\n\n\n\n\n\n\nWithout clustering\n\nds = [3,4,5,6]\nplanes = [plane(1000*2**(d-2), d) for d in ds]\nfor i, d in enumerate(ds):\n    G = get_alpha_decay_graph(planes[i], decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\")\n    ks = DC.curvature(G, t=8, dim=d, knn=15)\n    print(\"dimension\",d,\": Curvature of Plane is \",ks[0])\n\n\n\n\ndimension 3 : Curvature of Plane is  -0.113577366\ndimension 4 : Curvature of Plane is  -0.031496525\ndimension 5 : Curvature of Plane is  -0.05647278\ndimension 6 : Curvature of Plane is  0.07413292\n\n\n\n\n\n\n\n\n\n\n\nConclusion: when using more points, there’s less variance between dimensions — though still a slightly alarming amount of variance within them. There doesn’t appear to be any pervasive bias induced by dimensionality in either setting. That said, this is the best possible condition, as it is literally comparing a plane to a plane."
  },
  {
    "objectID": "experiments/3c Sampling Experiments.html#dimensional-analysis-of-planes",
    "href": "experiments/3c Sampling Experiments.html#dimensional-analysis-of-planes",
    "title": "3c Sampling Experiments on Diffusion Curvature",
    "section": "",
    "text": "How does it perform with planes of varying dimensions?\nUsing clustering within the manifold:\n\nds = [3,4,5,6]\nplanes = [plane(1000*2**(d-2), d) for d in ds]\nfor i, d in enumerate(ds):\n    G = get_alpha_decay_graph(planes[i], decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=500,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\")\n    ks = DC.curvature(G, t=8, dim=d, knn=15)\n    print(\"dimension\",d,\": Curvature of Plane is \",ks[0])\n\n\n\n\ndimension 3 : Curvature of Plane is  0.22488499\ndimension 4 : Curvature of Plane is  -0.0021333694\ndimension 5 : Curvature of Plane is  -0.1174202\ndimension 6 : Curvature of Plane is  -0.098750114\n\n\n\n\n\n\n\n\n\n\n\nWithout clustering\n\nds = [3,4,5,6]\nplanes = [plane(1000*2**(d-2), d) for d in ds]\nfor i, d in enumerate(ds):\n    G = get_alpha_decay_graph(planes[i], decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\")\n    ks = DC.curvature(G, t=8, dim=d, knn=15)\n    print(\"dimension\",d,\": Curvature of Plane is \",ks[0])\n\n\n\n\ndimension 3 : Curvature of Plane is  -0.113577366\ndimension 4 : Curvature of Plane is  -0.031496525\ndimension 5 : Curvature of Plane is  -0.05647278\ndimension 6 : Curvature of Plane is  0.07413292\n\n\n\n\n\n\n\n\n\n\n\nConclusion: when using more points, there’s less variance between dimensions — though still a slightly alarming amount of variance within them. There doesn’t appear to be any pervasive bias induced by dimensionality in either setting. That said, this is the best possible condition, as it is literally comparing a plane to a plane."
  },
  {
    "objectID": "experiments/3c Sampling Experiments.html#planes-under-different-sampling",
    "href": "experiments/3c Sampling Experiments.html#planes-under-different-sampling",
    "title": "3c Sampling Experiments on Diffusion Curvature",
    "section": "Planes under different sampling",
    "text": "Planes under different sampling\n\nsampled_plane_ks = []\nt = 8\nfor i in trange(1000):\n    X_plane = plane(1000,2)\n    G = get_alpha_decay_graph(X_plane, decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\")\n    ks = DC.curvature(G, t=t, dim=2, knn=15)\n    sampled_plane_ks.append(ks[0])\n\n\n\n\n\n# plot a histogram of the curvature values\nplt.hist(sampled_plane_ks, bins=100)\nplt.title(f\"Ks of Plane, with No Clustering, Subtraction, t={t}\")\n\nText(0.5, 1.0, 'Ks of Plane, with No Clustering, Subtraction, t=8')\n\n\n\n\n\nThat’s not looking very good. The randomness of the plane sampling, combined with the randomness of the comparison space has created a lot of variability.\nI see two strategies to address this: using a higher \\(t\\), and comparing to a grid.\n\nsampled_plane_ks = []\nt = 8\nfor i in trange(1000):\n    X_plane = plane(1000,2)\n    G = get_alpha_decay_graph(X_plane, decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\", use_grid=True)\n    ks = DC.curvature(G, t=t, dim=2, knn=15)\n    sampled_plane_ks.append(ks[0])\n\n\n\n\n\n# plot a histogram of the curvature values\nplt.hist(sampled_plane_ks, bins=100)\nplt.title(f\"Ks of Plane, with Grid, No Clustering, Subtraction, t={t}\")\n\nText(0.5, 1.0, 'Ks of Plane, with Grid, No Clustering, Subtraction, t=8')\n\n\n\n\n\nNow this is odd. It appears the grid biases the results; it must have a higher-than-normal entropy, making everything appear more positive while it, the comparison, looks falsely negative. What’s up with this?\nOn a more positive note, using a grid did shave off 0.2 variance.\nHypothesis 1: It’s the kernel we’re using. That darn alpha-decay kernel is somehow changing the shape of the grid. Disabling the decay should remedy the problem. To be doubly sure that’s working, I can construct a kernel with my code.\n\nDecay=None does nothing – that’s what we were using before.\nBut perhaps it has to do with the knn value! In a grid, the 15th nearest neighbor may be further than it is on a uniformly sampled surface, because the points are arranged in squares rather than circles.\n\n\nsampled_plane_ks = []\nt = 8\nfor i in trange(1000):\n    X_plane = plane(1000,2)\n    G = get_alpha_decay_graph(X_plane, decay=None, knn=10, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\", use_grid=True)\n    ks = DC.curvature(G, t=t, dim=2, knn=10)\n    sampled_plane_ks.append(ks[0])\n\n\n\n\n\n# plot a histogram of the curvature values\nplt.hist(sampled_plane_ks, bins=100)\nplt.title(f\"Ks of Plane, with Grid, No Clustering, Subtraction, t={t}, knn=10\")\n\nText(0.5, 1.0, 'Ks of Plane, with Grid, No Clustering, Subtraction, t=8, knn=10')\n\n\n\n\n\nSupport for the knn hypothesis. Changing k from 15 to 10 increased the perceived negativity of the grid’s curvature.\nThis would likely be best avoided by not using a knn grid; or using some average of distances, rather than the concrete distance from the kth nearest neighbor.\nIt would also, if the hypothesis is shrewd, diminish in effect the higher the k.\n\nsampled_plane_ks = []\nt = 8\nfor i in trange(1000):\n    X_plane = plane(1000,2)\n    G = get_alpha_decay_graph(X_plane, decay=None, knn=30, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\", use_grid=True)\n    ks = DC.curvature(G, t=t, dim=2, knn=30)\n    sampled_plane_ks.append(ks[0])\n\n\n\n\n\n# plot a histogram of the curvature values\nplt.hist(sampled_plane_ks, bins=100)\nplt.title(f\"Ks of Plane, with Grid, No Clustering, Subtraction, t={t}, knn=30\")\n\nText(0.5, 1.0, 'Ks of Plane, with Grid, No Clustering, Subtraction, t=8, knn=30')\n\n\n\n\n\nIndeed, using a larger knn value decreased the descrepency considerably. But it’s still there!\nAs an ablation, here’s this same experiment on a 5000 point plane.\nHere’s the k=15 version: (With GPU, it jumps to about 10 minutes to run 1000 trials. Not bad. Thank ya, Nvidia!)\n\nsampled_plane_ks = []\nt = 8\nfor i in trange(1000):\n    X_plane = plane(5000,2)\n    G = get_alpha_decay_graph(X_plane, decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\", use_grid=True)\n    ks = DC.curvature(G, t=t, dim=2, knn=15)\n    sampled_plane_ks.append(ks[0])\n\n\n\n\n\n# plot a histogram of the curvature values\nplt.hist(sampled_plane_ks, bins=100)\nplt.title(f\"Ks of Plane, with Grid, No Clustering, Subtraction, t={t}, knn=15\")\n\nText(0.5, 1.0, 'Ks of Plane, with Grid, No Clustering, Subtraction, t=8')\n\n\n\n\n\n\nsampled_plane_ks = []\nt = 8\nfor i in trange(1000):\n    X_plane = plane(5000,2)\n    G = get_alpha_decay_graph(X_plane, decay=None, knn=30, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\", use_grid=True)\n    ks = DC.curvature(G, t=t, dim=2, knn=30)\n    sampled_plane_ks.append(ks[0])\n\n\n\n\n\n# plot a histogram of the curvature values\nplt.hist(sampled_plane_ks, bins=100)\nplt.title(f\"Ks of Plane, with Grid, No Clustering, Subtraction, t={t}, knn=30\")\n\nText(0.5, 1.0, 'Ks of Plane, with Grid, No Clustering, Subtraction, t=8, knn=30')\n\n\n\n\n\nThe grid, if it can be made to work, greatly reduces the variance in reported curvatures. To work with it, I see two immediate options:\n\nAdopting a non-knn kernel – something more sophisticated – that weighs across the distances of all of the k nearest points, and not merely the kth point. If used simultaneously on real data and the comparison space, this would allow us to use the grid.\nInstead of changing our kernel to match the hyper-uniform sampling of the grid, whose chief advantage is predictability, we could average the results of a large number of uniform samplings. We can take the average entropy over N uniform samplings for a grid of likely pairings between k, t, and d.\n\nI favor the latter approach, as it would also reduce the runtime of the algorithm, by precomputing the expected uniform samplings. If parameters are chosen outside of the precomputed grid, you can revert to a single sampling, as we presently do it. Additionally, this would allow fast matching of comparison spaces with graphs. At low \\(t\\) values, the diffusion entropy should be approximately equal to the flat entropy, modulo the kernel bandwidth, thus allowing us to estimate that \\(knn\\) parameter.\nThe feasibility question is this: how many pairings do we need?\n\nnum_ks = 30\nnum_ts = 50\nnum_ds = 10 # anything much higher dimensional is impossible to get enough samples from\nnum_trials = num_ks * num_ts * num_ds\nnum_trials\n\n15000\n\n\nEach of those could be done in at most 5 minutes, costing\n\nstr(num_trials/12/24)[:4] + \" days\"\n\n'52.0 days'\n\n\nOf course, I can parallelize that across Yale’s clusters, cutting it down to just a couple of days. That seems feasible.\nThe other feasibility check is whether the number of points in the comparison space changes the entropy. It shouldn’t. Let’s check:\n\nks_bigs = []\nks_smalls = []\nfor i in range(100):\n    big_plane = plane(5000,2)\n    small_plane = plane(500,2)\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\", use_grid=False)\n    G_big_plane = get_alpha_decay_graph(big_plane, knn=15, anisotropy=1, decay=None)\n    G_small_plane = get_alpha_decay_graph(small_plane, knn=15, anisotropy=1, decay=None)\n    ks_big = DC.unsigned_curvature(G_big_plane, t=8, idx=0)\n    ks_small = DC.unsigned_curvature(G_small_plane, t=8, idx=0)\n    ks_bigs.append(ks_big) \n    ks_smalls.append(ks_small)\n\n\n# show the mean and standard deviation of ks_bigs and ks_smalls\nprint(\"mean of ks_bigs:\", np.mean(ks_bigs))\nprint(\"mean of ks_smalls:\", np.mean(ks_smalls))\nprint(\"std of ks_bigs:\", np.std(ks_bigs))\nprint(\"std of ks_smalls:\", np.std(ks_smalls))\n\nmean of ks_bigs: 5.059733\nmean of ks_smalls: 5.0795994\nstd of ks_bigs: 0.07575969\nstd of ks_smalls: 0.0928274\n\n\nSo there is a difference arising from the number of points used. Likely this is because the diffusion, though concentrated in the center of our plane, has lots of ‘close to zero’ values that have spread across the manifold.\nI tried changing the entropy calculation to zero out elements below an epsilon threshold (set to 10e-5); this helps some, but for large discrepancies in the number of points there’s still a .02 discrepancy. Perhaps that’s close enough it can be tolerated – it’s certainly less than the variance within different uniform samplings of the plane.\nThe next step is to modify the ‘Fixed’ comparison space construction to first load a database of flat entropies (on initialization of the class?), check if the current parameters are within the database, and, if not, average the uniform sampling N times."
  },
  {
    "objectID": "experiments/3c Sampling Experiments.html#effects-of-t",
    "href": "experiments/3c Sampling Experiments.html#effects-of-t",
    "title": "3c Sampling Experiments on Diffusion Curvature",
    "section": "Effects of \\(t\\)",
    "text": "Effects of \\(t\\)\n\nsampled_plane_ks = []\nt = 25\nfor i in trange(1000):\n    X_plane = plane(1000,2)\n    G = get_alpha_decay_graph(X_plane, decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\", use_grid=True)\n    ks = DC.curvature(G, t=t, dim=2, knn=30)\n    sampled_plane_ks.append(ks[0])\n\n\n\n\n\n# plot a histogram of the curvature values\nplt.hist(sampled_plane_ks, bins=100)\nplt.title(f\"Ks of Plane, with Grid, No Clustering, Subtraction, t={t}, knn=15\")\n\nText(0.5, 1.0, 'Ks of Plane, with Grid, No Clustering, Subtraction, t=25, knn=15')\n\n\n\n\n\n\nnp.std(sampled_plane_ks)\n\n0.054011818"
  },
  {
    "objectID": "experiments/3c Sampling Experiments.html#pure-resampling-with-no-noise-1000-points",
    "href": "experiments/3c Sampling Experiments.html#pure-resampling-with-no-noise-1000-points",
    "title": "3c Sampling Experiments on Diffusion Curvature",
    "section": "Pure Resampling, with no noise, 1000 points",
    "text": "Pure Resampling, with no noise, 1000 points\n\ndiffusion_ks, real_ks = curved_sampling_experiment(\n    density_variance=0, noisiness=0, num_samplings=5, num_surfaces=50\n)\n\n\n\n\n\n\n\n\nanalyze_sampling_results(diffusion_ks, real_ks, \"Variance across Samplings, no noise, no density variance\")"
  },
  {
    "objectID": "experiments/3c Sampling Experiments.html#with-0.1-noise",
    "href": "experiments/3c Sampling Experiments.html#with-0.1-noise",
    "title": "3c Sampling Experiments on Diffusion Curvature",
    "section": "With 0.1 Noise",
    "text": "With 0.1 Noise\n\ndiffusion_ks, real_ks = curved_sampling_experiment(\n    density_variance=0, noisiness=0.1, num_samplings=5, num_surfaces=50, num_points_per_surface=1000, t = 25, \n)\n\n\n\n\n\n\n\n\nanalyze_sampling_results(diffusion_ks, real_ks, title = \"Variance across Samplings, no density variance, noise=0.1\")"
  },
  {
    "objectID": "experiments/3c Sampling Experiments.html#with-0.2-noise",
    "href": "experiments/3c Sampling Experiments.html#with-0.2-noise",
    "title": "3c Sampling Experiments on Diffusion Curvature",
    "section": "With 0.2 Noise",
    "text": "With 0.2 Noise\n\ndiffusion_ks, real_ks = curved_sampling_experiment(\n    density_variance=0, noisiness=0.2, num_samplings=5, num_surfaces=50, num_points_per_surface=1000, t = 25, \n)\n\n\n\n\n\n\n\n\nanalyze_sampling_results(diffusion_ks, real_ks, title = \"Variance across Samplings, no density variance, noise=0.1\")"
  },
  {
    "objectID": "experiments/3c Sampling Experiments.html#with-different-sampling-densities",
    "href": "experiments/3c Sampling Experiments.html#with-different-sampling-densities",
    "title": "3c Sampling Experiments on Diffusion Curvature",
    "section": "With Different Sampling Densities",
    "text": "With Different Sampling Densities\n\ndiffusion_ks, real_ks = curved_sampling_experiment(\n    density_variance=0.1, noisiness=0, num_samplings=5, num_surfaces=50, num_points_per_surface=1000, t = 25, \n)\n\n\n\n\n\n\n\n\nanalyze_sampling_results(diffusion_ks, real_ks, title = \"Variance across Samplings, density variance=0.1, no noise\")"
  },
  {
    "objectID": "documentation/index.html",
    "href": "documentation/index.html",
    "title": "Diffusion Curvature",
    "section": "",
    "text": "[!INFO] This code is currently in early beta. Some features, particularly those relating to dimension estimation and the construction of comparison spaces, are experimental and will likely change. Please report any issues you encounter to the Github Issues page.\nDiffusion curvature is a pointwise extension of Ollivier-Ricci curvature, designed specifically for the often messy world of pointcloud data. Its advantages include:"
  },
  {
    "objectID": "documentation/index.html#install",
    "href": "documentation/index.html#install",
    "title": "Diffusion Curvature",
    "section": "Install",
    "text": "Install\n\nTo install with pip (or better yet, poetry),\npip install diffusion-curvature\nor\npoetry add diffusion-curvature\nConda releases are pending."
  },
  {
    "objectID": "documentation/index.html#usage",
    "href": "documentation/index.html#usage",
    "title": "Diffusion Curvature",
    "section": "Usage",
    "text": "Usage\nTo compute diffusion curvature, first create a graphtools graph with your data. Graphtools offers extensive support for different kernel types (if creating from a pointcloud), and can also work with graphs in the PyGSP format. We recommend using anistropy=1, and verifying that the supplied knn value encompasses a reasonable portion of the graph.\nGraphtools offers many additional options. For large graphs, you can speed up the powering of the diffusion matrix with landmarking: simply pass n_landmarks=1000 (e.g) when creating the graphtools graph. If you enable landmarking, diffusion-curvature will automatically use it.\nNext, instantiate a DiffusionCurvature operator.\nAnd, finally, pass your graph through it. The DiffusionCurvature operator will store everything it computes – the powered diffusion matrix, the estimated manifold distances, and the curvatures – as attributes of your graph. To get the curvatures, you can run G.ks.\n\n# G_torus = DC.curvature(G_torus, dimension=2) # note: this is the intrinsic dimension of the data\n\n\nplot_3d(X_torus, G_torus.ks, colorbar=True, title=\"Diffusion Curvature on the torus\")"
  },
  {
    "objectID": "experiments/3a Visual Battery.html",
    "href": "experiments/3a Visual Battery.html",
    "title": "3a A Visual Battery of Benchmarks",
    "section": "",
    "text": "Here is the curvature equivalent of the “sniff test”: does our technique appropriately color the most basic 2 manifolds? This notebook implements this comparison, making it easy to swap in and out curvature methods and rerun them on every baseline.\n# Establish Datasets\nn_points = 5000\nXs = {}\nKs = {}\nXs['torus'], Ks['torus'] = torus(n_points, use_guide_points=True)\nXs['plane'] = plane(n_points, dim=2)\nXs['paraboloid'], Ks['paraboloid'] = paraboloid(n_points, use_guide_points=True)\nXs['plane'], Ks['plane'] = sphere(n_points)\nXs['ellipsoid'], Ks['ellipsoid'] = ellipsoid(n_points)\nXs['hyperboloid'], Ks['hyperboloid'] = hyperboloid(n_points)"
  },
  {
    "objectID": "experiments/3a Visual Battery.html#with-same-parameter-fitting",
    "href": "experiments/3a Visual Battery.html#with-same-parameter-fitting",
    "title": "3a A Visual Battery of Benchmarks",
    "section": "With Same parameter fitting",
    "text": "With Same parameter fitting\n\nG_plane = get_alpha_decay_graph(Xs['plane'], knn=30, anisotropy=1, )\nG_flat = euclidean_comparison_graph(G_plane,dimension=2)\nP = diffusion_matrix_from_affinities(G_plane.K.todense())\nplt.scatter(Xs['plane'][:,0],Xs['plane'][:,1],c=P[0])\nts = np.arange(1,20)\nDC = DiffusionCurvature(laziness_method=\"Entropic\",comparison_space_size_factor=2,comparison_method=\"Subtraction\",use_graphs_kernel_parameters=False)\nuks = []\nflat_uks = []\nfor t in tqdm(ts):\n    uks += [float(DC.unsigned_curvature(G_plane,t)[0])]\n    flat_uks += [float(DC.unsigned_curvature(G_flat,t)[0])]\n\n\n\n\n\n\n\n\nG_flat.get_params()\n\n{'n_pca': None,\n 'random_state': None,\n 'kernel_symm': '+',\n 'theta': None,\n 'anisotropy': 0,\n 'knn': 5,\n 'decay': 40,\n 'bandwidth': None,\n 'bandwidth_scale': 1.0,\n 'distance': 'euclidean',\n 'precomputed': 'affinity'}\n\n\n\nG_plane.get_params()\n\n{'n_pca': None,\n 'random_state': None,\n 'kernel_symm': '+',\n 'theta': None,\n 'anisotropy': 0,\n 'knn': 5,\n 'decay': 40,\n 'bandwidth': None,\n 'bandwidth_scale': 1.0,\n 'distance': 'euclidean',\n 'precomputed': 'affinity'}\n\n\n\n# plot uks and flat_uks on the same graph, with labels\nfig, axs = plt.subplots(1, 2, figsize=(14, 7))\naxs[0].plot(ts,uks,label=\"Plane\")\naxs[0].plot(ts,flat_uks,label=\"Flat\")\naxs[0].legend()\n\naxs[0].set_ylabel(\"Unsigned Curvature\")\naxs[0].set_title(\"Unsigned Curvature of Plane and Flat\")\n\n# Plot the ratio flat_uks/uks\naxs[1].plot(ts,np.array(flat_uks)/np.array(uks))\naxs[1].set_xlabel(\"t\")\naxs[1].set_ylabel(\"Unsigned Curvature\")    \naxs[1].set_title(\"Ratio of Flat to Plane\")\n\nplt.show()\n\n\n\n\n\nG_plane = get_alpha_decay_graph(Xs['plane'], knn=30, anisotropy=1, )\nG_flat = euclidean_comparison_graph(G_plane,dimension=2)\nP = diffusion_matrix_from_affinities(G_plane.K.todense())\nplt.scatter(Xs['plane'][:,0],Xs['plane'][:,1],c=P[0])\nts = np.arange(1,20)\nDC = DiffusionCurvature(laziness_method=\"Entropic\",comparison_space_size_factor=2,comparison_method=\"Subtraction\",use_graphs_kernel_parameters=False)\nuks = []\nflat_uks = []\nfor t in tqdm(ts):\n    uks += [float(DC.unsigned_curvature(G_plane,t)[0])]\n    flat_uks += [float(DC.unsigned_curvature(G_flat,t)[0])]\n\n\n# plot uks and flat_uks on the same graph, with labels\nfig, axs = plt.subplots(1, 2, figsize=(14, 7))\naxs[0].plot(ts,uks,label=\"plane\")\naxs[0].plot(ts,flat_uks,label=\"Flat\")\naxs[0].legend()\naxs[0].set_xlabel(\"t\")\naxs[0].set_ylabel(\"Unsigned Curvature\")\naxs[0].set_title(\"Unsigned Curvature of plane and Flat\")\n\n# Plot the ratio flat_uks/uks\naxs[1].plot(ts,np.array(flat_uks)/np.array(uks))\naxs[1].set_xlabel(\"t\")\naxs[1].set_ylabel(\"Unsigned Curvature\")    \naxs[1].set_title(\"Ratio of Flat to plane\")\n\nplt.show()\n\n\n\n\n\nG_paraboloid = get_alpha_decay_graph(Xs['paraboloid'], knn=30, anisotropy=1, )\nG_flat = euclidean_comparison_graph(G_paraboloid,dimension=2)\nP = diffusion_matrix_from_affinities(G_paraboloid.K.todense())\nplot_3d(Xs['paraboloid'], P[0])\nts = np.arange(1,20)\nDC = DiffusionCurvature(laziness_method=\"Entropic\",comparison_space_size_factor=2,comparison_method=\"Subtraction\",use_graphs_kernel_parameters=False)\nuks = []\nflat_uks = []\nfor t in tqdm(ts):\n    uks += [float(DC.unsigned_curvature(G_paraboloid,t)[0])]\n    flat_uks += [float(DC.unsigned_curvature(G_flat,t)[0])]\n\n\n\n\n\n\n\n\n# plot uks and flat_uks on the same graph, with labels\nfig, axs = plt.subplots(1, 2, figsize=(14, 7))\naxs[0].plot(ts,uks,label=\"Paraboloid\")\naxs[0].plot(ts,flat_uks,label=\"Flat\")\naxs[0].legend()\naxs[0].set_xlabel(\"t\")\naxs[0].set_ylabel(\"Unsigned Curvature\")\naxs[0].set_title(\"Unsigned Curvature of Paraboloid and Flat\")\n\n# Plot the ratio flat_uks/uks\naxs[1].plot(ts,np.array(flat_uks)/np.array(uks))\naxs[1].set_xlabel(\"t\")\naxs[1].set_ylabel(\"Unsigned Curvature\")    \naxs[1].set_title(\"Ratio of Flat to Paraboloid\")\n\nplt.show()"
  },
  {
    "objectID": "experiments/3a Visual Battery.html#with-fitted-comparison-space",
    "href": "experiments/3a Visual Battery.html#with-fitted-comparison-space",
    "title": "3a A Visual Battery of Benchmarks",
    "section": "With Fitted Comparison Space",
    "text": "With Fitted Comparison Space\n\nPlane\n\nplane = get_alpha_decay_graph(Xs['plane'], knn=30, anisotropy=1, )\njump_of_diffusion = DC.unsigned_curvature(G_plane,1)[0]\nP = diffusion_matrix_from_affinities(G_plane.K.todense())\nplt.scatter(Xs['plane'][:,0],Xs['plane'][:,1],c=P[0])\nts = np.arange(1,20)\nDC = DiffusionCurvature(laziness_method=\"Entropic\",comparison_space_size_factor=2,comparison_method=\"Subtraction\",use_graphs_kernel_parameters=False)\n\n\nmodel = EuclideanComparisonSpace(dimension=2, num_points=len(Xs['plane']), jump_of_diffusion=jump_of_diffusion,)\nparams = fit_comparison_space_model(model, max_epochs=1000)\nprint(params)\neuclidean_stuffs = model.apply(params) # dictionary containing A, P, D\nW = fill_diagonal(euclidean_stuffs['A'],0)\nG_flat = pygsp.graphs.Graph(\n    W = W,\n    lap_type = G_plane.lap_type, # type of laplacian; we'll use the same as inputted.\n    )\n\n\nuks = []\nflat_uks = []\nfor t in tqdm(ts):\n    uks += [float(DC.unsigned_curvature(G_plane,t)[0])]\n    flat_uks += [float(DC.unsigned_curvature(G_flat,t)[0])]\n\n{'params': {'kernel bandwidth': Array([0.03706357], dtype=float32)}}\n\n\n\n\n\n\n\n\n\n# plot uks and flat_uks on the same graph, with labels\nfig, axs = plt.subplots(1, 2, figsize=(14, 7))\naxs[0].plot(ts,uks,label=\"Plane\")\naxs[0].plot(ts,flat_uks,label=\"Flat\")\naxs[0].legend()\naxs[0].set_xlabel(\"t\")\naxs[0].set_ylabel(\"Unsigned Curvature\")\naxs[0].set_title(\"Unsigned Curvature of Plane and Flat\")\n\n# Plot the ratio flat_uks/uks\naxs[1].plot(ts,np.array(flat_uks)/np.array(uks)-1)\naxs[1].set_xlabel(\"t\")\naxs[1].set_ylabel(\"Ralative ratio (0 is 1)\")    \naxs[1].set_title(\"Ratio of Flat to Plane\")\n\nplt.show()\n\n\n\n\n\n\nSphere\n\nsphere = get_alpha_decay_graph(Xs['sphere'], knn=30, anisotropy=1, )\njump_of_diffusion = DC.unsigned_curvature(sphere,1)[0]\nP = diffusion_matrix_from_affinities(sphere.K.todense())\nplot_3d(Xs['sphere'], P[0])\nts = np.arange(1,20)\nDC = DiffusionCurvature(laziness_method=\"Entropic\",comparison_space_size_factor=2,comparison_method=\"Subtraction\",use_graphs_kernel_parameters=False)\n\n\nmodel = EuclideanComparisonSpace(dimension=2, num_points=len(Xs['sphere']), jump_of_diffusion=jump_of_diffusion,)\nparams = fit_comparison_space_model(model, max_epochs=1000)\nprint(params)\neuclidean_stuffs = model.apply(params) # dictionary containing A, P, D\nW = fill_diagonal(euclidean_stuffs['A'],0)\nG_flat = pygsp.graphs.Graph(\n    W = W,\n    lap_type = sphere.lap_type, # type of laplacian; we'll use the same as inputted.\n    )\n\n\nuks = []\nflat_uks = []\nfor t in tqdm(ts):\n    uks += [float(DC.unsigned_curvature(sphere,t)[0])]\n    flat_uks += [float(DC.unsigned_curvature(G_flat,t)[0])]\n\n\n\n\n{'params': {'kernel bandwidth': Array([0.04104568], dtype=float32)}}\n\n\n\n\n\n\n# plot uks and flat_uks on the same graph, with labels\nfig, axs = plt.subplots(1, 2, figsize=(14, 7))\naxs[0].plot(ts,uks,label=\"Sphere\")\naxs[0].plot(ts,flat_uks,label=\"Flat\")\naxs[0].legend()\naxs[0].set_xlabel(\"t\")\naxs[0].set_ylabel(\"Unsigned Curvature\")\naxs[0].set_title(\"Unsigned Curvature of Sphere and Flat\")\n\n# Plot the ratio flat_uks/uks\naxs[1].plot(ts,np.array(flat_uks)/np.array(uks)-1)\naxs[1].set_xlabel(\"t\")\naxs[1].set_ylabel(\"Ralative ratio (0 is 1)\")    \naxs[1].set_title(\"Ratio of Flat to Sphere\")\n\nplt.show()"
  },
  {
    "objectID": "experiments/3a1 DC of Battery.html",
    "href": "experiments/3a1 DC of Battery.html",
    "title": "3a1 Computing the diffusion curvature of the battery",
    "section": "",
    "text": "name = \"heron_adaptive_graph_former_k10_tNone\"\n\n\nimport graphtools\nfrom functools import partial\nfrom diffusion_curvature.core import DiffusionCurvature, get_adaptive_graph\n\n\ndef diffusion_curvature_of_pt(X, dim):\n    graph_former = partial(\n        get_adaptive_graph, k=15,\n    )\n    G = graph_former(X) #graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\n    DC = DiffusionCurvature(\n        laziness_method=\"Entropic\",\n        flattening_method=\"Fixed\",\n        comparison_method=\"Subtraction\",\n        graph_former = graph_former,\n        points_per_cluster=None, # construct separate comparison spaces around each point\n        comparison_space_size_factor=1\n    )\n    ks = DC.curvature(G, t=15, dim=dim, idx=0)\n    return ks\n\n\nimport deepdish\n\n\n# load curvature battery\nbattery_file = \"/home/piriac/data/diffusion_curvature/Curvature_Colosseum_dikey.h5\"\nCC = deepdish.io.load(battery_file)\n\n\ncomputed_curvature = {}\nfor d in tqdm(CC['dims'][:1], desc=\"intrinsic dimensions\"):\n    computed_curvature[d] = {}\n    for c in tqdm(CC[d]['codims'][:1], leave=False, desc='codimensions'):\n        computed_curvature[d][c] = {}\n        for noise_level in tqdm(CC[d][c]['noise_levels'][:1], leave=False, desc=\"Noise Levels\"):\n            computed_curvature[d][c][noise_level] = {}\n            computed_curvature[d][c][noise_level]['k'] = []\n            # apply curvature function in parallel\n            # us = [(CC[d][c][noise_level]['Xs'][i], d) for i in range(len(CC[d][c][noise_level]['Xs']))]\n            # ks = parallel(curvature_function, us, n_workers=25)\n            # computed_curvature[d][c][noise_level]['k'] = ks\n            for i in trange(len(CC[d][c][noise_level]['Xs']), leave=False, desc=\"Samples\"):\n                X = CC[d][c][noise_level]['Xs'][i]\n                k = diffusion_curvature_of_pt(X, d)\n                computed_curvature[d][c][noise_level]['k'].append(k)\n\nKeyError: 'dims'\n\n\n\nimport matplotlib.pyplot as plt\n\n\nd = 2\nc = 1\nnoise_level = 0.0\nplt.scatter(CC[d][c][noise_level]['k'], computed_curvature[d][c][noise_level]['k'], alpha=0.1)\nplt.xlabel(\"True Curvature\")\nplt.ylabel(\"Computed Curvature\")\nplt.title(f\"Sanity Check in dim {d} and codim {c}\")\nplt.show()\n\n\n\n\n\nX.shape\n\n(1000, 3)\n\n\n\nfrom diffusion_curvature.utils import plot_3d\n\n\nplot_3d(X, use_plotly=True)\n\n\n                                                \n\n\n\nG = get_adaptive_graph(X) #graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    graph_former = get_adaptive_graph,\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1\n)\nks = DC.curvature(G, t=15, dim=2)\n\n\nplot_3d(X,ks,use_plotly=True)\n\n\n                                                \n\n\n\nfrom tqdm.auto import tqdm, trange\nfrom fastcore.all import *\n\n\n\ncompute_curvature_on_battery\n\n compute_curvature_on_battery (curvature_function, CC,\n                               restrict_to_first_n_dims=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncurvature_function\n\n\nfn that, given X and dim, returns the curvature of the first point\n\n\nCC\n\n\nthe battery dictionary\n\n\nrestrict_to_first_n_dims\nNoneType\nNone\n\n\n\n\n\nsaved_calcs = f\"/home/piriac/data/diffusion_curvature/computed_diffusion_curvatures_core_{name}.h5\"\nif os.path.exists(saved_calcs):\n    print(f\"Loading saved calculations from {saved_calcs}\")\n    computed_diffusion_curvatures = deepdish.io.load(saved_calcs)\nelse:\n    computed_diffusion_curvatures = compute_curvature_on_battery(diffusion_curvature_of_pt, CC)\n    deepdish.io.save(f\"/home/piriac/data/diffusion_curvature/computed_diffusion_curvatures_core_{name}.h5\", computed_diffusion_curvatures)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPearson Correlations\n\nfrom scipy.stats import pearsonr\n\n\n\ncompute_correlations\n\n compute_correlations (computed_curvature, CC)\n\n\n\n\n\nDetails\n\n\n\n\ncomputed_curvature\nthe computed curvature\n\n\nCC\nthe battery dictionary\n\n\n\n\ndc_curvature_correlations = compute_correlations(computed_diffusion_curvatures, CC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyError: 3\n\n\n\nfrom tabulate import tabulate\n\n\n\n\nresult_table\n\n result_table (correlations, c:int, style='fancy_grid', keys=['r', 'p'])\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncorrelations\n\n\ndictionary of correlations\n\n\nc\nint\n\ncodimension\n\n\nstyle\nstr\nfancy_grid\n\n\n\nkeys\nlist\n[‘r’, ‘p’]\n\n\n\n\n\ntable = result_table(dc_curvature_correlations, c=1)\n\n\ntable = result_table(dc_curvature_correlations, c=2)\n\n\ntable = result_table(dc_curvature_correlations, c=3)\n\n\ntable_latex = result_table(dc_curvature_correlations, c=1, style='latex_raw')\ntable_latex += result_table(dc_curvature_correlations, c=2, style='latex_raw')\ntable_latex += result_table(dc_curvature_correlations, c=3, style='latex_raw')\n\n\nimport matplotlib.pyplot as plt\n\n\nd = 2\nc = 1\nnoise_level = 0.0\nplt.scatter(CC[d][c][noise_level]['k'], computed_diffusion_curvatures[d][c][noise_level]['k'], alpha=0.1)\nplt.xlabel(\"True Curvature\")\nplt.ylabel(\"Computed Curvature\")\nplt.title(f\"Correlation = {dc_curvature_correlations[d][c][noise_level]['r']:.3f}\")\nplt.show()\n\n\n\n\n\n\n\nFidelity of Sign\nThe above shows that the unsigned diffusion curvature correlates robustly with the true curvature. Let’s measure how well the sign is predicted by diffusion curvature.\n\nimport numpy as np\n\n\n\ncompute_sign_score\n\n compute_sign_score (computed_curvature, CC)\n\n\n\n\n\nDetails\n\n\n\n\ncomputed_curvature\nthe computed curvature\n\n\nCC\nthe battery dictionary\n\n\n\n\nsign_accs = compute_sign_score(computed_diffusion_curvatures, CC)\n\n\ntable = result_table(sign_accs, c=2, keys=['accuracy'])"
  },
  {
    "objectID": "experiments/3e2 Neural Flattening with Gromov Wasserstein.html",
    "href": "experiments/3e2 Neural Flattening with Gromov Wasserstein.html",
    "title": "3e2 Neural Flattening with Gromov Wasserstein",
    "section": "",
    "text": "Any measurement of curvature must deal with the confounding influence of density. The high-frequency effects of sampling, including regions of sparsity and pockets of density, are locally indistinguishable from curvature. There are two ways of dealing with this: we can either build a sufficiently robust measurement with high enough noise tolerance that these local density effects don’t matter, or we can adapt the measurement to them, by comparing to a euclidean space with approximately the same sampling.\nThis notebook explores one move towards the second option, the Gromov Wasserstein distance, which takes an OT like distance between points in distinct space. It works by searching over all possible couplings of points between the two spaces \\(X,Y\\) to minimize the discrepancy within a coupling \\(\\gamma\\), defined as\n\\[\\int \\int d_{X}(x - x') - d_{Y}(y - y') \\, d\\gamma(x,y) \\, d \\gamma(x',y')\\]\nThe Gromov Wasserstein distance is routinely used to recognize objects that might be changing shape, for example several pointclouds made from a hand with fingers in positions of varying curvature. This suggests that GW gives us some robustness against curvature, being partially blind to it. As long as the points within the manifold have the same proximal relation to each other, their orientation in space doesn’t matter.\nSo here’s the idea: given a manifold region surrounding some point whose curvature we want to know, we’ll use GW to construct a neurally flattened version of this region by learning a positioning of points in a euclidean space of the manifold’s intrinsic dimension to minimize the GW distance between this flattened space and the manifold. Ideally, this will recapitulate all of the density artifacts of our region, but now within a flattened space.\n\nHow does GW reconstruct curvature vs density?\nThe trouble, of course, is that curvature - over a global level - does change the relations of points. In higher curvature settings, there’s more interconnectivity. Our goal with this preliminary experiment is to assess the degree to which the curvature-based differences in graph connectivity are weighted by GW versus the density-based differences. The hypothesis is that density artifacts are preserved more faithfully.\nTo measure this, we’ll rig together a simple test case by measuring the GW distance between\n\na neighborhood sampled from a sphere\nPCA projections of this neighborhood, with various amounts of noise added\n\nWe’ll then visually inspect the PCA projections with the lowest distance, to see how well they recreate the sampling artifacts on the sphere.\n\nX_sphere, ks_sphere = sphere(1000) # keep it relatively sparse\nX_cap_of_sphere = X_sphere[X_sphere[:,2] &gt; 0.7] # Just the itty bitty polar top\n\n\nprint(len(X_cap_of_sphere))\nplot_3d(X_cap_of_sphere,use_plotly=True)\nplt.scatter(X_cap_of_sphere[:,0],X_cap_of_sphere[:,1])\n\n143\n\n\n\n                                                \n\n\n&lt;matplotlib.collections.PathCollection at 0x7f85326081d0&gt;\n\n\n\n\n\nThe PCA projection here is just the x and y coords. Note that although this is ‘flattened’, it retains some peculiarities of the projection. For instance, the density of points is higher around the edges and sparser in the middle.\n\nX_pca = X_cap_of_sphere[:,:2]\n\nWe hope the Gromov-Wasserstein will reward flat spaces that retain the density quirks but get rid of the these projection artifacts. To measure, we’ll sample several flat spaces\n\nDifferent samples of noise added to X_pca\nRandom samplings of the plane.\n\n\nfrom diffusion_curvature.core import get_adaptive_graph\n\n\nA_pca = get_adaptive_graph(X_pca).W\nplt.imshow(A_pca)\n\n&lt;matplotlib.image.AxesImage at 0x7f84007174d0&gt;\n\n\n\n\n\n\nimport ot\n\n\nclass NoisedPCA():\n    def __init__(self, X, sigma):\n        self.sigma = sigma\n        self.noise = np.random.normal(size = X.shape, loc = 0, scale = sigma)\n        self.X = X + self.noise\n        self.A = get_adaptive_graph(self.X).W\n        self.A /= self.A.max()\n    def compute_distance(self, A_real):\n        # Projected Gradient algorithm with entropic regularization\n        A_real /= A_real.max()\n        n_samples = len(A_real)\n        p = ot.unif(n_samples)\n        q = ot.unif(n_samples)\n        gwe, loge = ot.gromov.entropic_gromov_wasserstein(\n        self.A, A_real, p, q, 'square_loss', epsilon=5e-4, solver='PGD',\n        log=True, verbose=False)\n        self.distance = loge['gw_dist']\n        self.coupling = gwe # the coupling, T\n\ncomparison_spaces = []\nfor sigma in tqdm([0.05, 0.1, 0.15, 0.2, 0.3]):\n    for trials in trange(10, leave=False):\n        NP = NoisedPCA(X_pca, sigma)\n        NP.compute_distance(A_pca)\n        comparison_spaces.append(NP)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncomparison_spaces.sort(key=lambda x: x.distance)\n\n\n# order the spaces with corresponding idxs, using the coupling map\ndef order_comparison_space(C):\n    ordering = np.arange(len(C.T)) @ C.T\n    X_ordered = C.X[ordering]\n\n\ni = 1\nplt.scatter(comparison_spaces[i].X[:,0], comparison_spaces[i].X[:,1])\nplt.title(f\"Sampling {i} with sigma {comparison_spaces[i].sigma} has GW Distance {comparison_spaces[i].distance}\")\n\nText(0.5, 1.0, 'Sampling 1 with sigma 0.05 has GW Distance 0.0022035801608677992')\n\n\n\n\n\n\ni = 5\nplt.scatter(comparison_spaces[i].X[:,0], comparison_spaces[i].X[:,1])\nplt.title(f\"Sampling {i} with sigma {comparison_spaces[i].sigma} has GW Distance {comparison_spaces[i].distance}\")\n\nText(0.5, 1.0, 'Sampling 5 with sigma 0.05 has GW Distance 0.0026334806113825094')"
  },
  {
    "objectID": "experiments/3b Hickok Comparison.html",
    "href": "experiments/3b Hickok Comparison.html",
    "title": "diffusion_curvature",
    "section": "",
    "text": "scalar_curvature_est\n\n scalar_curvature_est (n, X=None, n_nbrs=20, kernel=None, density=None,\n                       Rdist=None, T=None, nbr_matrix=None, verbose=True)\n\n\n\n\nKDE\n\n KDE (n, X=None, D=None, kernel=None)"
  },
  {
    "objectID": "experiments/Examples.html",
    "href": "experiments/Examples.html",
    "title": "Examples",
    "section": "",
    "text": "from diffusion_curvature.datasets import *\nfrom diffusion_curvature.core import *\nfrom diffusion_curvature.core import DiffusionCurvature, get_adaptive_graph\nfrom diffusion_curvature.kernels import *\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport graphtools\n\n\ndef visualize_2_curvatures(X,k1,k2):\n    \"\"\"Makes two side-by-side 3d plots of X, the first colored by k1, the second by k2. A colorbar accompanies each.\"\"\"\n    fig = plt.figure(figsize=(12,6))\n    ax1 = fig.add_subplot(121, projection='3d')\n    ax2 = fig.add_subplot(122, projection='3d')\n    ax1.scatter(X[:,0], X[:,1], X[:,2], c=k1, cmap='jet')\n    ax2.scatter(X[:,0], X[:,1], X[:,2], c=k2, cmap='jet')\n    ax1.set_title('Gaussian curvature')\n    ax2.set_title('Diffusion curvature')\n    fig.colorbar(ax1.scatter(X[:,0], X[:,1], X[:,2], c=k1, cmap='jet'), ax=ax1)\n    fig.colorbar(ax2.scatter(X[:,0], X[:,1], X[:,2], c=k2, cmap='jet'), ax=ax2)\n    plt.show()\n\nFor the hyperboloid, we found these parameters to be most impactful:\n\nanisotropy=1, when constructing the Graphtools graph. This combats some of the fluctuations in curvature caused by local density variations.\nknn=10: large enough to allow diffusion to cover the graph, local enough to capture the curvature\n\nNote that our pointcloud, unlike the ideal hyperboloid, cuts off at the top and bottom, causing diffusion to rebound and giving the impression of higher curvatures.\n\nX_hyperboloid, ks_hyperboloid = hyperboloid(3000)\nG_hyperboloid = get_adaptive_graph(X_hyperboloid) # graphtools.Graph(X_hyperboloid, knn=10, anisotropy=1)\nDC = DiffusionCurvature()\nG_hyperboloid = DC.curvature(G_hyperboloid, dim=2, t=25)\nvisualize_2_curvatures(X_hyperboloid, ks_hyperboloid, G_hyperboloid.ks)\n\n2023-12-19 19:03:52.481334: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 25370427392\nCUDA backend failed to initialize: INTERNAL: no supported devices found for platform CUDA (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\nAttributeError: 'ArrayImpl' object has no attribute 'ks'\n\n\nAs the sphere shows,\n\nX_sphere, ks_sphere = sphere(3000)\nG_sphere = graphtools.Graph(X_sphere, knn=15, anisotropy=1)\nDC = DiffusionCurvature(t=15)\nG_sphere = DC.curvature(G_sphere,dimension=2)\nvisualize_2_curvatures(X_sphere, ks_sphere, G_sphere.ks)\n\n\n\n\n\nPure Graphs\nDiffusion curvature was designed for pointclouds, and it’s in this domain that it shows the clearest advantages over competing methods, like Ollivier Ricci curvature. But it can also be used directly on an adjacency matrix. Here’s how:"
  },
  {
    "objectID": "experiments/3d Detecting Negative Curvature.html",
    "href": "experiments/3d Detecting Negative Curvature.html",
    "title": "3d Detecting Negative Curvature",
    "section": "",
    "text": "One puzzling fact brought to light by our “curvature colosseum” is that all methods struggle mightily to label high-dimensional datasets with any negative curvature. The Pearson correlation with the scalar curvature is robust – but the actual values are always positive. What’s up?\nHere we investigate one hypothesis: sparse sampling affects the measurement of negative curvature more strongly than positive curvature.\nTo test this, we’ll experiment on a 3-saddle, sampled at varying densities. We’ll plot the reported curvature versus the density, then compare this to the same measurements taken on a positive region.\n\nimport sympy as sp\nfrom diffusion_curvature.random_surfaces import rejection_sample_from_surface, scalar_curvature_at_origin\ndef rejection_sample_from_saddle(n_samples=1000, intrinsic_dim = 2, verbose=False, intensity=1):\n    d = intrinsic_dim\n    vars = sp.symbols('x0:%d' % d)\n    saddle = sp.Matrix([*vars])\n    for i in range(d,d+1):\n        saddle = saddle.row_insert(i, sp.Matrix([intensity*sum([(-1)**j * vars[j]**2 for j in range(d)])]))\n    if verbose: print(saddle)\n    k = scalar_curvature_at_origin(saddle)\n    return rejection_sample_from_surface(saddle, n_samples), k\n\nAs a sanity check, here’s the diffusion curvature of a 2-saddle.\n\nX, k = rejection_sample_from_saddle(1000, 2, intensity=2)\nG = graphtools.Graph(X, anisotropy=1, knn=5, decay=None).to_pygsp()\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Mean Fixed\",\n    comparison_method=\"Subtraction\",\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1\n)\nks = DC.curvature(G, t=25, dim=2, knn=5)\nplot_3d(X,ks, colorbar=True, title = f\"Diffusion Curvature of Saddle with {k=}\")\nprint(\"Curvature of center point = \",ks[0])\n\n\n\n\nCurvature of center point =  -0.1267333\n\n\n\nX, k = rejection_sample_from_saddle(1000, 7)\nprint(k)\n\n-24.0\n\n\n\nimport graphtools\nfrom diffusion_curvature.core import DiffusionCurvature\n\n\nks_dc = []\ndim = 2\nsamplings = np.arange(1000,20000,500) \nfor n_points in tqdm(samplings):\n    X, k = rejection_sample_from_saddle(n_points, dim)\n    # Compute Diffusion Curvature\n    G = graphtools.Graph(X, anisotropy=1, knn=5, decay=None).to_pygsp()\n    DC = DiffusionCurvature(\n        laziness_method=\"Entropic\",\n        flattening_method=\"Mean Fixed\",\n        comparison_method=\"Subtraction\",\n        points_per_cluster=None, # construct separate comparison spaces around each point\n        comparison_space_size_factor=1\n    )\n    ks = DC.curvature(G, t=25, dim=dim, knn=5, idx=0)\n    ks_dc.append(ks)\n# plot the number of points versus the ks_dc\nplt.plot(samplings, ks_dc)\nplt.title(f\"Diffusion Curvature of {dim}-Saddle with Different Samplings. (Ground truth k={k})\")\nplt.xlabel(\"Number of Points\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n\n\nText(0, 0.5, 'Diffusion Curvature')\n\n\n\n\n\nThere’s a troubling amount of variance between samplings of the saddling.\n\nks_dc = []\ndim = 3\nsamplings = np.arange(1000,20000,500) \nfor n_points in tqdm(samplings):\n    X, k = rejection_sample_from_saddle(n_points, dim)\n    # Compute Diffusion Curvature\n    G = graphtools.Graph(X, anisotropy=1, knn=5, decay=None).to_pygsp()\n    DC = DiffusionCurvature(\n        laziness_method=\"Entropic\",\n        flattening_method=\"Mean Fixed\",\n        comparison_method=\"Subtraction\",\n        points_per_cluster=None, # construct separate comparison spaces around each point\n        comparison_space_size_factor=1\n    )\n    ks = DC.curvature(G, t=25, dim=dim, knn=5, idx=0)\n    ks_dc.append(ks)\n# plot the number of points versus the ks_dc\nplt.plot(samplings, ks_dc)\nplt.title(f\"Diffusion Curvature of {dim}-Saddle with Different Samplings. (Ground truth k={k})\")\nplt.xlabel(\"Number of Points\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n\n\nText(0, 0.5, 'Diffusion Curvature')\n\n\n\n\n\n\nks_dc = []\ndim = 4\nsamplings = np.arange(1000,20000,500) \nfor n_points in tqdm(samplings):\n    X, k = rejection_sample_from_saddle(n_points, dim)\n    # Compute Diffusion Curvature\n    G = graphtools.Graph(X, anisotropy=1, knn=5, decay=None).to_pygsp()\n    DC = DiffusionCurvature(\n        laziness_method=\"Entropic\",\n        flattening_method=\"Mean Fixed\",\n        comparison_method=\"Subtraction\",\n        points_per_cluster=None, # construct separate comparison spaces around each point\n        comparison_space_size_factor=1\n    )\n    ks = DC.curvature(G, t=25, dim=dim, knn=5, idx=0)\n    ks_dc.append(ks)\n# plot the number of points versus the ks_dc\nplt.plot(samplings, ks_dc)\nplt.title(f\"Diffusion Curvature of {dim}-Saddle with Different Samplings. (Ground truth k={k})\")\nplt.xlabel(\"Number of Points\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n\n\nText(0, 0.5, 'Diffusion Curvature')\n\n\n\n\n\nSo it is possible to pick up negative diffusion curvature in higher dimensions – but it takes a lot of points!\n\nCloser Investigation of Variance between Samplings of the saddle\n\nks_dc = []\ndim = 3\nsamplings = [2000]*100\nXs_sampled = []\nfor n_points in tqdm(samplings):\n    X, k = rejection_sample_from_saddle(n_points, dim)\n    Xs_sampled.append(X)\n    # Compute Diffusion Curvature\n    G = graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\n    DC = DiffusionCurvature(\n        laziness_method=\"Entropic\",\n        flattening_method=\"Mean Fixed\",\n        comparison_method=\"Subtraction\",\n        points_per_cluster=None, # construct separate comparison spaces around each point\n        comparison_space_size_factor=1\n    )\n    ks = DC.curvature(G, t=25, dim=dim, knn=5, idx=0)\n    ks_dc.append(ks)\n# plot a histogram of the diffusion curvatures\nplt.hist(ks_dc, bins=20)\n\n\n\n\n(array([ 2.,  2.,  2.,  7.,  3., 10.,  7.,  5., 10.,  8.,  9.,  7.,  6.,\n         8.,  3.,  3.,  2.,  3.,  1.,  2.]),\n array([-1.12866116, -1.12302792, -1.1173948 , -1.11176157, -1.10612845,\n        -1.10049522, -1.09486198, -1.08922887, -1.08359563, -1.07796252,\n        -1.07232928, -1.06669605, -1.06106293, -1.0554297 , -1.04979658,\n        -1.04416335, -1.03853011, -1.032897  , -1.02726376, -1.02163064,\n        -1.01599741]),\n &lt;BarContainer object of 20 artists&gt;)\n\n\n\n\n\n\n\nVisual Investigations of the Saddle\n\n# sort Xs_sorted by the curvatures ks_dc, from highest to lowest\nXs_sorted = [Xs_sampled[i] for i in np.argsort(ks_dc)[::-1]]\n\n\ndegenerate_X = Xs_sorted[0]\nsignal = np.zeros(degenerate_X.shape[0])\nsignal[0] = 1\nplot_3d(degenerate_X, signal, title = \"A difficult-to-graph saddle\", use_plotly=True)\n\n\n                                                \n\n\n\ndegenerate_X = Xs_sorted[1]\nsignal = np.zeros(degenerate_X.shape[0])\nsignal[0] = 1\nplot_3d(degenerate_X, signal, title = \"Another difficult-to-graph saddle\", use_plotly=True)\n\n\n                                                \n\n\n\ndegenerate_X = Xs_sorted[2]\nsignal = np.zeros(degenerate_X.shape[0])\nsignal[0] = 1\nplot_3d(degenerate_X, signal, title = \"Yet another difficult-to-graph saddle\", use_plotly=True)\n\n\n                                                \n\n\nThese ancdata confirm a suspicion: the graphs of these mis-diagnosed saddles are deranged because they have these big holes close to the center point that give the appearance of positive curvature. Diffusion from the center point is reflected by the boundary of the hole, increasing the perceived laziness.\nHow to counter this? I have a few ideas.\n\n\nPHATE Denoising of the Graph\nLet’s try a tact suggested by E.B.: using PHATE distances to construct a new “denoised” graph, which (one hopes) has fewer spurious connections and more consistent curvature.\n\nfrom diffusion_curvature.distances import phate_distances_differentiable\nfrom diffusion_curvature.vne import optimal_t_via_vne\nfrom diffusion_curvature.utils import *\nfrom diffusion_curvature.heat_diffusion import jax_power_matrix\n\n\ndef phate_denoised_graph(\n    X, \n    t = None,\n    knn=15,\n):\n    \"\"\"\n    Computes PHATE distances on graph, \n    then returns a new graph built with this distance matrix.\n    \"\"\"\n    G_old = graphtools.Graph(X, anisotropy=1, knn=knn, decay=None).to_pygsp()\n    P = diff_op(G_old).todense() # is sparse, by default\n    P = jnp.array(P)\n    if t is None: t = optimal_t_via_vne(P)\n    Pt = jax_power_matrix(P,t)\n    Pt_cpu = jax.device_put(Pt, jax.devices('cpu')[0])\n    D = phate_distances_differentiable(Pt_cpu).numpy()\n    # construct graph\n    G = graphtools.Graph(D, anisotropy=1, knn=5, decay=20, precomputed=\"distance\").to_pygsp()\n    return G\n\n\nX, k = rejection_sample_from_saddle(3000, 2)\nG = phate_denoised_graph(X,t=25)\n\n\nks_dc = []\ndim = 2\nsamplings = np.arange(1000,20000,500) \nfor n_points in tqdm(samplings):\n    X, k = rejection_sample_from_saddle(n_points, dim)\n    # Compute Diffusion Curvature\n    G = phate_denoised_graph(X,t=25)\n    DC = DiffusionCurvature(\n        laziness_method=\"Entropic\",\n        flattening_method=\"Mean Fixed\",\n        comparison_method=\"Subtraction\",\n        points_per_cluster=None, # construct separate comparison spaces around each point\n        comparison_space_size_factor=1\n    )\n    ks = DC.curvature(G, t=25, dim=dim, knn=5, idx=0)\n    ks_dc.append(ks)\n# plot the number of points versus the ks_dc\nplt.plot(samplings, ks_dc)\nplt.title(f\"Diffusion Curvature of {dim}-Saddle with Different Samplings. (Ground truth k={k})\")\nplt.xlabel(\"Number of Points\")\nplt.ylabel(\"Diffusion Curvature\")"
  },
  {
    "objectID": "experiments/3a1a DC of LowD High Sample Battery.html",
    "href": "experiments/3a1a DC of LowD High Sample Battery.html",
    "title": "3a1a Computing the diffusion curvature of the battery",
    "section": "",
    "text": "name = \"lowd_highsamples\"\n\n\ndef diffusion_curvature_of_pt(X, dim):\n    graph_former = partial(\n        get_adaptive_graph, k=15,\n    )\n    G = graph_former(X) #graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\n    DC = DiffusionCurvature(\n        laziness_method=\"Entropic\",\n        flattening_method=\"Fixed\",\n        comparison_method=\"Subtraction\",\n        graph_former = graph_former,\n        points_per_cluster=None, # construct separate comparison spaces around each point\n        comparison_space_size_factor=1\n    )\n    ks = DC.curvature(G, t=15, dim=dim, idx=0)\n    return ks\n\n\n# load curvature battery\nbattery_file = \"/home/piriac/data/diffusion_curvature/Curvature_Colosseum_LowD_HighSampled.h5\"\nCC = deepdish.io.load(battery_file)\n\n\nCC\n\n{'dims': [2, 3],\n 2: {'codims': [1],\n  1: {'noise_levels': [0.0],\n   0.0: {'Xs': [array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.95640816, -0.02246371,  0.36863864],\n            [-0.40320402,  0.73988065,  1.75622989],\n            ...,\n            [ 0.03834261, -0.8980153 , -0.57845877],\n            [ 0.12822575, -0.07889399, -0.16749644],\n            [-0.56596365, -0.97877089,  0.20525702]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.52833845,  0.2363624 ,  0.80735627],\n            [-0.80514902,  0.41627454,  2.00266582],\n            ...,\n            [-0.28023072,  0.63784418,  1.11836598],\n            [-0.27641066,  0.84835173,  1.71673899],\n            [ 0.96846278, -0.88421014,  3.90829755]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.40755058, -0.63885716, -0.4457507 ],\n            [ 0.18326285,  0.85257864, -1.45348568],\n            ...,\n            [-0.56448538,  0.22306108,  0.4208769 ],\n            [-0.16495575, -0.52949789,  0.59905505],\n            [ 0.14768841,  0.47786333, -0.76997722]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.68383444,  0.57495065, -0.48139744],\n            [ 0.17306001, -0.97099862, -1.45979699],\n            ...,\n            [ 0.60051973, -0.64824879, -0.63905132],\n            [-0.24855214, -0.82104643, -1.12136314],\n            [ 0.87573823, -0.92602815, -0.97368378]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.3419848 ,  0.64660485, -0.27066422],\n            [ 0.78702079, -0.41142326, -1.48687092],\n            ...,\n            [ 0.93118273, -0.35466841, -1.7707051 ],\n            [ 0.60394356, -0.72338134, -1.69073476],\n            [ 0.48410696, -0.8349131 , -1.70148629]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.32293231, -0.31281593,  0.25279485],\n            [ 0.77278193,  0.49654779,  1.69187248],\n            ...,\n            [ 0.2207407 ,  0.53592642,  0.94825362],\n            [ 0.05868674,  0.92878446,  1.92797081],\n            [-0.66956072,  0.55988679,  1.69949952]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.70195222,  0.00721277, -0.930013  ],\n            [-0.15980338,  0.87659812, -3.13574964],\n            ...,\n            [ 0.62113428, -0.94298289, -2.42071268],\n            [ 0.50081212, -0.58961453, -0.99907167],\n            [-0.7920292 , -0.88036539,  0.10275619]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.68056321,  0.48593048, -1.73069723],\n            [ 0.40226152,  0.61694689, -1.79364024],\n            ...,\n            [-0.45299238,  0.72822499, -0.5242996 ],\n            [-0.67091591,  0.59700351,  0.28648384],\n            [ 0.76868672,  0.50855442, -1.90744224]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.63963882,  0.68625124,  3.08819419],\n            [ 0.46831365, -0.69008992,  0.48720757],\n            ...,\n            [-0.36229193, -0.35195947, -1.29529894],\n            [-0.30140959, -0.64681776, -1.60681475],\n            [ 0.85813518,  0.15234654,  3.03760561]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.62872444,  0.54533823,  0.63861911],\n            [-0.76395598, -0.60322815,  1.77226546],\n            ...,\n            [-0.30843095, -0.02252248,  0.40032571],\n            [ 0.19738249,  0.07014657, -0.26751452],\n            [-0.57077104, -0.1986304 ,  0.91954113]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.23954244,  0.96572695,  0.5859547 ],\n            [ 0.18833457,  0.31716208, -0.08997093],\n            ...,\n            [ 0.12400812, -0.81690239,  0.05424191],\n            [-0.75130491,  0.00411133, -0.75832366],\n            [-0.08129252, -0.97613857,  0.04129495]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.80719343, -0.25873688, -1.43536467],\n            [ 0.6669801 ,  0.6480634 , -0.30071248],\n            ...,\n            [-0.11137854,  0.51110896, -0.07216077],\n            [-0.30129164,  0.64965388, -0.43428905],\n            [-0.95774682,  0.26611323, -2.36486363]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.74782038, -0.70951912, -1.65716108],\n            [ 0.10559992, -0.68255662, -0.39299342],\n            ...,\n            [-0.30394751, -0.22842677, -0.55738118],\n            [-0.48946622,  0.36607431, -0.74384512],\n            [-0.45649532, -0.51862228, -0.98724821]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.54372929,  0.97119474,  3.30076543],\n            [ 0.80577811, -0.34722749, -2.78012321],\n            ...,\n            [-0.92071864, -0.08950097,  1.31086613],\n            [ 0.73651377,  0.15312551, -1.21439464],\n            [-0.86204111,  0.06721575,  1.52186868]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.58870606,  0.34158556, -0.5701992 ],\n            [ 0.44025686, -0.79308852, -1.0795271 ],\n            ...,\n            [ 0.2357718 , -0.67870654, -0.76127234],\n            [ 0.99754859, -0.2115336 ,  0.37703746],\n            [-0.63831433, -0.79879158, -0.44143523]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.84177875,  0.09947028, -1.78041274],\n            [-0.43901199,  0.1415575 , -0.62017878],\n            ...,\n            [ 0.17895153, -0.98439664, -0.65482009],\n            [-0.88296219, -0.55693609, -2.96530782],\n            [-0.7872102 ,  0.856256  , -0.98285316]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.92159824, -0.35959322,  2.23441167],\n            [ 0.46758255, -0.55280877,  1.69844848],\n            ...,\n            [ 0.49563819, -0.34841924,  1.35005684],\n            [ 0.99735541, -0.92362349,  3.62067136],\n            [ 0.90354831,  0.20245468,  0.96102986]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.72048868,  0.79732778,  1.49802403],\n            [-0.05748901, -0.29619579, -0.1890759 ],\n            ...,\n            [-0.09045914,  0.19703081,  0.10259463],\n            [ 0.72094648,  0.79817844,  1.50007255],\n            [-0.53966625, -0.73877183,  0.66030771]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.75514579, -0.12929473, -1.08834593],\n            [-0.13559992, -0.09373943, -0.13803568],\n            ...,\n            [ 0.61605514,  0.01788049,  0.06609196],\n            [-0.24867971, -0.51058949, -0.4684627 ],\n            [-0.86619281, -0.46351743, -1.72632725]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.21396198, -0.99075567,  3.28760304],\n            [-0.19505195, -0.91393249,  2.37644646],\n            ...,\n            [-0.1576565 , -0.25609052,  0.43313634],\n            [ 0.57056722,  0.31874977, -0.56486906],\n            [ 0.64794351,  0.72992679, -1.27276815]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.9392148 , -0.78129107,  1.00319121],\n            [-0.46424868, -0.04594144,  0.67941076],\n            ...,\n            [ 0.8074371 , -0.79429325, -2.45129482],\n            [ 0.48308263, -0.76041583, -2.2435603 ],\n            [-0.61516289,  0.77437804,  0.41151842]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.93118241,  0.65800566,  0.83442956],\n            [-0.71152194, -0.84021166,  0.14215528],\n            ...,\n            [ 0.30644622,  0.00347832,  0.05340058],\n            [ 0.68266382, -0.65689313, -0.26365165],\n            [ 0.4857084 ,  0.91080409,  0.20828988]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.27099667,  0.60332836,  0.06983312],\n            [ 0.78753304, -0.11283414,  1.00256938],\n            ...,\n            [ 0.49335747,  0.33696325, -0.13830013],\n            [ 0.57580259,  0.54749191, -0.26306385],\n            [-0.19803344,  0.90627811,  0.16725844]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.82775145, -0.29718978, -0.03523782],\n            [-0.93850296,  0.97870963, -1.96835882],\n            ...,\n            [-0.40428654, -0.7845258 , -0.32340853],\n            [-0.35750553,  0.99159407, -1.59962295],\n            [-0.66044303, -0.03925582, -0.09544771]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.73304777,  0.00842576,  1.98391379],\n            [ 0.98793222, -0.33355594,  3.0367709 ],\n            ...,\n            [ 0.78128305,  0.88989008,  3.31717092],\n            [ 0.91947669, -0.60393895,  2.83143754],\n            [-0.10375547, -0.56631023,  0.85888615]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.35745503,  0.45697557,  1.23475464],\n            [ 0.84478143,  0.83743281,  3.92540714],\n            ...,\n            [-0.68195349,  0.69194138,  1.71607256],\n            [-0.73079789,  0.60809197,  1.53270804],\n            [-0.05067352, -0.21215596, -0.07601478]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.06901802,  0.84527669,  0.99841906],\n            [-0.09729896, -0.57573219,  1.00369795],\n            ...,\n            [-0.46462878, -0.54347888,  1.51880387],\n            [-0.20785671,  0.99612086,  0.94611042],\n            [ 0.12248063, -0.44386555,  0.44522082]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.42559469,  0.77971357,  1.13984993],\n            [-0.14332617,  0.63033025,  0.83973734],\n            ...,\n            [-0.76091504,  0.97750228,  2.51901301],\n            [ 0.73508963,  0.57306284,  0.53428363],\n            [-0.48253651, -0.1916221 ,  0.74775262]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.88184537,  0.70263777, -1.65930649],\n            [ 0.93760723, -0.01503011,  1.12682186],\n            ...,\n            [ 0.39538248, -0.17716305,  0.3621344 ],\n            [-0.31187111, -0.02377279,  0.35562695],\n            [ 0.20869874,  0.58828502, -1.37978613]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.81035684,  0.10082623, -0.01477162],\n            [ 0.90926826,  0.95387029, -3.49971289],\n            ...,\n            [-0.4896629 ,  0.65237706, -1.91848287],\n            [-0.55260594,  0.76786014, -2.4160592 ],\n            [ 0.50251776,  0.72980199, -2.1205714 ]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.46752482, -0.8616545 ,  1.60167081],\n            [ 0.28239371,  0.77105414,  0.59176527],\n            ...,\n            [ 0.14348745, -0.43284849,  0.56662947],\n            [-0.18113386, -0.25168433, -0.23124463],\n            [-0.46603031, -0.00900792, -0.97493801]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.70841605, -0.69552856, -3.04875745],\n            [ 0.93549813, -0.59547566,  2.35812404],\n            ...,\n            [ 0.78158432,  0.50656867,  0.21701101],\n            [ 0.41974801,  0.92080789, -0.83357282],\n            [ 0.43597551, -0.36965601,  0.72781181]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.22840995, -0.90557301,  0.48102365],\n            [-0.38151973, -0.73840031,  0.33205262],\n            ...,\n            [ 0.62886138,  0.84609839,  0.47684375],\n            [ 0.04984079,  0.28858161, -0.01353944],\n            [ 0.75968552, -0.59142976,  0.63521186]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.48174751, -0.71606509,  0.29168757],\n            [-0.51143935, -0.54808111,  0.98629109],\n            ...,\n            [ 0.18166291, -0.95363341, -0.15192559],\n            [ 0.26701446, -0.56916634,  0.31444147],\n            [-0.19213116, -0.96049985,  0.14296431]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.56801227, -0.75619012,  0.85131545],\n            [-0.90860551,  0.46397176,  2.50345134],\n            ...,\n            [-0.029462  , -0.67271633,  0.03624397],\n            [-0.09715213,  0.71429685,  0.48653472],\n            [ 0.44346092, -0.48268942,  0.33586649]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.17618996,  0.60923453,  1.56356085],\n            [-0.31218994,  0.87203663,  2.56428665],\n            ...,\n            [-0.22638293,  0.90868759,  2.82489988],\n            [ 0.82116069,  0.95817182,  3.51401376],\n            [ 0.83196304,  0.46348753,  0.90612137]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.95470009, -0.09513379,  1.20870301],\n            [ 0.93102473,  0.56242337, -0.28587929],\n            ...,\n            [-0.80401281, -0.11170554,  1.09179829],\n            [ 0.51011763,  0.40037387, -0.12252893],\n            [-0.38413565,  0.44624232,  1.10291656]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.76175972,  0.9622692 ,  3.7027247 ],\n            [-0.68150253, -0.78516578,  2.20716832],\n            ...,\n            [-0.35245749, -0.72515413,  1.17778004],\n            [ 0.35848474, -0.87658768,  1.34273839],\n            [ 0.97028938, -0.69537463,  2.76285718]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.64015411, -0.14766579,  0.43478678],\n            [ 0.8393534 , -0.32399379,  1.02917386],\n            ...,\n            [ 0.8866647 ,  0.80419462, -2.54845639],\n            [ 0.25767125,  0.36649959, -1.05483815],\n            [ 0.09147551,  0.69541593, -1.85295431]]),\n     array([[ 0.        ,  0.        , -0.        ],\n            [ 0.46611314, -0.88886445,  2.61756626],\n            [ 0.56227366,  0.44477685, -2.4513291 ],\n            ...,\n            [ 0.15641484,  0.76360996, -2.74599079],\n            [-0.79307265, -0.89981059,  2.58844346],\n            [-0.30038629,  0.89628001, -2.23960498]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.43616626, -0.94988861,  1.56216742],\n            [ 0.52749456,  0.97967934,  2.54716814],\n            ...,\n            [ 0.81910182, -0.64730623, -1.06975071],\n            [-0.79723514, -0.85568066,  1.22144611],\n            [ 0.18909841, -0.29944563, -0.14174294]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.70788351,  0.16901928,  0.58385877],\n            [ 0.8186907 ,  0.85719189,  4.03990588],\n            ...,\n            [ 0.46785242,  0.93036003,  3.86399017],\n            [-0.81537426, -0.7543394 ,  1.52411633],\n            [ 0.92568618,  0.32033366,  1.21389113]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.08386957,  0.11693751,  0.02566182],\n            [-0.85591278, -0.62267362, -1.63225829],\n            ...,\n            [-0.77171417,  0.86843831,  2.05075333],\n            [-0.21934225, -0.60663525, -0.09454086],\n            [-0.95661655, -0.3354538 , -1.65164255]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.8709931 , -0.27754409, -0.32825173],\n            [ 0.31920925,  0.96634609,  0.44989277],\n            ...,\n            [ 0.17209905, -0.19549891, -0.20657007],\n            [-0.40921382, -0.71250545, -1.02116754],\n            [ 0.29843177, -0.01812007, -0.04809388]]),\n     array([[ 0.        ,  0.        , -0.        ],\n            [ 0.90101168, -0.08275289, -2.22325057],\n            [-0.47063535,  0.8666154 , -1.58767885],\n            ...,\n            [-0.53693407, -0.99800713, -0.5977302 ],\n            [ 0.58736629,  0.12738877, -1.63843833],\n            [ 0.31970827,  0.79966345, -3.20492156]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.43719333, -0.10617949,  0.49265398],\n            [-0.56964038, -0.78172181,  0.86567211],\n            ...,\n            [-0.792483  ,  0.7770994 , -0.35778548],\n            [-0.66790627,  0.26057632,  0.49095243],\n            [-0.58963577,  0.11801001,  0.54281745]]),\n     array([[ 0.        ,  0.        , -0.        ],\n            [-0.38116453, -0.96731663,  2.00551339],\n            [ 0.10786189,  0.41441204, -1.11569762],\n            ...,\n            [ 0.69852331, -0.21346274, -0.24922295],\n            [ 0.12054468, -0.45562598,  1.00146985],\n            [-0.78638833, -0.86848546,  1.41743917]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.4236139 ,  0.41619434, -0.92462241],\n            [ 0.29756512, -0.16730916,  0.39025878],\n            ...,\n            [-0.35575296, -0.40319076,  0.2829158 ],\n            [ 0.92308181, -0.16637098,  0.52245746],\n            [ 0.30510953,  0.14848021, -0.27439564]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [-0.08770767,  0.21976838, -0.21007197],\n            [-0.9845334 ,  0.28178204,  0.92258083],\n            ...,\n            [ 0.39985943, -0.76411225,  1.02455704],\n            [-0.07872803,  0.77352802, -0.69399006],\n            [-0.28522793, -0.88081261,  1.89092189]]),\n     array([[ 0.        ,  0.        ,  0.        ],\n            [ 0.72486801, -0.10863555, -1.14725205],\n            [-0.77610466, -0.58133165,  1.9245843 ],\n            ...,\n            [-0.85778553, -0.81915152,  2.05680264],\n            [-0.83013222,  0.44691911,  2.32338345],\n            [ 0.91452364, -0.88980782, -1.90194036]])],\n    'k': [5.927669976373062,\n     26.22235466946866,\n     -0.03316944782019726,\n     -4.166079532351944,\n     8.923748074652892,\n     10.700883814240068,\n     15.326003302502556,\n     -7.8456883143870595,\n     2.76680579259889,\n     1.170252687413232,\n     -5.205578821838396,\n     2.6724434385806752,\n     1.66653637857433,\n     -1.979138109411313,\n     -5.862787588212144,\n     3.5978271429047046,\n     -0.7529947688252301,\n     -23.039596736076692,\n     -2.834904222404761,\n     -6.949578872406576,\n     -17.32231918615915,\n     -4.940423896530474,\n     5.058279445953586,\n     -0.0832180006144308,\n     10.187989559692639,\n     31.65775311002621,\n     1.2527636844562675,\n     10.063630099372622,\n     -25.505264992266117,\n     5.662566061376404,\n     0.19386233830147973,\n     -18.128116292135832,\n     0.9723108651422716,\n     -21.286910250211417,\n     -1.5098458587246348,\n     -11.576479954729633,\n     -13.338489332682911,\n     21.292182002594732,\n     -0.8489483936801433,\n     -2.5102583452292446,\n     -18.508048356792823,\n     -16.481197362471207,\n     -21.109075572202414,\n     -1.1146149589039254,\n     12.640954385572078,\n     -11.678689269681247,\n     -0.08324896916426006,\n     -6.136529056780218,\n     2.57405856981685,\n     -2.4825160352021878]}}},\n 3: {'codims': [1],\n  1: {'noise_levels': [0.0],\n   0.0: {'Xs': [array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.66644174,  0.13039481, -0.85484299, -0.01786597],\n            [-0.76863539, -0.84128297, -0.91865777,  3.42237636],\n            ...,\n            [-0.80149499,  0.74047032, -0.0098324 ,  0.0304671 ],\n            [ 0.49951235,  0.93039486, -0.99277753, -0.9500855 ],\n            [ 0.20491818,  0.86670819, -0.56865486, -0.48096033]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.89046958, -0.71629974,  0.42014847,  0.9736477 ],\n            [ 0.44535004, -0.83037915, -0.37450334, -2.2158849 ],\n            ...,\n            [-0.0122523 , -0.98663472,  0.84025593,  1.15478016],\n            [-0.18079369,  0.8334723 , -0.91513802,  0.27252437],\n            [-0.38192947,  0.25311041, -0.45814642, -0.2289131 ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.71808997,  0.13336152, -0.07486753, -1.35726789],\n            [ 0.13224712,  0.49630004,  0.04862322, -0.45533565],\n            ...,\n            [-0.88345507,  0.82038959,  0.74424961, -5.17591962],\n            [ 0.9950808 , -0.90663697, -0.54009959, -0.1994017 ],\n            [-0.69555301,  0.90651484,  0.66941391, -4.81289941]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.02932477,  0.58565558,  0.68039913,  1.18011551],\n            [-0.84904307,  0.6376825 , -0.406807  ,  1.08298871],\n            ...,\n            [ 0.8708455 , -0.43793416, -0.42572656,  0.09374731],\n            [ 0.85960339,  0.53643406,  0.0544426 ,  0.6170755 ],\n            [ 0.53238959,  0.54473656,  0.3822431 ,  0.92885381]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.11394458, -0.38643818,  0.66597496, -0.43143252],\n            [ 0.08733456, -0.03553093,  0.83568681,  0.23726885],\n            ...,\n            [-0.48968235, -0.64158381,  0.27212485, -1.3138608 ],\n            [ 0.62389172, -0.22328256, -0.41142498, -1.06991877],\n            [ 0.09978563, -0.67571757,  0.17196876, -0.8961064 ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.19920386, -0.66633949,  0.20863486, -0.47276082],\n            [ 0.9187616 , -0.0993208 , -0.18605208,  0.84113789],\n            ...,\n            [ 0.5530946 , -0.49576266,  0.3800899 , -0.2803455 ],\n            [ 0.15732007, -0.69535527, -0.43853909, -0.12960247],\n            [-0.27421029,  0.67232028,  0.78662612, -0.02799243]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.35417522, -0.82853479,  0.79061444,  0.28108221],\n            [ 0.80571163, -0.28189754, -0.81874895, -0.01533457],\n            ...,\n            [-0.42471711,  0.67346262, -0.92295597,  2.00179287],\n            [ 0.51818123, -0.7067401 ,  0.15330281,  0.74474143],\n            [-0.67497726,  0.1923381 , -0.96799564,  2.0813964 ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.0100054 , -0.68524841,  0.9205174 , -0.89256022],\n            [-0.84809942, -0.90122505,  0.31458905, -1.17690074],\n            ...,\n            [-0.8394331 ,  0.52641602,  0.48744038,  2.50326228],\n            [ 0.28563383,  0.35647865, -0.521134  ,  0.35338036],\n            [ 0.62921553, -0.53744813, -0.14023239, -0.26641755]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.02728175, -0.11644127,  0.23022908, -0.13081786],\n            [-0.57136874, -0.54888277,  0.25529673,  0.07795584],\n            ...,\n            [ 0.7498905 , -0.90821411, -0.79718215,  1.3039511 ],\n            [ 0.8383756 , -0.97110204,  0.02564818,  1.07219392],\n            [-0.41040692, -0.83183071,  0.52245788, -0.48042882]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.24765652,  0.53052073, -0.46093225, -0.28184307],\n            [-0.16438359,  0.67873907, -0.68715744,  0.4410151 ],\n            ...,\n            [-0.48933807,  0.33495829,  0.86923027, -0.25610894],\n            [-0.06224309,  0.15258009, -0.24301302,  0.32306068],\n            [-0.66968547,  0.27826352, -0.80359819,  1.58672265]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.80995807, -0.24900633, -0.9915048 ,  1.59462351],\n            [-0.15751099, -0.04071649, -0.9465692 ,  2.10785958],\n            ...,\n            [ 0.39377393,  0.84031475, -0.13139668, -1.08722859],\n            [ 0.53838104,  0.19448517,  0.24728933, -0.09640471],\n            [ 0.31940389,  0.31580121, -0.63924948,  0.4057041 ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.34630168,  0.97222702,  0.00788444,  0.02359417],\n            [ 0.69551595, -0.3783164 , -0.44978726, -0.56790311],\n            ...,\n            [-0.84523806, -0.42350616, -0.24324408,  1.05792742],\n            [ 0.47985055, -0.43447616, -0.96091292, -1.75694673],\n            [ 0.00925812, -0.29570185,  0.29202055,  0.73679352]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.38011592, -0.13838541, -0.26730926,  0.23796685],\n            [ 0.57433329, -0.3833447 ,  0.51530085, -1.15662009],\n            ...,\n            [ 0.68957111, -0.10290562, -0.8896045 ,  1.4953874 ],\n            [ 0.63177652,  0.22535707,  0.13704813,  0.4857586 ],\n            [ 0.77926251, -0.28054152, -0.70913899,  0.94270832]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.79100258,  0.94735086,  0.98756004, -0.56064197],\n            [-0.70693622, -0.11445163, -0.89165723, -1.36447372],\n            ...,\n            [ 0.48329883,  0.23113554, -0.16863164,  0.95162098],\n            [-0.84261743, -0.27537222, -0.43680221, -0.68413213],\n            [ 0.3158313 , -0.08596246, -0.17763125,  0.22984914]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.79670842,  0.68430608,  0.1997678 , -0.54226574],\n            [-0.74716366, -0.76769111,  0.0813997 ,  0.01363202],\n            ...,\n            [-0.77744575, -0.78903616,  0.66047842, -2.67607011],\n            [ 0.07423347, -0.94435158, -0.85017921, -0.40230588],\n            [-0.3846163 , -0.46490191,  0.2746545 , -0.8508343 ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.85683988,  0.75838247,  0.9212716 ,  0.22498563],\n            [-0.77060387, -0.26528504,  0.71320888,  0.80727022],\n            ...,\n            [ 0.36170355, -0.75015494, -0.86935195, -0.2032506 ],\n            [ 0.11265044, -0.12229327, -0.91582454, -0.48713793],\n            [-0.48146336, -0.95905851,  0.57348003,  2.49789898]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.58313473,  0.69172318, -0.75455402, -0.47669804],\n            [ 0.52475792, -0.97819803, -0.93476738,  2.74046358],\n            ...,\n            [-0.74757983, -0.99906353, -0.27136655, -2.47073159],\n            [ 0.05144515, -0.81421057, -0.8114226 ,  0.10668377],\n            [-0.67362325, -0.26705764, -0.55412917, -1.34277713]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.46752568, -0.04982827,  0.22626191, -0.60347102],\n            [ 0.29046027,  0.99333943,  0.37239855,  0.04251761],\n            ...,\n            [-0.78969787, -0.6076252 , -0.20619774,  0.5763363 ],\n            [ 0.23693099, -0.62544104, -0.1876203 , -0.24144794],\n            [ 0.14326867,  0.05622704, -0.21787818, -0.603211  ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.58787542,  0.99697812, -0.79416991, -2.81233123],\n            [-0.52484451,  0.17199371,  0.31197825, -0.56178837],\n            ...,\n            [ 0.05544412,  0.9946104 , -0.97538606, -1.45145433],\n            [ 0.0458598 ,  0.70493353, -0.19842858, -1.02920924],\n            [ 0.39976159,  0.97464042, -0.25964582, -1.24047044]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.53552005,  0.25979896, -0.87763348, -3.14697198],\n            [-0.25088109,  0.77117237, -0.93533617, -2.71381332],\n            ...,\n            [ 0.59370163, -0.53666112,  0.55699011,  1.54869925],\n            [ 0.37518606, -0.18506458,  0.5208914 ,  1.5302616 ],\n            [ 0.93194075, -0.95358243, -0.55627883, -0.28112074]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.95738678,  0.19387479,  0.3138578 ,  1.30112221],\n            [-0.74181535,  0.64566548,  0.1372755 , -0.14267997],\n            ...,\n            [ 0.82848032,  0.67177272,  0.2591834 ,  0.81408659],\n            [-0.87235749,  0.81964443, -0.32293397, -1.35606395],\n            [-0.76386596, -0.55336753, -0.78594825,  1.50252973]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.18300314,  0.3910864 ,  0.97373459,  2.99006283],\n            [-0.4888939 ,  0.97685156,  0.25872976,  3.24196983],\n            ...,\n            [ 0.97984534, -0.69808031, -0.48466971,  0.12301656],\n            [ 0.50206996, -0.26717255, -0.44497837, -0.01070559],\n            [ 0.04726419,  0.96957915,  0.41528709,  4.63296896]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.83114581,  0.32749073, -0.44421909,  1.49253375],\n            [ 0.14890592,  0.05720007, -0.21691818,  0.49659709],\n            ...,\n            [ 0.56967608, -0.93162655,  0.50280239,  0.32309313],\n            [-0.98361333, -0.53504947, -0.4257446 , -1.62592148],\n            [ 0.7901818 , -0.05828456,  0.16534484,  0.43324898]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.61979487,  0.02997219, -0.51447037, -1.27493882],\n            [ 0.62599311,  0.39232369,  0.55423621, -0.814649  ],\n            ...,\n            [ 0.82716611,  0.90078353,  0.92340874, -0.84356616],\n            [ 0.51711089,  0.4314267 , -0.3235843 , -1.21339554],\n            [ 0.94558136,  0.94877409,  0.77506747, -1.26299839]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.56010435, -0.31463739, -0.3985091 ,  1.55588723],\n            [ 0.41874494,  0.28622755, -0.02410414, -0.22941483],\n            ...,\n            [-0.19328532,  0.90890228, -0.4350509 ,  0.65313755],\n            [-0.5798935 ,  0.85809673, -0.59421679,  0.97987813],\n            [ 0.11455188,  0.62544664, -0.90660519,  0.65671602]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.09483093, -0.90863246, -0.78755677,  1.0277244 ],\n            [-0.37595808, -0.53061775, -0.00907669,  0.95560888],\n            ...,\n            [-0.95883738,  0.16195748, -0.47036342, -0.5737903 ],\n            [ 0.03673988, -0.97846961, -0.94204494,  1.2460543 ],\n            [ 0.78750049, -0.69321329,  0.01454519,  2.1116496 ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.92531288,  0.64130367,  0.6878341 , -2.34379284],\n            [-0.15414424, -0.19884012, -0.8991579 , -0.60395863],\n            ...,\n            [ 0.57068615, -0.05751405,  0.98448084, -2.51505654],\n            [ 0.97954659,  0.09749501,  0.64561133, -1.99407207],\n            [-0.1073006 , -0.64447877, -0.26602762, -0.91021265]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.97031612, -0.88633403,  0.36767678, -0.51870323],\n            [ 0.07379623,  0.37091553, -0.13380891,  0.41722529],\n            ...,\n            [ 0.51933234, -0.43000789, -0.6686941 , -0.16028467],\n            [ 0.70017284, -0.39922136,  0.40672291, -1.25717537],\n            [-0.82675023,  0.46723081, -0.66676578,  3.50162054]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.98007914,  0.97471144, -0.34224856,  3.28162463],\n            [ 0.8097693 , -0.86215505, -0.42705711,  3.0179893 ],\n            ...,\n            [-0.18009568, -0.8393353 , -0.99540538,  1.82084683],\n            [-0.47981006,  0.20684549, -0.63842067,  1.2556307 ],\n            [-0.46524885,  0.80599351, -0.4387952 ,  1.46866467]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.95751825,  0.4466168 ,  0.3927667 , -0.02501852],\n            [-0.54905628, -0.03167724, -0.88275698, -1.57522742],\n            ...,\n            [-0.05282327,  0.96704525,  0.03366223,  2.13824776],\n            [ 0.47552916,  0.3035634 ,  0.02096841,  2.01347585],\n            [ 0.49633601,  0.05148778, -0.1936731 ,  1.5605971 ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.4413701 , -0.35205062,  0.86531915,  0.84597221],\n            [ 0.21543154, -0.63486086, -0.20371755, -1.18138376],\n            ...,\n            [ 0.05379877,  0.20382561,  0.52549735,  0.60245993],\n            [-0.20557902, -0.2134711 , -0.89741948, -2.55274788],\n            [-0.27946698, -0.46489623,  0.95866846,  0.79631603]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.79974347,  0.65317075,  0.16094567, -0.00901891],\n            [ 0.35221889, -0.3578389 ,  0.28760227, -0.17946538],\n            ...,\n            [-0.9134063 ,  0.94754847, -0.9838284 ,  3.26333371],\n            [ 0.78135704,  0.31077864, -0.9924243 , -1.6527693 ],\n            [ 0.1122107 , -0.68715379, -0.62048468, -0.73279956]]),\n     array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n              0.00000000e+00],\n            [ 6.18849975e-01, -5.51278770e-01, -4.97116975e-01,\n             -2.42922393e+00],\n            [-5.99944404e-02,  2.05909228e-01, -6.23812298e-01,\n              2.66191796e-02],\n            ...,\n            [-8.15668581e-01,  6.33325685e-01,  9.69733418e-01,\n              2.70440016e+00],\n            [ 4.43354154e-01, -8.50291083e-01,  1.05234401e-01,\n             -3.25959443e+00],\n            [ 2.96524295e-03,  9.02827203e-02,  5.96285314e-01,\n              1.20403411e+00]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.88868986,  0.83881763, -0.93663545, -2.4551114 ],\n            [-0.42554858,  0.78970012,  0.20681618, -1.88289285],\n            ...,\n            [ 0.20588638,  0.48028189,  0.59120678, -0.62272204],\n            [-0.24390082,  0.64105876, -0.96999824, -1.44198101],\n            [ 0.34487337, -0.15596929, -0.00695545,  0.28020874]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.64068395, -0.19913071, -0.1113794 , -1.10094237],\n            [ 0.92451781,  0.69279565,  0.66779412, -1.08668574],\n            ...,\n            [ 0.89171832,  0.94135077, -0.89367994,  2.11194002],\n            [-0.83863282,  0.51062932, -0.41321192,  0.91928043],\n            [ 0.95545394, -0.94314877, -0.3447589 , -0.61916594]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.58744277,  0.76024521,  0.31550139, -0.78761429],\n            [-0.83540759, -0.30135258,  0.87888128,  2.09732601],\n            ...,\n            [-0.80243015,  0.24167242, -0.56878896,  2.68613579],\n            [-0.70678155,  0.77684958, -0.34639354,  2.24984883],\n            [-0.07801619,  0.52095354, -0.02935602,  0.34288759]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.21360563,  0.40843443, -0.82679791, -2.24115118],\n            [-0.82998956, -0.52313165, -0.81043113, -0.76347833],\n            ...,\n            [ 0.35452216,  0.80395146, -0.30891143, -2.20608884],\n            [ 0.44816856,  0.43449524, -0.53823898, -1.30315883],\n            [-0.95993956,  0.56409272, -0.56485226, -0.80272868]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.93008145, -0.97482755,  0.5823842 , -2.37541664],\n            [ 0.88406804, -0.52203128, -0.94303273, -0.65502539],\n            ...,\n            [ 0.85141126, -0.62975217, -0.85032569, -0.45271107],\n            [ 0.11235438, -0.51731568, -0.25388248,  0.37934545],\n            [ 0.19257787, -0.32149315,  0.57254017, -0.53232048]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.34526933,  0.70092214,  0.0392119 ,  0.22662987],\n            [-0.25322829,  0.13691938, -0.54092098,  1.20805881],\n            ...,\n            [ 0.20152136, -0.30537969,  0.19807104, -0.11982227],\n            [ 0.37466511, -0.41412027,  0.2293846 , -0.06566688],\n            [-0.11674053,  0.35238015, -0.12967637,  0.1854458 ]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.23450294, -0.1511352 ,  0.47421272,  0.79032759],\n            [-0.78922387, -0.76583746, -0.49332227, -2.18302247],\n            ...,\n            [-0.89797413, -0.66237863,  0.8094847 , -0.01903959],\n            [ 0.82117949, -0.08233808,  0.63759509,  1.59459949],\n            [-0.12319642, -0.3381825 ,  0.85000204,  1.24471455]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.34151263, -0.803816  , -0.67525493, -1.84437321],\n            [ 0.60826937, -0.9174049 , -0.39566129, -1.14989093],\n            ...,\n            [ 0.26745687, -0.13420888, -0.9147114 , -0.62491359],\n            [ 0.07856063, -0.9544152 , -0.84421198, -2.17396484],\n            [ 0.04658051,  0.8485651 ,  0.9795638 , -1.14702976]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.73445454, -0.5156    , -0.94503852,  2.3167044 ],\n            [ 0.54068475,  0.73690338, -0.64878402, -1.73198471],\n            ...,\n            [-0.68639029, -0.67876814,  0.54854981, -0.11564298],\n            [ 0.88074518, -0.78221585, -0.91909901,  3.95258857],\n            [ 0.68267541, -0.49689147,  0.26007781,  1.06095011]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.76516691, -0.16370143,  0.14812904,  0.03468795],\n            [ 0.14891152, -0.52869529, -0.88608788,  0.42238551],\n            ...,\n            [-0.32336525,  0.60005225, -0.69630632, -0.5124624 ],\n            [ 0.40376572,  0.30335102,  0.56239759,  0.39098119],\n            [ 0.28243791, -0.48843246,  0.71602817,  0.46077279]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.63137908,  0.23467052, -0.08760608, -0.18234139],\n            [-0.79175867,  0.98249861, -0.37230597, -0.99431616],\n            ...,\n            [-0.74719945, -0.47962972,  0.32430849,  0.72184087],\n            [ 0.88891871,  0.79396982, -0.65524231,  0.52054349],\n            [ 0.89830817,  0.41273412, -0.09448206, -0.39519035]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.96077669,  0.89347122,  0.22781145, -1.06964764],\n            [-0.52331029,  0.06721439, -0.97314725,  0.34383866],\n            ...,\n            [-0.66246282,  0.05236244, -0.16667286,  0.35649874],\n            [ 0.76103307, -0.89333703,  0.22446117,  1.15609826],\n            [ 0.99617555, -0.67005314,  0.12446449, -0.00562325]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.72194229, -0.48281149,  0.57206604,  3.06992624],\n            [-0.22799282, -0.78850829, -0.1952378 ,  2.24646797],\n            ...,\n            [ 0.91567164,  0.94501041,  0.25742665, -4.19633247],\n            [-0.53705702, -0.33947952, -0.68666614,  2.52973407],\n            [ 0.60827395, -0.90718319, -0.50498331,  0.30497091]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.69214241, -0.25339647,  0.17612625,  0.60960559],\n            [-0.11614855, -0.81759377,  0.6414754 ,  3.80999341],\n            ...,\n            [-0.44968842,  0.9686861 , -0.5638026 ,  0.49545597],\n            [ 0.30940222, -0.15782613,  0.40479201,  1.33975285],\n            [ 0.62846485, -0.39446182, -0.92281514,  1.39530659]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [ 0.09545252, -0.29309008, -0.37049286, -0.28610953],\n            [ 0.98791224, -0.27290154,  0.60987403, -0.08892136],\n            ...,\n            [ 0.97094205,  0.02033472, -0.87389206,  2.09292147],\n            [-0.94321386, -0.70894762, -0.23017164,  0.13381393],\n            [-0.26712847, -0.58441118, -0.97488999, -1.30867054]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.7553817 ,  0.29386616, -0.28066302,  1.32094761],\n            [ 0.27236118,  0.0436781 , -0.74191246,  0.49581016],\n            ...,\n            [-0.52515575, -0.18693076, -0.86074912,  2.06878816],\n            [ 0.21062709,  0.25698972,  0.74366938,  0.68178938],\n            [ 0.341533  ,  0.03671408, -0.96305644,  0.89057465]]),\n     array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n            [-0.60923875,  0.29995802, -0.3528712 , -0.06401706],\n            [-0.5067465 ,  0.7511705 ,  0.50826259, -2.06560882],\n            ...,\n            [ 0.61829096, -0.94401531, -0.82824438,  0.81429791],\n            [ 0.26624646,  0.52508788, -0.27702401,  0.36829821],\n            [ 0.20182815,  0.33824812, -0.3832219 ,  0.69474449]])],\n    'k': [11.190249276318378,\n     -20.611501405701052,\n     9.823864692757592,\n     -12.522225682893616,\n     3.0851566284056027,\n     -17.264747285479878,\n     -0.6726135418377688,\n     -17.025881901256724,\n     -7.21012903408119,\n     -7.997447390908017,\n     -7.428929452258014,\n     4.01193979742498,\n     -5.487962177873035,\n     -21.600934209619183,\n     -32.657671728629495,\n     5.213590598121715,\n     -7.070611385221728,\n     -2.8468946063332083,\n     -5.867787203476146,\n     0.8510480142064997,\n     -22.488368466958292,\n     -64.19287565324412,\n     -5.791706470741071,\n     -6.025937593754556,\n     -6.017398861625491,\n     -10.754336406981732,\n     6.328553140272717,\n     -15.283873741385005,\n     -1.0848777001163472,\n     -20.236192409788988,\n     16.12068918362062,\n     -7.227708759254526,\n     -11.183701683086118,\n     -3.9571814668608645,\n     -20.83016762546179,\n     -8.991242780193778,\n     -13.925649795612422,\n     -3.475053050587684,\n     -6.813690781981125,\n     -18.825139968477767,\n     -4.138334186542133,\n     -20.531039579707397,\n     -3.9712660015304393,\n     -21.536764667220865,\n     -27.10629631533119,\n     -2.790984260201859,\n     31.35163464620797,\n     -12.188513112418969,\n     -30.57234001905998,\n     -14.96214319412558]}}}}\n\n\n\nd = 2\nc = 1\nnoise_level = 0.0\nplt.scatter(CC[d][c][noise_level]['k'], computed_curvature[d][c][noise_level]['k'], alpha=0.1)\nplt.xlabel(\"True Curvature\")\nplt.ylabel(\"Computed Curvature\")\nplt.title(f\"Sanity Check in dim {d} and codim {c}\")\nplt.show()\n\n\n\n\n\nX.shape\n\n(1000, 3)\n\n\n\nplot_3d(X, use_plotly=True)\n\n\n                                                \n\n\n\nG = get_adaptive_graph(X) #graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    graph_former = get_adaptive_graph,\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1\n)\nks = DC.curvature(G, t=15, dim=2)\n\n\nplot_3d(X,ks,use_plotly=True)\n\n\n                                                \n\n\n\n\ncompute_curvature_on_battery\n\n compute_curvature_on_battery (curvature_function, CC,\n                               restrict_to_first_n_dims=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncurvature_function\n\n\nfn that, given X and dim, returns the curvature of the first point\n\n\nCC\n\n\nthe battery dictionary\n\n\nrestrict_to_first_n_dims\nNoneType\nNone\n\n\n\n\n\nsaved_calcs = f\"/home/piriac/data/diffusion_curvature/computed_diffusion_curvatures_core_{name}.h5\"\nif os.path.exists(saved_calcs):\n    print(f\"Loading saved calculations from {saved_calcs}\")\n    computed_diffusion_curvatures = deepdish.io.load(saved_calcs)\nelse:\n    computed_diffusion_curvatures = compute_curvature_on_battery(diffusion_curvature_of_pt, CC)\n    deepdish.io.save(f\"/home/piriac/data/diffusion_curvature/computed_diffusion_curvatures_core_{name}.h5\", computed_diffusion_curvatures)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPearson Correlations\n\n\ncompute_correlations\n\n compute_correlations (computed_curvature, CC)\n\n\n\n\n\nDetails\n\n\n\n\ncomputed_curvature\nthe computed curvature\n\n\nCC\nthe battery dictionary\n\n\n\n\ndc_curvature_correlations = compute_correlations(computed_diffusion_curvatures, CC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom tabulate import tabulate\n\n\n\n\nresult_table\n\n result_table (correlations, c:int, style='fancy_grid', keys=['r', 'p'])\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncorrelations\n\n\ndictionary of correlations\n\n\nc\nint\n\ncodimension\n\n\nstyle\nstr\nfancy_grid\n\n\n\nkeys\nlist\n[‘r’, ‘p’]\n\n\n\n\n\ntable = result_table(dc_curvature_correlations, c=1)\n\nCodimension =  1\n╒═══════╤═══════════════╕\n│   dim │ Noise = 0.0   │\n╞═══════╪═══════════════╡\n│     2 │ 0.780/2.50    │\n├───────┼───────────────┤\n│     3 │ 0.309/0.02    │\n╘═══════╧═══════════════╛\n\n\n\ntable_latex = result_table(dc_curvature_correlations, c=1, style='latex_raw')\n\nCodimension =  1\n\\begin{tabular}{rl}\n\\hline\n   dim & Noise = 0.0   \\\\\n\\hline\n     2 & 0.780/2.50    \\\\\n     3 & 0.309/0.02    \\\\\n\\hline\n\\end{tabular}\n\n\n\nd = 2\nc = 1\nnoise_level = 0.0\nplt.scatter(CC[d][c][noise_level]['k'], computed_diffusion_curvatures[d][c][noise_level]['k'], alpha=0.1)\nplt.xlabel(\"True Curvature\")\nplt.ylabel(\"Computed Curvature\")\nplt.title(f\"Correlation = {dc_curvature_correlations[d][c][noise_level]['r']:.3f}\")\nplt.show()\n\n\n\n\n\nd = 3\nc = 1\nnoise_level = 0.0\nplt.scatter(CC[d][c][noise_level]['k'], computed_diffusion_curvatures[d][c][noise_level]['k'], alpha=0.1)\nplt.xlabel(\"True Curvature\")\nplt.ylabel(\"Computed Curvature\")\nplt.title(f\"Correlation = {dc_curvature_correlations[d][c][noise_level]['r']:.3f}\")\nplt.show()\n\n\n\n\n\n\n\nFidelity of Sign\nThe above shows that the unsigned diffusion curvature correlates robustly with the true curvature. Let’s measure how well the sign is predicted by diffusion curvature.\n\n\ncompute_sign_score\n\n compute_sign_score (computed_curvature, CC)\n\n\n\n\n\nDetails\n\n\n\n\ncomputed_curvature\nthe computed curvature\n\n\nCC\nthe battery dictionary\n\n\n\n\nsign_accs = compute_sign_score(computed_diffusion_curvatures, CC)\n\n\n\n\n\n\n\n\n\n\n\ntable = result_table(sign_accs, c=1, keys=['accuracy'])\n\nCodimension =  1\n╒═══════╤═══════════════╕\n│   dim │   Noise = 0.0 │\n╞═══════╪═══════════════╡\n│     2 │          0.74 │\n├───────┼───────────────┤\n│     3 │          0.18 │\n╘═══════╧═══════════════╛\n\n\n\n\n\nDataset Exploration\nDimension 3 looks terrible! Why is this?\n\nXs = CC[3][1][0]['Xs']\n\n\nX = Xs[0]\nG = get_adaptive_graph(X) #graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    graph_former = get_adaptive_graph,\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1\n)\nks = DC.curvature(G, t=15, dim=3)\nplot_3d(X, ks, use_plotly=True)\n\nTypeError: slice indices must be integers or None or have an __index__ method"
  },
  {
    "objectID": "experiments/Explorations in Lazy-first diffusion.html",
    "href": "experiments/Explorations in Lazy-first diffusion.html",
    "title": "Explorations in Lazy-first Diffusion Curvature",
    "section": "",
    "text": "from diffusion_curvature.datasets import *\n\n\nfrom sklearn.metrics import pairwise_distances\n\n\ndef knn_kernel(\n    X\n    k = 10,\n):\n    D = pairwise_distances(X)\n\nSyntaxError: invalid syntax (380248663.py, line 4)"
  },
  {
    "objectID": "library/Comparison Space Construction.html",
    "href": "library/Comparison Space Construction.html",
    "title": "Comparison Space Construction",
    "section": "",
    "text": "The construction of the comparison space is the most delicate operation diffusion curvature performs. The key to our construction is ensuring that diffusion, at a single scale, behaves equivalently on the manifold and the graph. Recall our connections to Ollivier’s theory: we just need to ensure that the jump of diffusion is the same in both spaces. Curvature emerges from the interactions of diffusion at higher timesteps.\nOur comparisons take pure graphs as input. We don’t change the euclidean comparison space (which we sample uniformly from an nd random distribution). Instead, we tune the parameters of the kernel to minimize the KLD between the target jump and the average jump in our (boundary-excluded) comparison space. Thus, the beating heart of this approach is the differentiable graph constructor which is expressive enough to approximate a wide variety of graphs).\nThe most contentious point of this implementation is how to compute the \\(W_1\\) distances. We need a metric for each of the graphs; but how is this to be constructed, given that the graph itself is in flux? We have the geodesic distances for the sampled euclidean points, but those won’t be on the same scale as whatever graph distance we use on the manifold.\nOur solution is to use PHATE distances with \\(t=1\\). This requires only taking the log of the diffusion matrix, and for a single scale of distances is basically a way of converting affinities back into distances."
  },
  {
    "objectID": "library/Comparison Space Construction.html#does-it-produce-the-same-kernel-parameters",
    "href": "library/Comparison Space Construction.html#does-it-produce-the-same-kernel-parameters",
    "title": "Comparison Space Construction",
    "section": "1. Does it produce the same kernel parameters?",
    "text": "1. Does it produce the same kernel parameters?\nHere are two heatmaps of the predicted versus actual kernel parameters in the easiest possible situation. We have two planes of the same dimension and same number of points, and use the same kernel. Can matching the jump of diffusion predict the correct parameters?\n\nfrom diffusion_curvature.datasets import plane, sphere, paraboloid\n\n\n# plot the sigma stored against the real sigmas\nplt.figure(figsize=(8,8))\nplt.plot(sigmas, sigma_store[0], label=\"Estimated Sigma\")\nplt.plot(sigmas, sigmas, label=\"True Sigma\")\nplt.xlabel(\"True Sigma\")\nplt.ylabel(\"Estimated Sigma\")\nplt.title(\"Estimated Sigma vs. True Sigma\")\nplt.legend()\nplt.show()\n\n\n\n\nHow does the jump of diffusion change with these parameters?"
  },
  {
    "objectID": "library/Datasets.html",
    "href": "library/Datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "In this notebook, we’ll build various toy datasets and calculate their sectional curvatures.\nThis will use the Python symbolic computation library, sympy. Note: this library is not required to use the diffusion_curvature package. We merely employ it to calculate the curvature and appropriate expressions for rejection sampling.\n\nimport sympy as sym\n\n\ntheta = sym.Symbol('theta')\nphi = sym.Symbol('phi')\nR = sym.Symbol(\"R\")\nr = sym.Symbol(\"r\")\n\n\nf1 = (R + r*sym.cos(theta))*sym.cos(phi)\n\n\nsym.diff(f1,theta)\n\n\\(\\displaystyle - r \\sin{\\left(\\theta \\right)} \\cos{\\left(\\phi \\right)}\\)\n\n\n\nf = sym.Matrix([(R + r*sym.cos(theta))*sym.cos(phi), (R + r*sym.cos(theta))*sym.sin(phi), r*sym.sin(theta)])\n\n\nsym.diff(f, theta)\n\n\\(\\displaystyle \\left[\\begin{matrix}- r \\sin{\\left(\\theta \\right)} \\cos{\\left(\\phi \\right)}\\\\- r \\sin{\\left(\\phi \\right)} \\sin{\\left(\\theta \\right)}\\\\r \\cos{\\left(\\theta \\right)}\\end{matrix}\\right]\\)\n\n\n\n(sym.diff(f, theta).T  * sym.diff(f, theta))[0]\n\n\\(\\displaystyle r^{2} \\sin^{2}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} + r^{2} \\sin^{2}{\\left(\\theta \\right)} \\cos^{2}{\\left(\\phi \\right)} + r^{2} \\cos^{2}{\\left(\\theta \\right)}\\)\n\n\n\ndef rejection_sample_formula(f, variables):\n    G = sym.Matrix.zeros(2,2)\n    for i, x1 in enumerate(variables):\n        for j, x2 in enumerate(variables):\n            G[i,j] = (sym.diff(f, x1).T  * sym.diff(f, x2))[0]\n    return sym.sqrt(G.det().simplify()).simplify()\n\n\nt = rejection_sample_formula(f,[theta, phi])\nt\n\n\\(\\displaystyle \\sqrt{r^{2} \\left(R + r \\cos{\\left(\\theta \\right)}\\right)^{2}}\\)\n\n\n\nTorus\nThe curvature of the torus is given by \\[ S(\\theta) = \\frac{8 \\cos{\\theta}}{5 + \\cos{\\theta}} \\]\n\n\nrejection_sample_for_torus\n\n rejection_sample_for_torus (n, r, R)\n\n/Users/boreas/Pumberton/Workshop/21-SUMRY-Curvature/diffusion-curvature/.pixi/env/lib/python3.11/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nParameters \n----------- in \nSample `n` data points on a torus. Modified from [tadasets.shapes — TaDAsets 0.1.0 documentation](https://tadasets.scikit-tda.org/en/latest/_modules/tadasets/shapes.html#torus)\nUses rejection sampling....\n  else: warn(msg)\n\n\n\ntorus\n\n torus (n=2000, c=2, a=1, noise=None, seed=None, use_guide_points=False)\n\nSample n data points on a torus. Modified from tadasets.shapes — TaDAsets 0.1.0 documentation Uses rejection sampling.\nIn addition to the randomly generated points, a few constant points have been added. The 0th point is on the outer rim, in a region of high positive curvature. The 1st point is in the inside, in a region of negative curvature, and the 2nd point is on the top, where the curvature should be closer to zero.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n2000\nNumber of data points in shape.\n\n\nc\nint\n2\nDistance from center to center of tube.\n\n\na\nint\n1\nRadius of tube.\n\n\nnoise\nNoneType\nNone\n\n\n\nseed\nNoneType\nNone\nSeed for random state.\n\n\nuse_guide_points\nbool\nFalse\n\n\n\n\nVisualize with the curvature\n\nX,ks = torus(n=5000)\nplot_3d(X, ks, title=\"Torus with scalar curvature\")\n\n\n\n\n\nlen(X)\n\n5000\n\n\n\n\n\nOne-Sheet Hyperboloid\nFirst, let’s determine the rejection sampling formula\n\na = sym.Symbol('a')\nb = sym.Symbol('b')\ntheta = sym.Symbol(\"theta\")\nu = sym.Symbol('u')\nf = sym.Matrix(\n    [a*sym.cos(theta)*sym.sqrt(u**2+1),b*sym.sin(theta)*sym.sqrt(u**2+1),u]\n)\n\n\nvariables = [theta, u]\nrej = rejection_sample_formula(f, variables)\nrej\n\n\\(\\displaystyle \\sqrt{a^{2} b^{2} u^{2} + a^{2} u^{2} \\sin^{2}{\\left(\\theta \\right)} + a^{2} \\sin^{2}{\\left(\\theta \\right)} - b^{2} u^{2} \\sin^{2}{\\left(\\theta \\right)} + b^{2} u^{2} - b^{2} \\sin^{2}{\\left(\\theta \\right)} + b^{2}}\\)\n\n\n\n\nhyperboloid\n\n hyperboloid (n=2000, a=2, b=2, c=1, u_limit=2, seed=None)\n\nSample roughly n points on a hyperboloid, using rejection sampling.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n2000\nnumber of points, by default 2000\n\n\na\nint\n2\nhyperboloid param1, by default 2\n\n\nb\nint\n2\nhyperboloid param2, by default 2\n\n\nc\nint\n1\nstretchiness in z, by default 1\n\n\nu_limit\nint\n2\nConstrain the free parameter u to [-l,l], by default 2\n\n\nseed\nNoneType\nNone\nFor repeatability, seed the randomness, by default None\n\n\nReturns\nThe sampled points, and the curvatures of each point\n\n\n\n\n\n\n\n\nrejection_sample_for_hyperboloid\n\n rejection_sample_for_hyperboloid (n, a, b, c, u_limit)\n\n&lt;function nbdev.showdoc.show_doc(sym, renderer=None, name: 'str | None' = None, title_level: 'int' = 3)&gt;\n\nX, ks = hyperboloid(2000)\nplot_3d(X,ks,colorbar=True,use_plotly=False)\n\n\n\n\n\n\n\nEllipsoid\n\na = sym.Symbol('a')\nb = sym.Symbol('b')\nc = sym.Symbol('c')\ntheta = sym.Symbol(\"theta\")\nphi = sym.Symbol(\"phi\")\nu = sym.Symbol('u')\nf = sym.Matrix(\n    [a*sym.cos(theta)*sym.sin(phi),b*sym.sin(theta)*sym.sin(phi),c*sym.cos(phi)]\n)\n\n\nvariables = [theta, phi]\nrej = rejection_sample_formula(f, variables)\nrej\n\n\\(\\displaystyle \\sqrt{- a^{2} b^{2} \\sin^{4}{\\left(\\phi \\right)} + a^{2} b^{2} \\sin^{2}{\\left(\\phi \\right)} + a^{2} c^{2} \\sin^{4}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} - b^{2} c^{2} \\sin^{4}{\\left(\\phi \\right)} \\sin^{2}{\\left(\\theta \\right)} + b^{2} c^{2} \\sin^{4}{\\left(\\phi \\right)}}\\)\n\n\n\n\nellipsoid\n\n ellipsoid (n=2000, a=3, b=2, c=1, seed=None, noise=None)\n\nSample roughly n points on an ellipsoid, using rejection sampling.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n2000\nnumber of points, by default 2000\n\n\na\nint\n3\nellipsoid param1, by default 3\n\n\nb\nint\n2\nellipsoid param2, by default 2\n\n\nc\nint\n1\nstretchiness in z, by default 1\n\n\nseed\nNoneType\nNone\nFor repeatability, seed the randomness, by default None\n\n\nnoise\nNoneType\nNone\n\n\n\nReturns\nThe sampled points, and the curvatures of each point\n\n\n\n\n\n\n\n\nrejection_sample_for_ellipsoid\n\n rejection_sample_for_ellipsoid (n, a, b, c)\n\n\nX, ks = ellipsoid(n=5000, noise = 0.1)\nplot_3d(X,ks,colorbar=True)\n\n\n\n\n\n\n\nHypersphere\n\n\nsphere\n\n sphere (n, d=2, radius=1, use_guide_points=False)\n\n\nX, ks = sphere(n=1000)\nplot_3d(X)\n\n\n\n\n\n\n\nRandom Cube\n\ndef random_cube(n):\n    \"\"\"Return a random cube\n\n    Parameters\n    ----------\n    n : _type_\n        _description_\n\n    Returns\n    -------\n    _type_\n        _description_\n    \"\"\"\n    data = np.random.rand(n,3)\n    return data\n\n\n\nSaddle Regions\nGenerate hyperbolic regions as test cases of Laziness curvature.\n\na = sym.Symbol('a')\nb = sym.Symbol('b')\nx = sym.Symbol(\"x\")\ny = sym.Symbol(\"y\")\nf = sym.Matrix(\n    [x,y,a*x**2 + b*y**2]\n)\n\n\nvariables = [x, y]\nrej = rejection_sample_formula(f, variables)\nrej\n\n\\(\\displaystyle \\sqrt{4 a^{2} x^{2} + 4 b^{2} y^{2} + 1}\\)\n\n\n\n\nparaboloid\n\n paraboloid (n=2000, a=1, b=-1, seed=None, use_guide_points=False)\n\nSample roughly n points on a saddle, using rejection sampling for even density coverage Defined by \\(ax^2 + by^2\\).\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n2000\nnumber of points, by default 2000\n\n\na\nint\n1\nellipsoid param1, by default 1\n\n\nb\nint\n-1\nellipsoid param2, by default -1\n\n\nseed\nNoneType\nNone\nFor repeatability, seed the randomness, by default None\n\n\nuse_guide_points\nbool\nFalse\n\n\n\nReturns\nThe sampled points, and the curvatures of each point\n\n\n\n\n\n\n\n\nrejection_sample_for_saddle\n\n rejection_sample_for_saddle (n, a, b)\n\n\nX, ks = paraboloid(n=10000, a = 1, b = -1,use_guide_points=True)\n\n\nplot_3d(X,ks)\n\n\n\n\n\nx = np.zeros(10)\n\n\nnp.concatenate([[0],x])\n\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n\n\n\n\nrejection_sample_from_saddle\n\n rejection_sample_from_saddle (n_samples=1000, intrinsic_dim=2,\n                               verbose=False, intensity=1)\n\n\n\n\nThe Plane\n\n\nplane\n\n plane (n, dim=2)\n\n\n!nbdev_export"
  },
  {
    "objectID": "library/Heat Diffusion.html",
    "href": "library/Heat Diffusion.html",
    "title": "Heat Diffusion",
    "section": "",
    "text": "jax.devices()\n\n[gpu(id=0)]\nThis is the most computationally demanding step: simulating heat diffusion. There are two main methods:"
  },
  {
    "objectID": "library/Heat Diffusion.html#philosophy",
    "href": "library/Heat Diffusion.html#philosophy",
    "title": "Heat Diffusion",
    "section": "Philosophy",
    "text": "Philosophy\nThe graph diffusion matrix \\(P\\) is one means of approximating the heat kernel, which has seen repeated empirical success in methods like Diffusion Maps, PHATE, Diffusion Condensation, etc. Yet, \\(P\\)’s approximation of heat diffusion is fairly crude. All it does is normalize the adjacency matrix, which leaves it awfully dependent on how we parameterize that matrix. A wonky kernel bandwidth or unsatisfactory density normalization leaves \\(P\\) stranded.\nCoifman et al. have proven that \\(P^t\\) converges to the Neumann heat kernel on the manifold as \\(t \\to 0\\), which is to say: locally, it’s perfectly fine. But in practice, \\(P\\) isn’t used with really small powers of \\(t\\), and the kernel bandwidth is usually large enough that a single step of diffusion extends haphazardly across the manifold, with decay determined by unreliable euclidean distances. This can be avoided by restricting a single step of diffusion to a single neighborhood - but in this case, powering \\(P\\) to the needed global reach becomes prohibitive and quite noisy.\nIn this notebook, we implement and experiment with an alternate estimation of the heat kernel. This was used by Huguet et al’s A Heat Diffusion Perspective on Geodesic Preserving Dimensionality Reduction. The implementation is adapted from the authors’ source code KrishnaswamyLab/HeatGeo: Embedding with the Heat-geodesic dissimilarity. But, following Knuth’s guidance on code reuse, we strip it out of the framework and reimplement the pieces ourselves, to escape ‘dependency heck’."
  },
  {
    "objectID": "library/Heat Diffusion.html#implementation",
    "href": "library/Heat Diffusion.html#implementation",
    "title": "Heat Diffusion",
    "section": "Implementation",
    "text": "Implementation\n\n\nexpm_multiply\n\n expm_multiply (L:numpy.ndarray, X:numpy.ndarray, phi:float, tau,\n                K:int=None, err:float=1e-32)\n\nComputes the exp(tL)X for each t in tau. If L is the graph laplacian, this is heat diffusion applied to X.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nL\nndarray\n\nThe graph laplacian. or another PSD matrix with max eval &lt;= 2\n\n\nX\nndarray\n\nThe signal to diffuse\n\n\nphi\nfloat\n\nl_max/2, where l_max is the largest eigenvalue of L. PyGSP has a method to compute this easily.\n\n\ntau\n\n\nDiffusion times, either as a single float/int, or a list/ndarray of floats/ints\n\n\nK\nint\nNone\nThe number of polynomial terms to use in the approximation. If None, calculates the least number that guarantees precision of err.\n\n\nerr\nfloat\n1e-32\nPrecision\n\n\n\n\n\n\ncompute_chebychev_coeff_all\n\n compute_chebychev_coeff_all (phi, tau, K)\n\nCompute the K+1 Chebychev coefficients for our functions.\n\n\n\nreverse_bound\n\n reverse_bound (f, phi, x, tau, err)\n\nReturns the minimal K such that f(phi, x, tau, K) &lt;= err.\n\n\n\nget_bound_bergamaschi_specific\n\n get_bound_bergamaschi_specific (phi, x, tau, K)\n\n\n\n\nget_bound_bergamaschi_generic\n\n get_bound_bergamaschi_generic (phi, x, tau, K)\n\n\n\n\nE\n\n E (K, C)\n\n\n\n\nget_bound_eta_specific\n\n get_bound_eta_specific (phi, x, tau, K)\n\n\n\n\nget_bound_eta_generic\n\n get_bound_eta_generic (phi, x, tau, K)\n\n\n\n\nget_bound_eps_generic\n\n get_bound_eps_generic (phi, x, tau, K)\n\n\n\n\ng\n\n g (K, C)"
  },
  {
    "objectID": "library/Heat Diffusion.html#tests",
    "href": "library/Heat Diffusion.html#tests",
    "title": "Heat Diffusion",
    "section": "Tests",
    "text": "Tests\nHere’s an example of how to use this.\n\nfrom diffusion_curvature.datasets import torus\nfrom diffusion_curvature.graphs import *\n\n\nX, ks = torus(2000, use_guide_points = True)\nG_torus = get_alpha_decay_graph(X)\n\nTo use expm_multiply, we need: 1. The graph laplacian 2. An estimate of the largest eigenvalue (e.g. from PyGSP) 3. The diffusion times\nFor convenience, here’s a wrapper that does all of this for a PyGSP graph and signal.\n\n\nheat_diffusion_on_signal\n\n heat_diffusion_on_signal (G:pygsp.graphs.graph.Graph, x:numpy.ndarray, t)\n\nReturns the heat-diffused signal. Uses chebyshev approximation of exp(-tL).\n\n\n\n\nType\nDetails\n\n\n\n\nG\nGraph\nThe graph on which to diffuse heat\n\n\nx\nndarray\nThe signal to diffuse\n\n\nt\n\ntime of diffusion, or list of times\n\n\n\n\n\n\nkronecker_delta\n\n kronecker_delta (length, idx=None)\n\nreturns jnp array of len with all zeroes except idx.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlength\n\n\nlength of array. If you pass an array or list, length is set to size of the first dimension.\n\n\nidx\nNoneType\nNone\nidx to make nonzero. If none, fills a random idx.\n\n\n\n\n\n\nheat_diffusion_from_dirac\n\n heat_diffusion_from_dirac (G:pygsp.graphs.graph.Graph, t, idx=None)\n\nReturns array of size (len t) x (num_idxs) x (num nodes) If idx is None, returns heat diffusion on each node.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nG\nGraph\n\npyGSP graph\n\n\nt\n\n\ntime of diffusion, or list of times\n\n\nidx\nNoneType\nNone\nif given, returns just the diffusion of a dirac at this idx. Else, diffuses at every idx\n\n\n\nHere’s heat diffused from one dirac\n\ndiffused_diracs = heat_diffusion_from_dirac(G_torus, idx=0, t=[2,4,12])\n\n\nplot_3d(X,diffused_diracs[2])\n\n\n\n\nHere’s this calculation carried out across all indices:\n\ndiffused_diracs_on_each_point = heat_diffusion_from_dirac(G_torus, t=[2,4,12])\n\n\nplot_3d(X,diffused_diracs_on_each_point[2][0])\n\n\n\n\n\ndiffused_diracs_on_each_point.shape\n\n(3, 2000, 2000)\n\n\n\n!nbdev_export"
  },
  {
    "objectID": "library/Construct Battery.html",
    "href": "library/Construct Battery.html",
    "title": "3a Construct Battery",
    "section": "",
    "text": "create_battery\n\n create_battery (intrinsic_dims=[3, 4, 5, 6], codimensions=[1, 2],\n                 num_manifolds_per_dim=10, noise_levels=[0.0, 0.05, 0.1,\n                 0.2, 0.3, 0.5])\n\n\n\n\nmain\n\n main (filename:str='/home/piriac/data/diffusion_curvature/Curvature_Colos\n       seum.h5', intrinsic_dims:list=[2, 3, 4, 5], codimensions:list=[1,\n       2, 3, 4], num_manifolds_per_dim:int=50, noise_levels:list=[0.0,\n       0.05, 0.1, 0.2, 0.3, 0.5])\n\nConstructs a battery of toy manifolds and saves it to disk in HDF5 format\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfilename\nstr\n/home/piriac/data/diffusion_curvature/Curvature_Colosseum.h5\npath to the sampled toy manifolds\n\n\nintrinsic_dims\nlist\n[2, 3, 4, 5]\nintrinsic dimensions of the toy manifolds\n\n\ncodimensions\nlist\n[1, 2, 3, 4]\ncodimensions of the toy manifolds\n\n\nnum_manifolds_per_dim\nint\n50\nnumber of toy manifolds per intrinsic dimension\n\n\nnoise_levels\nlist\n[0.0, 0.05, 0.1, 0.2, 0.3, 0.5]\n\n\n\n\n\nmain(\n    filename='/home/piriac/data/diffusion_curvature/Curvature_Colosseum_LowD_HighSampled.h5',\n    intrinsic_dims=[2,3],\n    codimensions= [1],\n    num_manifolds_per_dim=50,\n    noise_levels=[0.0],\n)\n\nSampling from 50 manifolds in dims [2, 3] with codims [1] and noise level [0.0]. Saving to /home/piriac/data/diffusion_curvature/Curvature_Colosseum_LowD_HighSampled.h5"
  },
  {
    "objectID": "library/Core.html",
    "href": "library/Core.html",
    "title": "Implementation (PyGSP + JAX)",
    "section": "",
    "text": "This notebook implements diffusion curvature atop the popular PyGSP library. To compute the curvature of any PyGSP graph, simply instantiate a DiffusionCurvature object with your choice of parameters, and pass the graphtools graph through as input.\nWhat follows is a literate implementation, showing the steps of the algorithm applied to our old friend, the torus.\nThe implementation of Diffusion Curvature involves several big pieces, each of which can be performed with different strategies:\nWe implement everything generically in JAX (a high performance numpy replacement, which can compile to the GPU), treating each of the above as modules that can be parametrically tuned. Functional programming is our game: each function takes a graph object as input and returns an updated graph object with the required quantities computed.\nfrom diffusion_curvature.datasets import torus\n# Our sample dataset for testing the rest of the notebook\nX_torus, ks_torus = torus(5000,use_guide_points=True)"
  },
  {
    "objectID": "library/Core.html#on-the-plane",
    "href": "library/Core.html#on-the-plane",
    "title": "Implementation (PyGSP + JAX)",
    "section": "On the Plane",
    "text": "On the Plane\n\nX_plane = plane(1000)\nG_plane = get_adaptive_graph(X_plane) #get_alpha_decay_graph(X_plane, decay=None, knn=15, anisotropy=1, )\nP = diffusion_matrix_from_affinities(G_plane.W) #diff_op(G_plane).todense() # is sparse, by default\nP = jnp.array(P)\nPt = jax_power_matrix(P,8)\n\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# plot the first scatter plot\naxs[0].scatter(X_plane[:,0],X_plane[:,1],c=P[0].tolist(), cmap='jet')\naxs[0].set_title('Diffusion P')\n\n# plot the second scatter plot\naxs[1].scatter(X_plane[:,0],X_plane[:,1],c=Pt[0].tolist(), cmap='jet')\naxs[1].set_title('Diffusion Pt')\n\nplt.show()\n\n\n\n\n\nDC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\")\nks_plane= DC.curvature(G_plane, t=8, dim=2, knn=15)\n\nLet’s check that higher dimensional planes are also given flat curvature\n\nds = [3,4,5,6]\nplanes = [plane(1000*2**(d-2), d) for d in ds]\nfor i, d in enumerate(ds):\n    G = get_adaptive_graph(planes[i]) #get_alpha_decay_graph(planes[i], decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=500,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\")\n    ks = DC.curvature(G, t=8, dim=d, knn=15)\n    print(\"dimension\",d,\": Curvature of Plane is \",ks[0])\n\ndimension 3 : Curvature of Plane is  0.0050811768\ndimension 4 : Curvature of Plane is  -0.0046873093\ndimension 5 : Curvature of Plane is  -0.000705719\n\n\n2024-01-03 19:46:52.845911: W external/tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 976.68MiB (rounded to 1024128256)requested by op \n2024-01-03 19:46:52.846067: W external/tsl/tsl/framework/bfc_allocator.cc:497] ************************************************xx_____*************______________________________**\n2024-01-03 19:46:52.846137: E external/xla/xla/pjrt/pjrt_stream_executor_client.cc:2716] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1024128004 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    1.91GiB\n              constant allocation:         0B\n        maybe_live_out allocation:  976.68MiB\n     preallocated temp allocation:         0B\n                 total allocation:    2.86GiB\n              total fragmentation:         0B (0.00%)\nPeak buffers:\n    Buffer 1:\n        Size: 976.68MiB\n        Entry Parameter Subshape: f32[16001,16001]\n        ==========================\n\n    Buffer 2:\n        Size: 976.68MiB\n        Entry Parameter Subshape: f32[16001,16001]\n        ==========================\n\n    Buffer 3:\n        Size: 976.68MiB\n        Operator: op_name=\"jit(fn)/jit(main)/add\" source_file=\"/home/piriac/Pumberton/Workshop/21-SUMRY-Curvature/diffusion_curvature/diffusion_curvature/graphs.py\" source_line=131\n        XLA Label: fusion\n        Shape: f32[16001,16001]\n        ==========================\n\n\n\n\nXlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1024128004 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    1.91GiB\n              constant allocation:         0B\n        maybe_live_out allocation:  976.68MiB\n     preallocated temp allocation:         0B\n                 total allocation:    2.86GiB\n              total fragmentation:         0B (0.00%)\nPeak buffers:\n    Buffer 1:\n        Size: 976.68MiB\n        Entry Parameter Subshape: f32[16001,16001]\n        ==========================\n\n    Buffer 2:\n        Size: 976.68MiB\n        Entry Parameter Subshape: f32[16001,16001]\n        ==========================\n\n    Buffer 3:\n        Size: 976.68MiB\n        Operator: op_name=\"jit(fn)/jit(main)/add\" source_file=\"/home/piriac/Pumberton/Workshop/21-SUMRY-Curvature/diffusion_curvature/diffusion_curvature/graphs.py\" source_line=131\n        XLA Label: fusion\n        Shape: f32[16001,16001]\n        ==========================\n\n\n\n\nds = [3,4,5,6]\nplanes = [plane(1000*2**(d-2), d) for d in ds]\nfor i, d in enumerate(ds):\n    G = get_adaptive_graph(planes[i]) #get_alpha_decay_graph(planes[i], decay=None, knn=15, anisotropy=1, )\n    DC = DiffusionCurvature(laziness_method=\"Entropic\",points_per_cluster=None,comparison_space_size_factor=1,comparison_method=\"Subtraction\", flattening_method=\"Fixed\")\n    ks = DC.curvature(G, t=8, dim=d, knn=15)\n    print(\"dimension\",d,\": Curvature of Plane is \",ks[0])"
  },
  {
    "objectID": "library/Core.html#how-bout-a-donut",
    "href": "library/Core.html#how-bout-a-donut",
    "title": "Implementation (PyGSP + JAX)",
    "section": "How bout a donut?",
    "text": "How bout a donut?\n\nWith Fixed Flattening\n\nX_torus,ks = torus(5000,use_guide_points=False)\nG_torus = get_adaptive_graph(X_torus) #graphtools.Graph(X_torus, anisotropy=1, knn=15, decay=None).to_pygsp()\nP = diffusion_matrix_from_affinities(G_torus.W) # is sparse, by default\nP = jnp.array(P)\nPt = jax_power_matrix(P,30)\n\n\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1\n    )\nks_torus = DC.curvature(G_torus, t=30, dim=2, knn=15)\n\n\nplot_3d(X_torus,ks_torus,colorbar=True,title='Diffusion Comparison Curvature of the Torus')\n\n\nplt.scatter(ks, ks_torus)\nplt.title(\"Diffusion Curvature vs Real Curvature of Torus\")\nplt.xlabel(\"Gaussian Curvature\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n\nWith Grid\n\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1,\n    use_grid=True,\n    )\nks_torus = DC.curvature(G_torus, t=25, dim=2, knn=15)\n\n\nplot_3d(X_torus,ks_torus,colorbar=True,title='Diffusion Comparison Curvature of the Torus')\n\n\nplt.scatter(ks, ks_torus)\nplt.title(\"Diffusion Curvature vs Real Curvature of Torus\")\nplt.xlabel(\"Gaussian Curvature\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n\nWith Wasserstein\n\nDC = DiffusionCurvature(\n    laziness_method=\"Wasserstein\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Ollivier\",\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1,\n    )\nks_torus = DC.curvature(G_torus, t=15, dim=2, knn=15)\n\n\nplot_3d(X_torus,ks_torus,colorbar=True,title='Diffusion Wasserstein Curvature of the Torus')\n\n\nplt.scatter(ks, ks_torus)\nplt.title(\"Diffusion Curvature vs Real Curvature of Torus\")\nplt.xlabel(\"Gaussian Curvature\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\nplot_3d(X_torus,ks_torus,colorbar=True,title='Diffusion Comparison Curvature of the Torus')\n\n\nplt.scatter(ks, ks_torus)\nplt.title(\"Diffusion Curvature vs Real Curvature of Torus\")\nplt.xlabel(\"Gaussian Curvature\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n\nWith Laziness\n\nDC = DiffusionCurvature(\n    laziness_method=\"Laziness\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1,\n    aperture=30,\n    smoothing = 4,\n    )\nks_torus = DC.curvature(G_torus, t=30, dim=2, knn=15,)\n\n\nuks = DC.unsigned_curvature(G_torus,t=30)\n\n\nplot_3d(X_torus,DC.Pt[0])\n\n\nplot_3d(X_torus,uks)\n\n\nplot_3d(X_torus,ks_torus,colorbar=True,title='Diffusion Wasserstein Curvature of the Torus')\n\n\nplt.scatter(ks, ks_torus)\nplt.title(\"Diffusion Curvature vs Real Curvature of Torus\")\nplt.xlabel(\"Gaussian Curvature\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n\nWith VNE t selection\n\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1,\n    use_grid=True,\n    )\nks_torus = DC.curvature(G_torus, t=None, dim=2, knn=15)\n\n&lt;class 'scipy.sparse._csr.csr_matrix'&gt;\n(1000,)\n&lt;class 'scipy.sparse._csr.csr_matrix'&gt;\n\n\n2024-01-03 20:44:48,884:[WARNING](pygsp.graphs.graph.check_weights): The main diagonal of the weight matrix is not 0!\n\n\n\nplot_3d(X_torus,ks_torus,colorbar=True,title='Diffusion Comparison Curvature of the Torus')\n\n\n\n\n\nplt.scatter(ks, ks_torus)\nplt.title(\"Diffusion Curvature vs Real Curvature of Torus\")\nplt.xlabel(\"Gaussian Curvature\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n\nWith Neural Flattening\n\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Neural\",\n    comparison_method=\"Subtraction\",\n    points_per_cluster=100, # construct separate comparison spaces around each point\n    comparison_space_size_factor=10,\n    max_flattening_epochs=100,\n    use_grid=False,\n    )\nks_torus = DC.curvature(G_torus, t=25, dim=2, knn=15)\n\n\nplot_3d(X_torus,ks_torus,colorbar=True,title='Diffusion Comparison Curvature of the Torus')\n\n\nplt.scatter(ks, ks_torus)\nplt.title(\"Diffusion Curvature vs Real Curvature of Torus\")\nplt.xlabel(\"Gaussian Curvature\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Fixed\",\n    comparison_method=\"Subtraction\",\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1\n    )\nks_torus_at_idx = DC.curvature(G_torus, t=15, dim=2, knn=15, idx=12)\n\n\nks_torus_at_idx\n\n\nuks = DC.unsigned_curvature(G_torus,t=15)\n\n\nuks\n\n\nplot_3d(X_torus,uks,colorbar=True)\n\n\nlabels = enhanced_spectral_clustering(G_torus, uks, dim=2, num_clusters=9, )\n\n\nplot_3d(X_torus,labels)\n\n\nentropy_of_diffusion(Pt[0])\n\n\nfakePt = jnp.concatenate([Pt[0], jnp.zeros(len(Pt[0]))])\nentropy_of_diffusion(jnp.concatenate([Pt[0], jnp.zeros(len(Pt[0]))]))\n\n\njax.scipy.special.entr(jnp.concatenate([Pt[0], jnp.zeros(len(Pt[0]))]))\n\n\n# get num nonzero entries in fakePt\njnp.sum(fakePt&gt;1e-10)\n\n\n(-jnp.log(1/jnp.sum(fakePt&gt;1e-10, axis=-1)))\n\n\njnp.sum(jax.scipy.special.entr(jnp.ones(10)/10))\n\n\n\nWith Mean Flattening\n\nDC = DiffusionCurvature(\n    laziness_method=\"Entropic\",\n    flattening_method=\"Mean Fixed\",\n    comparison_method=\"Subtraction\",\n    points_per_cluster=None, # construct separate comparison spaces around each point\n    comparison_space_size_factor=1,\n    use_grid=False,\n    )\nks_torus = DC.curvature(G_torus, t=25, dim=2, knn=15)\n\n\nplot_3d(X_torus,ks_torus,colorbar=True,title='Diffusion Comparison Curvature of the Torus')\n\n\nplt.scatter(ks, ks_torus)\nplt.title(\"Diffusion Curvature vs Real Curvature of Torus\")\nplt.xlabel(\"Gaussian Curvature\")\nplt.ylabel(\"Diffusion Curvature\")\n\n\n!nbdev_export"
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html",
    "href": "library/Diffusion Ricci Curvature.html",
    "title": "Diffusion Ricci Curvature",
    "section": "",
    "text": "Diffusion curvature is an excellent unsigned measure of curvature; it correlates nicely with the scalar curvature, even in high dimensions and amidst noise. But turning that always positive scalar - the measurement of laziness of random walks - into an indicator of positive or negative curvature requires oftentimes unweildy usage of comparison spaces. And comparison spaces depend, to a large degree, on being able to match the sampling and graph construction of the target space, turning signed diffusion curvature from a mathematical problem into a machine learning data-training problem.\nThis notebook explores an alternate way to make diffusion curvature signed. At its heart is this intuition: scalar curvature is a integral of sorts over the Ricci curvature. Thus, to recover the (signed) Ricci curvature from even an unsigned scalar curvature, one just has to differentiate, asking the question: does changing the weight of this edge increase or decrease the scalar curvature of the surrounding regions? If strengthening the edge causes random walks in the surrounding regions to become lazier, the edge has positive curvature. If, e.g., the edge connects two regions of already positive curvature (like two circles), then strengthening it makes the surrounding graph more saddle-like and has negative curvature.\nThis motivates our definition of Diffusion Ricci Curvature. Let \\(l(A,t)[i] = \\sum_j P^t[i,j] \\log P^t[i,j]\\) be the diffusion laziness of a node \\(i\\) in a graph with affinity matrix \\(A\\). The Diffusion Ricci Curvature \\(k_{rd}\\) of edge \\(i,j\\) is then\n\\[\nk_{rd} = \\frac{\\partial l(A,t)[i]}{\\partial A[i,j]} + \\frac{\\partial l(A,t)[j]}{\\partial A[i,j]}\n\\]\nComputing this made possible by the fact the diffusion curvature is differentiable - and we can ‘backpropogate’ through the multiplications of \\(P\\), much as one can backpropogate through a GNN. Here’s a few functions to implement the basics:"
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html#a-cube",
    "href": "library/Diffusion Ricci Curvature.html#a-cube",
    "title": "Diffusion Ricci Curvature",
    "section": "A Cube",
    "text": "A Cube\nWe’ll start with the simplest possible case: an 8 point cube. Here, we can directly visualize what happens when we weaken and strength an edge.\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n\ndef tweak_matrix_entry(A, i, j, num_ops = 10, max_weakening = 0.5):\n    A = jnp.array(A, dtype=float)\n    diager = jnp.zeros_like(A)\n    diager = diager.at[[i,j],[j,i]].set(1)\n    outs = [A + diager*(-max_weakening)]\n    # returns a list of new As, with A[i,j] weakened then strengthened\n    tweak_amount = 2*max_weakening / num_ops\n    tweaks = [-max_weakening]\n    for n in range(num_ops):\n        outs.append(\n            outs[-1] + diager*tweak_amount\n        )\n        tweaks.append(tweaks[-1] + tweak_amount)\n    return outs, tweaks\n\n\ndef plot_curvature_change_along_edge(A, i, j, t, use_mean=True):\n    A = jnp.array(A, dtype=float)\n    As, tweaks = tweak_matrix_entry(A, i,j, max_weakening=1, num_ops = 30)\n    local_diffusion_curvatures = []\n    for tweaked_A in As:\n        if not use_mean: local_diffusion_curvatures.append(\n            diffusion_laziness_of_idx(tweaked_A, i, t) + diffusion_laziness_of_idx(tweaked_A, j, t)\n        )\n        else: local_diffusion_curvatures.append(\n            mean_diffusion_laziness_of_graph(tweaked_A,t)\n        )\n    plt.plot(tweaks, local_diffusion_curvatures)\n    plt.title(f\"Change in {t}-step Diffusion Laziness when altering edge [{i},{j}]\")\n\n\nplot_curvature_change_along_edge(A,4,5,8, use_mean=False)\n\n\n\n\nAs expected, we can see the diffusion laziness of nodes 4 and 5 increase as the edge [4,5] is strengthened - a sign of positive curvature.\nInterestingly, though the mean diffusion laziness across the graph stays virtually constant.\n\nplot_curvature_change_along_edge(A,4,5,16, use_mean=True)\n\n\n\n\n\nR, E = differential_dc(A, 8)\nplot_graph_with_edge_and_node_colors(A,R=R)"
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html#a-saddle-like-region",
    "href": "library/Diffusion Ricci Curvature.html#a-saddle-like-region",
    "title": "Diffusion Ricci Curvature",
    "section": "A Saddle-like Region",
    "text": "A Saddle-like Region\n\ndef saddled_ring_graph(nodes_per_ring):\n    # Create an empty graph\n    G = nx.Graph()\n\n    # Generate nodes for the first ring\n    first_ring = list(range(1, nodes_per_ring + 1))\n    G.add_nodes_from(first_ring)\n    # Forming the cycle for the first ring\n    G.add_edges_from(zip(first_ring, first_ring[1:] + first_ring[:1]))\n\n    # Generate nodes for the second ring\n    second_ring = list(range(nodes_per_ring + 1, 2 * nodes_per_ring + 1))\n    G.add_nodes_from(second_ring)\n    # Forming the cycle for the second ring\n    G.add_edges_from(zip(second_ring, second_ring[1:] + second_ring[:1]))\n\n    # Add an edge to connect the two rings\n    G.add_edge(nodes_per_ring, nodes_per_ring + 1)\n\n    # Plot the graph\n    nx.draw(G, with_labels=True, node_color='lightblue', font_weight='bold')\n    plt.show()\n\n    # Return the adjacency matrix\n    return nx.adjacency_matrix(G).todense()\n\n# Example usage\nsaddle_A = saddled_ring_graph(5)\n\n\n\n\n\nplot_curvature_change_along_edge(saddle_A, 4, 5, 10, use_mean=False)\n\n\n\n\n\nplot_curvature_change_along_edge(saddle_A, 4, 5, 11, use_mean=False)"
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html#the-challenge",
    "href": "library/Diffusion Ricci Curvature.html#the-challenge",
    "title": "Diffusion Ricci Curvature",
    "section": "The challenge",
    "text": "The challenge\nThis method works convincingly on exceedingly simple toy data, where changing one edge has a drastic effect on the surrounding region. In this respect, it has many of the weaknesses of Ollivier Ricci curvature. In a densely-sampled manifold, most edges will appear flat, in that altering them doesn’t much change the geometry."
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html#with-300-point-torus",
    "href": "library/Diffusion Ricci Curvature.html#with-300-point-torus",
    "title": "Diffusion Ricci Curvature",
    "section": "With 300 Point torus",
    "text": "With 300 Point torus\n\nfrom diffusion_curvature.datasets import torus\n\n\nX, ks = torus(200)\nG = graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\n\n\nA = jnp.array(\n        G.W.todense(),\n        dtype=jnp.float32,\n    )\n\n\nR = differential_dc(A,8)\n\n\n\n\n\nscalar_ks = jnp.sum(R[0], axis=-1)\n\n\nfrom diffusion_curvature.utils import plot_3d\nplot_3d(X,scalar_ks,colorbar=True,use_plotly=True)"
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html#a-cube-1",
    "href": "library/Diffusion Ricci Curvature.html#a-cube-1",
    "title": "Diffusion Ricci Curvature",
    "section": "A Cube",
    "text": "A Cube\nWe’ll start with the simplest possible case: an 8 point cube. Here, we can directly visualize what happens when we weaken and strength an edge.\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n\ndef tweak_matrix_entry(A, i, j, num_ops = 10, max_weakening = 0.5):\n    A = jnp.array(A, dtype=float)\n    diager = jnp.zeros_like(A)\n    diager = diager.at[[i,j],[j,i]].set(1)\n    outs = [A + diager*(-max_weakening)]\n    # returns a list of new As, with A[i,j] weakened then strengthened\n    tweak_amount = 2*max_weakening / num_ops\n    tweaks = [-max_weakening]\n    for n in range(num_ops):\n        outs.append(\n            outs[-1] + diager*tweak_amount\n        )\n        tweaks.append(tweaks[-1] + tweak_amount)\n    return outs, tweaks\n\n\ndef plot_curvature_change_along_edge(A, i, j, t, use_mean=True):\n    A = jnp.array(A, dtype=float)\n    As, tweaks = tweak_matrix_entry(A, i,j, max_weakening=1, num_ops = 30)\n    local_diffusion_curvatures = []\n    for tweaked_A in As:\n        if not use_mean: local_diffusion_curvatures.append(\n            diffusion_laziness_of_idx(tweaked_A, i, t) + diffusion_laziness_of_idx(tweaked_A, j, t)\n        )\n        else: local_diffusion_curvatures.append(\n            mean_diffusion_laziness_of_graph(tweaked_A,t)\n        )\n    plt.plot(tweaks, local_diffusion_curvatures)\n    plt.title(f\"Change in {t}-step Diffusion Laziness when altering edge [{i},{j}]\")\n\n\nplot_curvature_change_along_edge(A,4,5,8, use_mean=False)\n\nAs expected, we can see the diffusion laziness increasing as the edge [4,5] is strengthened - a sign of positive curvature.\nIndeed, the Diffusion Ricci curvature of the edges is uniformly positive.\n\nplot_curvature_change_along_edge(A,4,5,16, use_mean=True)\n\n\nR, E = differential_dc(A, 8)\nplot_graph_with_edge_colors(A,R)\n\n\njnp.min(R)"
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html#a-saddle-like-region-1",
    "href": "library/Diffusion Ricci Curvature.html#a-saddle-like-region-1",
    "title": "Diffusion Ricci Curvature",
    "section": "A Saddle-like Region",
    "text": "A Saddle-like Region\n\ndef saddled_ring_graph(nodes_per_ring):\n    # Create an empty graph\n    G = nx.Graph()\n\n    # Generate nodes for the first ring\n    first_ring = list(range(1, nodes_per_ring + 1))\n    G.add_nodes_from(first_ring)\n    # Forming the cycle for the first ring\n    G.add_edges_from(zip(first_ring, first_ring[1:] + first_ring[:1]))\n\n    # Generate nodes for the second ring\n    second_ring = list(range(nodes_per_ring + 1, 2 * nodes_per_ring + 1))\n    G.add_nodes_from(second_ring)\n    # Forming the cycle for the second ring\n    G.add_edges_from(zip(second_ring, second_ring[1:] + second_ring[:1]))\n\n    # Add an edge to connect the two rings\n    G.add_edge(nodes_per_ring, nodes_per_ring + 1)\n\n    # Plot the graph\n    nx.draw(G, with_labels=True, node_color='lightblue', font_weight='bold')\n    plt.show()\n\n    # Return the adjacency matrix\n    return nx.adjacency_matrix(G).todense()\n\n# Example usage\nsaddle_A = saddled_ring_graph(5)\n\n\nplot_curvature_change_along_edge(saddle_A, 4, 5, 16, use_mean=False)\n\n\nplot_curvature_change_along_edge(saddle_A, 4, 5, 16, use_mean=True)\n\n\ntweaked_saddle_As, tweaks = tweak_matrix_entry(saddle_A,4,5, max_weakening=1)\n\n\ntweaked_diffusions = []\nfor sA in tweaked_saddle_As:\n    P = diffusion_matrix(sA)\n    Pt = jax_power_matrix(P,16)\n    tweaked_diffusions.append(Pt[5])\n\n\nplot_graph_with_edge_and_node_colors(saddle_A, N=tweaked_diffusions[0])\n\n\ndiffusion_laziness_of_idx(tweaked_saddle_As[0],4,16)\n\n\ndiffusion_laziness_of_idx(tweaked_saddle_As[0],5,16)\n\n\nplot_graph_with_edge_and_node_colors(saddle_A, N=tweaked_diffusions[5])\n\n\nplot_graph_with_edge_and_node_colors(saddle_A, N=tweaked_diffusions[-1])\n\n\ndiffusion_laziness_of_idx(tweaked_saddle_As[5],4,16)\n\n\ndiffusion_laziness_of_idx(tweaked_saddle_As[5],5,16)\n\nAnd here, strengthening this saddle edge decreases the diffusion laziness of the surrounding points – a sign of negative curvature.\n\nR, E = differential_dc(saddle_A, 16)\nplot_graph_with_edge_colors(saddle_A,R)\n\n\njax.grad(diffusion_laziness_of_edge)(jnp.array(A,dtype=float), 4, 5, 8)"
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html#the-challenge-1",
    "href": "library/Diffusion Ricci Curvature.html#the-challenge-1",
    "title": "Diffusion Ricci Curvature",
    "section": "The challenge",
    "text": "The challenge\nThis method works convincingly on exceedingly simple toy data, where changing one edge has a drastic effect on the surrounding region. In this respect, it has many of the weaknesses of Ollivier Ricci curvature. In a densely-sampled manifold, most edges will appear flat, in that altering them doesn’t much change the geometry."
  },
  {
    "objectID": "library/Diffusion Ricci Curvature.html#with-300-point-torus-1",
    "href": "library/Diffusion Ricci Curvature.html#with-300-point-torus-1",
    "title": "Diffusion Ricci Curvature",
    "section": "With 300 Point torus",
    "text": "With 300 Point torus\n\nfrom diffusion_curvature.datasets import torus\n\n\nX, ks = torus(200)\nG = graphtools.Graph(X, anisotropy=1, knn=15, decay=None).to_pygsp()\n\n\nA = jnp.array(\n        G.W.todense(),\n        dtype=jnp.float32,\n    )\n\n\nR = differential_dc(A,8)\n\n\nscalar_ks = jnp.sum(R[0], axis=-1)\n\n\nplot_3d(X,scalar_ks,colorbar=True,use_plotly=True)"
  },
  {
    "objectID": "library/Kernels.html",
    "href": "library/Kernels.html",
    "title": "Kernels",
    "section": "",
    "text": "This notebook will establish our core utilities: functions for building the diffusion matrix, with various types of kernels."
  },
  {
    "objectID": "library/Kernels.html#gaussian-kernel",
    "href": "library/Kernels.html#gaussian-kernel",
    "title": "Kernels",
    "section": "Gaussian Kernel",
    "text": "Gaussian Kernel\nThis currently supports either a fixed bandwidth, which applies to all points, or an adaptive bandwidth, that creates a tailor-made bandwidth for each point.\n\nThe Median Heuristic for Kernel Bandwidth\nSetting the kernel bandwidth is one of the most important operations with any kernel method. It’s important to have a good heuristic to avoid needing to estimate this by trial and error. This function implements the median heuristic described in https://arxiv.org/pdf/1707.07269.pdf.\nThe median heuristic sets the bandwidth to \\(\\sqrt{H_n/2}\\), where \\(H_n\\) is the median of the squared distances between the upper triangle of the distance matrix.\n\n\n\nmedian_heuristic\n\n median_heuristic (D:numpy.ndarray)\n\n\n\n\n\nType\nDetails\n\n\n\n\nD\nndarray\nthe distance matrix\n\n\n\n\n\n\ngaussian_kernel\n\n gaussian_kernel (X:numpy.ndarray, kernel_type='fixed', sigma:float=0,\n                  k:float=10, anisotropic_density_normalization:float=0.5,\n                  threshold_for_small_values:float=1e-05)\n\nConstructs an affinity matrix from pointcloud data, using a gaussian kernel\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\nndarray\n\npointcloud data as rows, shape n x d\n\n\nkernel_type\nstr\nfixed\neither fixed, or adaptive\n\n\nsigma\nfloat\n0\nif fixed, uses kernel bandwidth sigma. If not set, uses a heuristic to estimate a good sigma value\n\n\nk\nfloat\n10\nif adaptive, creates a different kernel bandwidth for each point, based on the distance from that point to the kth nearest neighbor\n\n\nanisotropic_density_normalization\nfloat\n0.5\nif nonzero, performs anisotropic density normalization\n\n\nthreshold_for_small_values\nfloat\n1e-05\nSets all affinities below this value to zero. Set to zero to disable.\n\n\n\n\n\n\npygsp_graph_from_points\n\n pygsp_graph_from_points (X, knn=15)"
  },
  {
    "objectID": "library/Kernels.html#the-adaptive-kernel",
    "href": "library/Kernels.html#the-adaptive-kernel",
    "title": "Kernels",
    "section": "The Adaptive Kernel",
    "text": "The Adaptive Kernel\nHere we have the adaptive kernel born Diffusion matrix, and we visualize the diffusion centered on the point (0,-3,0), which (from the view of the plot below), should be on the outer rim of the torus, facing us directly.\n\nP = diffusion_matrix(X,kernel_type=\"adaptive\",k=20)\n\n\ndist = P[0]\nplot_3d(X,dist)"
  },
  {
    "objectID": "library/Kernels.html#the-adaptive-anisotropic-kernel",
    "href": "library/Kernels.html#the-adaptive-anisotropic-kernel",
    "title": "Kernels",
    "section": "The Adaptive Anisotropic Kernel",
    "text": "The Adaptive Anisotropic Kernel\nNow we’ll add one more round of density normalization with the “adaptive anisotropic” kernel: \\[ W_{a} = D^{-1} W D^{-1} \\] Where D is the matrix whose diagonals are the rowsums of W.\n\nP = diffusion_matrix(X,kernel_type=\"adaptive\",k=20,anisotropic_density_normalization=1)\n\n\ndist = P[0]\nplot_3d(X,dist)\n\n\n\n\nIt looks much the same, as expected. Ideally, this kernel will combat density related differences in the curvature, by equalizing the density.\n\nfrom diffusion_curvature.datasets import sphere\n\n\nX, ks = sphere(2000)\n\n\nA = gaussian_kernel(X,kernel_type = \"adaptive\", k = 10, anisotropic_density_normalization = 1, threshold_for_small_values=1e-5)\n\n\nA\n\narray([[0.00102873, 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.00085635, 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.00079775, ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.00086877, 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.0009022 ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.00063627]])\n\n\n\nsum(A)\n\narray([0.01593725, 0.01654875, 0.01803043, ..., 0.01560873, 0.01835663,\n       0.0159891 ])\n\n\n\nplot_3d(X,A[0])\n\n\n\n\n\n\ncompute_anisotropic_diffusion_matrix_from_graph\n\n compute_anisotropic_diffusion_matrix_from_graph (A:numpy.ndarray,\n                                                  alpha:float)\n\n\n\n\n\nType\nDetails\n\n\n\n\nA\nndarray\nthe adjacency/affinity matrix of the graph\n\n\nalpha\nfloat\nthe anisotropic density normalization parameter\n\n\nReturns\nndarray\n\n\n\n\n\n\n\ncompute_anisotropic_affinities_from_graph\n\n compute_anisotropic_affinities_from_graph (A:numpy.ndarray, alpha:float)\n\n\n\n\n\nType\nDetails\n\n\n\n\nA\nndarray\nthe adjacency/affinity matrix of the graph\n\n\nalpha\nfloat\nthe anisotropic density normalization parameter\n\n\nReturns\nndarray"
  },
  {
    "objectID": "library/Kernels.html#knn-graph-1",
    "href": "library/Kernels.html#knn-graph-1",
    "title": "Kernels",
    "section": "kNN Graph",
    "text": "kNN Graph\n\nfrom diffusion_curvature.datasets import torus\nfrom diffusion_curvature.heat_diffusion import jax_power_matrix\n\n\nX, ks = torus(2000, use_guide_points = True)\nA = knn_graph(X,k=10, pygsp=False)\nP = diffusion_matrix(A = A).todense()\nPt = jax_power_matrix(jnp.asarray(P),20)\nplot_3d(X, Pt[0])\n\n\n\n\n\nP\n\n&lt;2000x2000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n    with 20000 stored elements in Compressed Sparse Row format&gt;\n\n\n\n!nbdev_export\n\n/Users/boreas/Pumberton/Workshop/21-SUMRY-Curvature/diffusion-curvature/.pixi/env/lib/python3.11/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nParameters \n----------- in \nSample `n` data points on a torus. Modified from [tadasets.shapes — TaDAsets 0.1.0 documentation](https://tadasets.scikit-tda.org/en/latest/_modules/tadasets/shapes.html#torus)\nUses rejection sampling....\n  else: warn(msg)\n\n\ntorus\n\n torus (n=2000, c=2, a=1, noise=None, seed=None, use_guide_points=False)\n\nSample n data points on a torus. Modified from tadasets.shapes — TaDAsets 0.1.0 documentation Uses rejection sampling.\nIn addition to the randomly generated points, a few constant points have been added. The 0th point is on the outer rim, in a region of high positive curvature. The 1st point is in the inside, in a region of negative curvature, and the 2nd point is on the top, where the curvature should be closer to zero.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n2000\nNumber of data points in shape.\n\n\nc\nint\n2\nDistance from center to center of tube.\n\n\na\nint\n1\nRadius of tube.\n\n\nnoise\nNoneType\nNone\n\n\n\nseed\nNoneType\nNone\nSeed for random state.\n\n\nuse_guide_points\nbool\nFalse"
  },
  {
    "objectID": "library/Volume Estimation.html",
    "href": "library/Volume Estimation.html",
    "title": "Volume Estimation with Heat Diffusion",
    "section": "",
    "text": "TLDR: The self-diffusion method of volume estimation works reliably in sampled euclidean planes of various dimensions. The volume differs from ground truth by a multiplicative factor, but otherwise grows at the same ratio as analytically expected. Be wary, though, of volumes taken at high diffusion times: they vary wildly between samplings.\nIn GitHub - KrishnaswamyLab/HeatGeo: Embedding with the Heat-geodesic dissimilarity, Tong et al use the Chebyshev approximation of the heat equation on the graph to estimate volume, by using Varadhan’s formula:\n\\[\n\\frac{c(\\epsilon)}{V(x, \\sqrt{t})} \\exp \\left(-\\frac{d(x, y)^2}{4(1+\\epsilon) t}\\right) \\leq h_t(x, y) \\leq \\frac{C(\\epsilon)}{V(x, \\sqrt{t})} \\exp \\left(-\\frac{d(x, y)^2}{4(1-\\epsilon) t}\\right)\n\\]\nThis suggests that the diagonals of the diffusion matrix (\\(h_t(x,x)\\)) approximate \\(\\frac{1}{V(x,\\sqrt{t})}\\). To recover the volume, invert the ‘laziness’ of the diffusion.\nNote that the diffusion times correspond only to the square root of the radius.\nIn this notebook, we’ll implement and experiment on this method of volume estimation, by performing it on several manifolds where the volume is known.\nfrom diffusion_curvature.datasets import torus\nfrom diffusion_curvature.graphs import *\nX, ks = torus(2000)\nG_torus = get_alpha_decay_graph(X)"
  },
  {
    "objectID": "library/Volume Estimation.html#volume-in-the-nd-euclidean-plane-compared-to-the-actual-volume",
    "href": "library/Volume Estimation.html#volume-in-the-nd-euclidean-plane-compared-to-the-actual-volume",
    "title": "Volume Estimation with Heat Diffusion",
    "section": "Volume in the ND Euclidean Plane, compared to the actual volume",
    "text": "Volume in the ND Euclidean Plane, compared to the actual volume\nThis is the simplest case. We’ll sample euclidean planes of several dimensions, and take volume estimates at various scales. We’ll compare those to the real volumes of balls of radii \\(\\sqrt{t}\\), by plotting one against the other.\nI suspect that there will be some scaling factor which needs to be estimated, as – just from the graph – we don’t know what the density is.\n\nfrom diffusion_curvature.datasets import plane\n\n\ndef volumes_of_euclidean_nplane(\n        n_points,\n        dim,\n        ts,\n        decay=40,\n        knn=10,\n        anisotropy=0,\n        denoising_scale = 0,\n):\n    X = plane(n_points,dim)\n    G = get_alpha_decay_graph(X, knn=knn, decay=decay, anisotropy=anisotropy)\n    vols = volume_via_heat_at_scales(G,0,ts, denoising_scale=denoising_scale)\n    return vols\n\n\n\nactual_euclidean_volumes_at_radii\n\n actual_euclidean_volumes_at_radii (dim, radii)\n\n\nassert actual_euclidean_volumes_at_radii(2,[4]) == np.pi*4**2\n\n\ndef perform_trials(fn,n_trials=10, **kwargs):\n    outs = []\n    for i in range(n_trials):\n        outs.append(fn(**kwargs))\n    return outs\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef plot_arrays(estimated, actual, xs=None, title=\"\"):\n    sns.set(style=\"darkgrid\")  # Set the seaborn style\n\n    # Create a figure and axes\n    fig, ax = plt.subplots()\n\n    if estimated.shape[0] &gt; 1:\n        # Compute the mean and standard deviation for the estimated array\n        mean_estimated = np.mean(estimated, axis=0)\n        std_estimated = np.std(estimated, axis=0)\n\n        # Plot estimated as a line with error bars\n        ax.errorbar(x = xs, y = mean_estimated, yerr=std_estimated, label=\"Estimated\")\n    else:\n        ax.plot(xs, estimated[0], label=\"Estimated\")\n    # Plot actual as a line\n    ax.plot(xs, actual, label=\"Actual\")\n\n    # Set the labels for x-axis and y-axis\n    ax.set_xlabel(\"Radius\")\n    ax.set_ylabel(\"Volume of n-sphere\")\n\n    # Set the title of the plot\n    ax.set_title(title)\n\n    # Display the legend\n    ax.legend()\n\n    # Show the plot\n    plt.show()\n\n\nts = [0,2,4,6,8,10,12,14,16,18,20]\ndim = 2\nn_points=1000\nknn=10\ndecay=20\nanisotropy=0.5\nradii = convert_t_to_r(ts,dim)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=50, n_points=n_points, dim=dim, ts=ts, knn=knn, anisotropy=anisotropy, decay=decay, denoising_scale=3)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,xs=radii,title=\"Euclidean 2 Plane\")\n\n\n\n\n\nts = [2,4,6,8,10,12,14,16,18,20]\nknn=10\ndecay=20\nanisotropy=0\ndim = 2\nn_points=10000\nradii = np.sqrt(ts)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=50, n_points=n_points, dim=dim, ts=ts, knn=knn, anisotropy=anisotropy, decay=decay)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,xs = radii, title=f\"Euclidean 2 Plane with knn {knn} anisotropy {anisotropy} and decay {decay}\")\n\n\n\n\n\nts = [2,4,6,8,10,12,14,16,18,20]\nknn=10\ndecay=20\nanisotropy=0.5\ndim = 2\nn_points=10000\nradii = np.sqrt(ts)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=50, n_points=n_points, dim=dim, ts=ts, knn=knn, anisotropy=anisotropy, decay=decay)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,xs=radii, title=f\"Euclidean 2 Plane with knn {knn} anisotropy {anisotropy} and decay {decay}\")\n\n\n\n\n\nts = [2,4,6,8,10,12,14,16,18,20]\nknn=10\ndecay=20\nanisotropy=0.8\ndim = 2\nn_points=10000\nradii = np.sqrt(ts)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=50, n_points=n_points, dim=dim, ts=ts, knn=knn, anisotropy=anisotropy, decay=decay)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,xs=radii,title=f\"Euclidean 2 Plane with knn {knn} anisotropy {anisotropy} and decay {decay}\")\n\n\n\n\nThis shows a clear pattern: the volume estimated from residual laziness has 1. a lot of variation across samplings, especially with higher t values 2. a consistently higher slope than the ground truth, by a constant multiple.\nThe second point is consistent with the hypothesis that the unknown density of the graph/point cloud results in a distortion of the volume by some constant factor. Fortunately, when performing a comparison between the manifold space and analytic euclidean space, this factor becomes a constant, reflected only in the linear term of the quadratic approximation, and not in the quadratic term, where scalar curvature is revealed.\nThe first phenomenon, of increasing variation with increasing radius, is odd. One might expect that large-scale diffusions had the least variation between samplings, because it has more time for local fluctuations in density to average out. The opposite appears to be true. At least this supports the use of local approximations.\nLet’s see what the ratio actually is:\n\ndef plot_array(ratios, title=\"\"):\n    sns.set(style=\"darkgrid\")  # Set the seaborn style\n\n    # Create a figure and axes\n    fig, ax = plt.subplots()\n    # Compute the mean and standard deviation for the estimated array\n    mean_estimated = np.mean(ratios, axis=0)\n    std_estimated = np.std(ratios, axis=0)\n\n    # Plot estimated as a line with error bars\n    ax.errorbar(np.arange(ratios.shape[1]), mean_estimated, yerr=std_estimated, label=\"Estimated\")\n\n    # Set the labels for x-axis and y-axis\n    ax.set_xlabel(\"Radius\")\n    ax.set_ylabel(\"Volume of n-sphere\")\n\n    # Set the title of the plot\n    ax.set_title(title)\n\n    # Display the legend\n    ax.legend()\n\n    # Show the plot\n    plt.show()\n\n\nplot_array(heat_estimates/actual_volumes, \"Ratio of Estimate to Actual Volume\")\n\n\n\n\nHere’s the same experiment in higher dimensions.\n\nts = [2,4,6,8,10,12,14,16,18,20]\ndim = 3\nn_points=10000\nradii = np.sqrt(ts)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=50, n_points=n_points, dim=dim, ts=ts)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,title=f\"Euclidean {dim} Plane\")\n\nKeyboardInterrupt: \n\n\n\nts = [2,4,6,8,10,12,14,16,18,20]\ndim = 5\nn_points=10000\nradii = np.sqrt(ts)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=50, n_points=n_points, dim=dim, ts=ts)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,title=f\"Euclidean {dim} Plane\")\n\n\n\n\nDimensions 3 and 5 behave as expected, displaying the same patterns of growing more unpredictable with age and varying from ground truth by some multiplicative factor.\nWith dimension 7, we begin to encounter the curse of dimensionality. 10,000 points is no longer enough; we need something on the order of a million to be able to diffuse for 10-20 steps without hitting edge effects.\n\nts = [2,4,6,8,10,12,14,16,18,20]\ndim = 7\nn_points=10000\nradii = np.sqrt(ts)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=10, n_points=n_points, dim=dim, ts=ts)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,title=f\"Euclidean {dim} Plane with {n_points}\")\n\n\n\n\n\nts = [2,4,6,8,10,12,14,16,18,20]\ndim = 7\nn_points=50000\nradii = np.sqrt(ts)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=10, n_points=n_points, dim=dim, ts=ts)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,title=f\"Euclidean {dim} Plane with {n_points}\")\n\n\n\n\n\nts = [2,4,6,8,10,12,14,16,18,20]\ndim = 7\nn_points=100000\nradii = np.sqrt(ts)\nheat_estimates = np.array(\n    perform_trials(volumes_of_euclidean_nplane, n_trials=10, n_points=n_points, dim=dim, ts=ts)\n)\nactual_volumes = actual_euclidean_volumes_at_radii(dim,radii)\nplot_arrays(heat_estimates,actual_volumes,title=f\"Euclidean {dim} Plane with {n_points}\")"
  },
  {
    "objectID": "library/Volume Estimation.html#does-denoising-reduce-variation-in-volume-measurements",
    "href": "library/Volume Estimation.html#does-denoising-reduce-variation-in-volume-measurements",
    "title": "Volume Estimation with Heat Diffusion",
    "section": "Does denoising reduce variation in volume measurements?",
    "text": "Does denoising reduce variation in volume measurements?\nTo test this, here’s several plots of the same volume estimate, with different scales of denoising.\n\nvolume_estimates_with_denoising = []\nfor denoising_scale in tqdm([0,1,3,5,7,9,15]):\n    volume_estimates_with_denoising.append({})\n    volume_estimates_with_denoising[-1]['scale'] = denoising_scale\n    volume_estimates_with_denoising[-1]['array'] = np.array(\n        perform_trials(volumes_of_euclidean_nplane, n_trials=50, n_points=5000, dim=2, ts=[2,4,6,8,10,12,14,16,18,20], denoising_scale=denoising_scale)\n    )\n\n\n\n\n\nsns.set(style=\"darkgrid\")  # Set the seaborn style\nfig, ax = plt.subplots()\nts = [2,4,6,8,10,12,14,16,18,20]\nxs = np.sqrt(ts)\nfor D in volume_estimates_with_denoising:\n    # Compute the mean and standard deviation for the estimated array\n    mean_estimated = np.mean(D['array'], axis=0)\n    std_estimated = np.std(D['array'], axis=0)\n    # Plot estimated as a line with error bars\n    ax.errorbar(x = xs, y = mean_estimated, yerr=std_estimated, label=f\"Denoising = {D['scale']}\")\nax.set_xlabel(\"Radius\")\nax.set_ylabel(\"Volume of n-sphere\")\nax.set_title(\"Volumes & Variations at Different Denoising Scales\")\nax.legend()\nplt.show()"
  }
]